2:I[1583,["231","static/chunks/231-a2a5e21f80783222.js","676","static/chunks/676-9ad3358feebe5792.js","107","static/chunks/app/blog/page/%5Bpage%5D/page-262e0c2d25dedd77.js"],"default"]
39:I[9275,[],""]
3b:I[1343,[],""]
3c:I[4404,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","97","static/chunks/97-7260ee5660d3a094.js","185","static/chunks/app/layout-41f547bf46e2a8fb.js"],"GoogleAnalytics"]
3d:I[8700,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","97","static/chunks/97-7260ee5660d3a094.js","185","static/chunks/app/layout-41f547bf46e2a8fb.js"],"ThemeProviders"]
3e:I[4080,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","97","static/chunks/97-7260ee5660d3a094.js","185","static/chunks/app/layout-41f547bf46e2a8fb.js"],""]
3f:I[9032,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","97","static/chunks/97-7260ee5660d3a094.js","185","static/chunks/app/layout-41f547bf46e2a8fb.js"],"KBarSearchProvider"]
40:I[5133,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","97","static/chunks/97-7260ee5660d3a094.js","185","static/chunks/app/layout-41f547bf46e2a8fb.js"],"default"]
41:I[231,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","797","static/chunks/app/blog/%5B...slug%5D/page-611054ae17c70393.js"],""]
4:["AI"]
5:{"text":"5 min read","minutes":4.355,"time":261300,"words":871}
7:{"value":"Abstract","url":"#abstract-9","depth":2}
8:{"value":"Introduction","url":"#introduction-14","depth":2}
9:{"value":"Data","url":"#data-1","depth":2}
a:{"value":"Data preprocessing","url":"#data-preprocessing-1","depth":3}
b:{"value":"Data filtering","url":"#data-filtering-1","depth":3}
c:{"value":"System Overview","url":"#system-overview-4","depth":2}
6:["$7","$8","$9","$a","$b","$c"]
d:{"@context":"https://schema.org","@type":"BlogPosting","headline":"WMT2019-新闻-Facebook","datePublished":"2021-08-16T00:00:00.000Z","dateModified":"2021-08-16T00:00:00.000Z","description":"这篇文章介绍了一个机器翻译系统,主要针对英德和英俄翻译方向。系统采用了大规模反向翻译、数据过滤、模型集成和噪声信道模型重排等技术,相比2018年提升了4.5个BLEU分。文章详细描述了数据预处理、模型训练和解码等各个环节的具体做法。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-16-WMT2019-新闻-Facebook"}
3:{"title":"WMT2019-新闻-Facebook","date":"2021-08-16T00:00:00.000Z","tags":"$4","lastmod":"2021-08-16T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了一个机器翻译系统,主要针对英德和英俄翻译方向。系统采用了大规模反向翻译、数据过滤、模型集成和噪声信道模型重排等技术,相比2018年提升了4.5个BLEU分。文章详细描述了数据预处理、模型训练和解码等各个环节的具体做法。","layout":"PostSimple","type":"Blog","readingTime":"$5","slug":"AI/2021-08-16-WMT2019-新闻-Facebook","path":"blog/AI/2021-08-16-WMT2019-新闻-Facebook","filePath":"blog/AI/2021-08-16-WMT2019-新闻-Facebook.mdx","toc":"$6","structuredData":"$d"}
f:["AI"]
10:{"text":"8 min read","minutes":7.745,"time":464700,"words":1549}
12:{"value":"Introduction","url":"#introduction-12","depth":2}
13:{"value":"Applying Multiple Word Segmentation Tools","url":"#applying-multiple-word-segmentation-tools-1","depth":2}
14:{"value":"English ↔ Chinese Machine Translation Task","url":"#english--chinese-machine-translation-task-1","depth":2}
15:{"value":"Japanese → English Translation Task (Patent Domain)","url":"#japanese--english-translation-task-patent-domain-1","depth":2}
11:["$12","$13","$14","$15"]
16:{"@context":"https://schema.org","@type":"BlogPosting","headline":"CCMT2020-OPPO","datePublished":"2021-08-15T00:00:00.000Z","dateModified":"2021-08-15T00:00:00.000Z","description":"这篇文章主要介绍了OPPO在CCMT 2020机器翻译比赛中的系统设计和发现。OPPO在7个任务方向中的6个排名第一,主要采用了Transformer模型,并使用了回译、领域微调、知识蒸馏等技术。文章还发现,在低资源语料上简单应用不同的中文分词工具,可以在多个任务中带来明显的性能提升。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-15-CCMT2020-OPPO"}
e:{"title":"CCMT2020-OPPO","date":"2021-08-15T00:00:00.000Z","tags":"$f","lastmod":"2021-08-15T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了OPPO在CCMT 2020机器翻译比赛中的系统设计和发现。OPPO在7个任务方向中的6个排名第一,主要采用了Transformer模型,并使用了回译、领域微调、知识蒸馏等技术。文章还发现,在低资源语料上简单应用不同的中文分词工具,可以在多个任务中带来明显的性能提升。","layout":"PostSimple","type":"Blog","readingTime":"$10","slug":"AI/2021-08-15-CCMT2020-OPPO","path":"blog/AI/2021-08-15-CCMT2020-OPPO","filePath":"blog/AI/2021-08-15-CCMT2020-OPPO.mdx","toc":"$11","structuredData":"$16"}
18:["AI"]
19:{"text":"6 min read","minutes":5.065,"time":303900,"words":1013}
1b:{"value":"Introduction","url":"#introduction-13","depth":2}
1c:{"value":"System overview","url":"#system-overview-3","depth":2}
1d:{"value":"Data Preprocessing and Filtering","url":"#data-preprocessing-and-filtering-1","depth":3}
1e:{"value":"Iterativa Back Translation","url":"#iterativa-back-translation-1","depth":3}
1f:{"value":"Multilingual Model","url":"#multilingual-model-1","depth":3}
20:{"value":"Model Architectures and Ensemble","url":"#model-architectures-and-ensemble-1","depth":3}
21:{"value":"Iterative KD and Fine-tuning","url":"#iterative-kd-and-fine-tuning-1","depth":3}
22:{"value":"Reranking","url":"#reranking-3","depth":3}
23:{"value":"Post Editing","url":"#post-editing-1","depth":3}
24:{"value":"Experiment","url":"#experiment-1","depth":2}
1a:["$1b","$1c","$1d","$1e","$1f","$20","$21","$22","$23","$24"]
25:{"@context":"https://schema.org","@type":"BlogPosting","headline":"WMT2020-新闻-小牛","datePublished":"2021-08-15T00:00:00.000Z","dateModified":"2021-08-15T00:00:00.000Z","description":"这篇文章介绍了NiuTrans团队在WMT20机器翻译评测中的系统。该系统在日英和英日翻译方向上排名第一,主要应用了迭代回译、宽深Transformer模型、迭代知识蒸馏和迭代微调等技术。系统的训练步骤包括数据预处理、生成伪数据、多样化翻译模型、知识蒸馏、领域微调和后处理等。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-15-WMT2020-新闻-小牛"}
17:{"title":"WMT2020-新闻-小牛","date":"2021-08-15T00:00:00.000Z","tags":"$18","lastmod":"2021-08-15T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了NiuTrans团队在WMT20机器翻译评测中的系统。该系统在日英和英日翻译方向上排名第一,主要应用了迭代回译、宽深Transformer模型、迭代知识蒸馏和迭代微调等技术。系统的训练步骤包括数据预处理、生成伪数据、多样化翻译模型、知识蒸馏、领域微调和后处理等。","layout":"PostSimple","type":"Blog","readingTime":"$19","slug":"AI/2021-08-15-WMT2020-新闻-小牛","path":"blog/AI/2021-08-15-WMT2020-新闻-小牛","filePath":"blog/AI/2021-08-15-WMT2020-新闻-小牛.mdx","toc":"$1a","structuredData":"$25"}
27:["AI"]
28:{"text":"8 min read","minutes":7.215,"time":432900,"words":1443}
2a:{"value":"Atman","url":"#atman-1","depth":3}
29:["$2a"]
2b:{"@context":"https://schema.org","@type":"BlogPosting","headline":"Atman机器翻译模型笔记","datePublished":"2021-08-13T00:00:00.000Z","dateModified":"2021-08-13T00:00:00.000Z","description":"这篇文章主要介绍了机器翻译模型的训练过程和数据处理方法。文章详细描述了从大规模语料训练基础模型到领域精调的完整流程,包括使用平行语料和单语回译语料进行训练,以及采用联合训练、EWC约束等技术来优化模型性能。此外,文章还讨论了语料清洗和数据增强的方法,如使用语言模型、句对相似度和统计规则进行数据筛选,以及通过反向翻译和对偶学习等技术来扩充训练数据。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-13-Atman机器翻译模型笔记"}
26:{"title":"Atman机器翻译模型笔记","date":"2021-08-13T00:00:00.000Z","tags":"$27","lastmod":"2021-08-13T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了机器翻译模型的训练过程和数据处理方法。文章详细描述了从大规模语料训练基础模型到领域精调的完整流程,包括使用平行语料和单语回译语料进行训练,以及采用联合训练、EWC约束等技术来优化模型性能。此外,文章还讨论了语料清洗和数据增强的方法,如使用语言模型、句对相似度和统计规则进行数据筛选,以及通过反向翻译和对偶学习等技术来扩充训练数据。","layout":"PostSimple","type":"Blog","readingTime":"$28","slug":"AI/2021-08-13-Atman机器翻译模型笔记","path":"blog/AI/2021-08-13-Atman机器翻译模型笔记","filePath":"blog/AI/2021-08-13-Atman机器翻译模型笔记.mdx","toc":"$29","structuredData":"$2b"}
2d:["AI"]
2e:{"text":"4 min read","minutes":3.58,"time":214800,"words":716}
30:{"value":"Abstract","url":"#abstract-7","depth":2}
31:{"value":"Introduction","url":"#introduction-10","depth":2}
32:{"value":"The Data","url":"#the-data-1","depth":2}
33:{"value":"The Approaches","url":"#the-approaches-1","depth":2}
34:{"value":"In-domain dictionary","url":"#in-domain-dictionary-1","depth":3}
35:{"value":"Reranking","url":"#reranking-2","depth":3}
36:{"value":"Data Processing","url":"#data-processing-1","depth":3}
37:{"value":"Experimental Results","url":"#experimental-results-1","depth":2}
2f:["$30","$31","$32","$33","$34","$35","$36","$37"]
38:{"@context":"https://schema.org","@type":"BlogPosting","headline":"WMT2020-生物医学-华为","datePublished":"2021-08-13T00:00:00.000Z","dateModified":"2021-08-13T00:00:00.000Z","description":"华为在WMT20生物医学翻译任务中的方法。研究者探讨了领域内字典对提高跨领域神经机器翻译性能的影响,并利用预训练机器翻译模型进行迁移学习。通过领域数据增强、重排序等技术,在英-法、英-德、英-意大利语对上取得了最先进的结果。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-13-WMT2020-生物医学-华为"}
2c:{"title":"WMT2020-生物医学-华为","date":"2021-08-13T00:00:00.000Z","tags":"$2d","lastmod":"2021-08-13T00:00:00.000Z","draft":false,"summary":"华为在WMT20生物医学翻译任务中的方法。研究者探讨了领域内字典对提高跨领域神经机器翻译性能的影响,并利用预训练机器翻译模型进行迁移学习。通过领域数据增强、重排序等技术,在英-法、英-德、英-意大利语对上取得了最先进的结果。","layout":"PostSimple","type":"Blog","readingTime":"$2e","slug":"AI/2021-08-13-WMT2020-生物医学-华为","path":"blog/AI/2021-08-13-WMT2020-生物医学-华为","filePath":"blog/AI/2021-08-13-WMT2020-生物医学-华为.mdx","toc":"$2f","structuredData":"$38"}
3a:["page","21","d"]
42:T69f,M12 0C8.74 0 8.333.015 7.053.072 5.775.132 4.905.333 4.14.63c-.789.306-1.459.717-2.126 1.384S.935 3.35.63 4.14C.333 4.905.131 5.775.072 7.053.012 8.333 0 8.74 0 12s.015 3.667.072 4.947c.06 1.277.261 2.148.558 2.913.306.788.717 1.459 1.384 2.126.667.666 1.336 1.079 2.126 1.384.766.296 1.636.499 2.913.558C8.333 23.988 8.74 24 12 24s3.667-.015 4.947-.072c1.277-.06 2.148-.262 2.913-.558.788-.306 1.459-.718 2.126-1.384.666-.667 1.079-1.335 1.384-2.126.296-.765.499-1.636.558-2.913.06-1.28.072-1.687.072-4.947s-.015-3.667-.072-4.947c-.06-1.277-.262-2.149-.558-2.913-.306-.789-.718-1.459-1.384-2.126C21.319 1.347 20.651.935 19.86.63c-.765-.297-1.636-.499-2.913-.558C15.667.012 15.26 0 12 0zm0 2.16c3.203 0 3.585.016 4.85.071 1.17.055 1.805.249 2.227.415.562.217.96.477 1.382.896.419.42.679.819.896 1.381.164.422.36 1.057.413 2.227.057 1.266.07 1.646.07 4.85s-.015 3.585-.074 4.85c-.061 1.17-.256 1.805-.421 2.227-.224.562-.479.96-.899 1.382-.419.419-.824.679-1.38.896-.42.164-1.065.36-2.235.413-1.274.057-1.649.07-4.859.07-3.211 0-3.586-.015-4.859-.074-1.171-.061-1.816-.256-2.236-.421-.569-.224-.96-.479-1.379-.899-.421-.419-.69-.824-.9-1.38-.165-.42-.359-1.065-.42-2.235-.045-1.26-.061-1.649-.061-4.844 0-3.196.016-3.586.061-4.861.061-1.17.255-1.814.42-2.234.21-.57.479-.96.9-1.381.419-.419.81-.689 1.379-.898.42-.166 1.051-.361 2.221-.421 1.275-.045 1.65-.06 4.859-.06l.045.03zm0 3.678c-3.405 0-6.162 2.76-6.162 6.162 0 3.405 2.76 6.162 6.162 6.162 3.405 0 6.162-2.76 6.162-6.162 0-3.405-2.76-6.162-6.162-6.162zM12 16c-2.21 0-4-1.79-4-4s1.79-4 4-4 4 1.79 4 4-1.79 4-4 4zm7.846-10.405c0 .795-.646 1.44-1.44 1.44-.795 0-1.44-.646-1.44-1.44 0-.794.646-1.439 1.44-1.439.793-.001 1.44.645 1.44 1.439z43:T498,M12.186 24h-.007c-3.581-.024-6.334-1.205-8.184-3.509C2.35 18.44 1.5 15.586 1.472 12.01v-.017c.03-3.579.879-6.43 2.525-8.482C5.845 1.205 8.6.024 12.18 0h.014c2.746.02 5.043.725 6.826 2.098 1.677 1.29 2.858 3.13 3.509 5.467l-2.04.569c-1.104-3.96-3.898-5.984-8.304-6.015-2.91.022-5.11.936-6.54 2.717C4.307 6.504 3.616 8.914 3.589 12c.027 3.086.718 5.496 2.057 7.164 1.43 1.783 3.631 2.698 6.54 2.717 2.623-.02 4.358-.631 5.8-2.045 1.647-1.613 1.618-3.593 1.09-4.798-.31-.71-.873-1.3-1.634-1.75-.192 1.352-.622 2.446-1.284 3.272-.886 1.102-2.14 1.704-3.73 1.79-1.202.065-2.361-.218-3.259-.801-1.063-.689-1.685-1.74-1.752-2.964-.065-1.19.408-2.285 1.33-3.082.88-.76 2.119-1.207 3.583-1.291a13.853 13.853 0 0 1 3.02.142c-.126-.742-.375-1.332-.75-1.757-.513-.586-1.308-.883-2.359-.89h-.029c-.844 0-1.992.232-2.721 1.32L7.734 7.847c.98-1.454 2.568-2.256 4.478-2.256h.044c3.194.02 5.097 1.975 5.287 5.388.108.046.216.094.321.142 1.49.7 2.58 1.761 3.154 3.07.797 1.82.871 4.79-1.548 7.158-1.85 1.81-4.094 2.628-7.277 2.65Zm1.003-11.69c-.242 0-.487.007-.739.021-1.836.103-2.98.946-2.916 2.143.067 1.256 1.452 1.839 2.784 1.767 1.224-.065 2.818-.543 3.086-3.71a10.5 10.5 0 0 0-2.215-.221z0:["kaKwU2XKs7dewhnoinbd-",[[["",{"children":["blog",{"children":["page",{"children":[["page","21","d"],{"children":["__PAGE__?{\"page\":\"21\"}",{}]}]}]}]},"$undefined","$undefined",true],["",{"children":["blog",{"children":["page",{"children":[["page","21","d"],{"children":["__PAGE__",{},[["$L1",["$","$L2",null,{"posts":[{"title":"Refactoring_UI","date":"2024-01-10T00:00:00.000Z","tags":["前端"],"lastmod":"2024-01-10T00:00:00.000Z","draft":false,"summary":"这篇文章主要讨论了网页设计的各个方面，包括功能优先、层次结构、布局与间距、文字设计、色彩运用、创造深度感以及图像处理等。文章强调了从功能出发、建立系统化的设计方法、注重视觉层次和可读性、合理使用色彩和阴影来创造深度，以及在细节上精益求精的重要性。最后，文章鼓励设计师跳出框架思维，创造性地解决设计问题。","layout":"PostSimple","type":"Blog","readingTime":{"text":"21 min read","minutes":20.11,"time":1206600,"words":4022},"slug":"前端/2024-01-10-Refactoring_UI","path":"blog/前端/2024-01-10-Refactoring_UI","filePath":"blog/前端/2024-01-10-Refactoring_UI.mdx","toc":[{"value":"开始","url":"#开始-1","depth":2},{"value":"首先看重功能","url":"#首先看重功能-1","depth":3},{"value":"不要纠结细节在开始的时候","url":"#不要纠结细节在开始的时候-1","depth":3},{"value":"不要过度投资","url":"#不要过度投资-1","depth":3},{"value":"个性化","url":"#个性化-1","depth":3},{"value":"限制你的选择","url":"#限制你的选择-1","depth":3},{"value":"提前定义系统","url":"#提前定义系统-1","depth":3},{"value":"Hierarchy is Everything","url":"#hierarchy-is-everything-1","depth":2},{"value":"大小不是一切","url":"#大小不是一切-1","depth":3},{"value":"标签是最后的方式","url":"#标签是最后的方式-1","depth":3},{"value":"语义是次要的","url":"#语义是次要的-1","depth":3},{"value":"Layout and Spacing","url":"#layout-and-spacing-1","depth":2},{"value":"建立间距和尺寸系统","url":"#建立间距和尺寸系统-1","depth":3},{"value":"定义系统","url":"#定义系统-1","depth":3},{"value":"不需要填满整个屏幕","url":"#不需要填满整个屏幕-1","depth":3},{"value":"Grids被高估了","url":"#grids被高估了-1","depth":3},{"value":"相对尺寸不可缩放","url":"#相对尺寸不可缩放-1","depth":3},{"value":"避免使用不明确的spacing空间","url":"#避免使用不明确的spacing空间-1","depth":3},{"value":"Designing Text","url":"#designing-text-1","depth":2},{"value":"建立一个 text scale","url":"#建立一个-text-scale-1","depth":3},{"value":"使用好的字体","url":"#使用好的字体-1","depth":3},{"value":"保持line length 适中","url":"#保持line-length-适中-1","depth":3},{"value":"并非每一个链接都需要颜色","url":"#并非每一个链接都需要颜色-1","depth":3},{"value":"以可读性为重点进行调整","url":"#以可读性为重点进行调整-1","depth":3},{"value":"有效使用字母间距 letter spacing","url":"#有效使用字母间距-letter-spacing-1","depth":3},{"value":"Color","url":"#color-1","depth":2},{"value":"放弃hex 使用HSL","url":"#放弃hex-使用hsl-1","depth":3},{"value":"我们需要更多的颜色","url":"#我们需要更多的颜色-1","depth":3},{"value":"事先定义色调","url":"#事先定义色调-1","depth":3},{"value":"不要让亮度lightness kill 饱和度saturation","url":"#不要让亮度lightness-kill-饱和度saturation-1","depth":3},{"value":"灰色不一定是灰色","url":"#灰色不一定是灰色-1","depth":3},{"value":"不要仅仅依赖颜色","url":"#不要仅仅依赖颜色-1","depth":3},{"value":"Creating Depth","url":"#creating-depth-1","depth":2},{"value":"使用阴影来传达高度感觉","url":"#使用阴影来传达高度感觉-1","depth":3},{"value":"建立系统","url":"#建立系统-1","depth":3},{"value":"双重阴影","url":"#双重阴影-1","depth":3},{"value":"即使是扁平设计也有深度","url":"#即使是扁平设计也有深度-1","depth":3},{"value":"Images","url":"#images-1","depth":2},{"value":"背景图片","url":"#背景图片-1","depth":3},{"value":"一切都有其预定的尺寸","url":"#一切都有其预定的尺寸-1","depth":3},{"value":"小心用户上传的图片","url":"#小心用户上传的图片-1","depth":3},{"value":"Finishing Touches","url":"#finishing-touches-1","depth":2},{"value":"用色彩点缀边框","url":"#用色彩点缀边框-1","depth":3},{"value":"装饰背景","url":"#装饰背景-1","depth":3},{"value":"不要忽视空状态","url":"#不要忽视空状态-1","depth":3},{"value":"使用更少的边框","url":"#使用更少的边框-1","depth":3},{"value":"跳出框架思维","url":"#跳出框架思维-1","depth":3},{"value":"Leveling UP","url":"#leveling-up-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Refactoring_UI","datePublished":"2024-01-10T00:00:00.000Z","dateModified":"2024-01-10T00:00:00.000Z","description":"这篇文章主要讨论了网页设计的各个方面，包括功能优先、层次结构、布局与间距、文字设计、色彩运用、创造深度感以及图像处理等。文章强调了从功能出发、建立系统化的设计方法、注重视觉层次和可读性、合理使用色彩和阴影来创造深度，以及在细节上精益求精的重要性。最后，文章鼓励设计师跳出框架思维，创造性地解决设计问题。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/前端/2024-01-10-Refactoring_UI"}},{"title":"python_多进程为什么慢","date":"2023-12-16T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-12-16T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了使用Python进行并行处理以提高质数计算效率的几种方法。文章比较了串行处理、简单并行处理、数据分块并行处理以及使用multiprocessing.Pool的并行处理方法，并分析了各种方法的性能差异。最终结论是，对于大规模数据，合适的并行处理方法可以显著提高计算效率。","layout":"PostSimple","type":"Blog","readingTime":{"text":"3 min read","minutes":2.65,"time":159000,"words":530},"slug":"Tech/2023-12-16-python_多进程为什么慢","path":"blog/Tech/2023-12-16-python_多进程为什么慢","filePath":"blog/Tech/2023-12-16-python_多进程为什么慢.mdx","toc":[{"value":"v1 代码 -串行处理","url":"#v1-代码--串行处理-1","depth":2},{"value":"v2代码 -并行处理","url":"#v2代码--并行处理-1","depth":2},{"value":"v3 代码-等份切分数据","url":"#v3-代码-等份切分数据-1","depth":2},{"value":"v4代码 -使用pool map function","url":"#v4代码--使用pool-map-function-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"python_多进程为什么慢","datePublished":"2023-12-16T00:00:00.000Z","dateModified":"2023-12-16T00:00:00.000Z","description":"这篇文章主要介绍了使用Python进行并行处理以提高质数计算效率的几种方法。文章比较了串行处理、简单并行处理、数据分块并行处理以及使用multiprocessing.Pool的并行处理方法，并分析了各种方法的性能差异。最终结论是，对于大规模数据，合适的并行处理方法可以显著提高计算效率。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-12-16-python_多进程为什么慢"}},{"title":"rollup","date":"2023-12-03T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-12-03T00:00:00.000Z","draft":false,"summary":"rollup是一个小巧的JavaScript模块打包工具，适合用于库应用的构建。它基于ES6模块，可以将小块代码编译成大块复杂的代码，有效减少文件请求大小。rollup支持多种打包格式，包括amd、cjs、es、iife和umd，可以根据不同需求选择合适的格式。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.825,"time":109500,"words":365},"slug":"Tech/2023-12-03-rollup","path":"blog/Tech/2023-12-03-rollup","filePath":"blog/Tech/2023-12-03-rollup.mdx","toc":[{"value":"rollup","url":"#rollup-1","depth":1},{"value":"打包格式","url":"#打包格式-1","depth":2},{"value":"操作","url":"#操作-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"rollup","datePublished":"2023-12-03T00:00:00.000Z","dateModified":"2023-12-03T00:00:00.000Z","description":"rollup是一个小巧的JavaScript模块打包工具，适合用于库应用的构建。它基于ES6模块，可以将小块代码编译成大块复杂的代码，有效减少文件请求大小。rollup支持多种打包格式，包括amd、cjs、es、iife和umd，可以根据不同需求选择合适的格式。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-12-03-rollup"}},{"title":"微信红包高性能复杂度分析","date":"2023-11-15T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-11-15T00:00:00.000Z","draft":false,"summary":"这篇文章主要讨论了微信红包系统的高性能复杂度分析和成本约束。文章介绍了2014年微信红包的使用数据，并详细分析了发红包、抢红包和看红包的架构设计。同时，文章还探讨了整体架构的设计思路，以及如何在保证高性能的同时进行成本优化。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.44,"time":86400,"words":288},"slug":"Tech/2023-11-15-微信红包高性能复杂度分析","path":"blog/Tech/2023-11-15-微信红包高性能复杂度分析","filePath":"blog/Tech/2023-11-15-微信红包高性能复杂度分析.mdx","toc":[{"value":"2014年的微信红包","url":"#2014年的微信红包-1","depth":2},{"value":"成本对高性能方案的约束","url":"#成本对高性能方案的约束-1","depth":2},{"value":"发红包","url":"#发红包-1","depth":3},{"value":"抢红包","url":"#抢红包-1","depth":3},{"value":"看红包","url":"#看红包-1","depth":3},{"value":"整体架构","url":"#整体架构-1","depth":2},{"value":"红包整体架构图-单机房","url":"#红包整体架构图-单机房-1","depth":2},{"value":"更高一级的架构决策","url":"#更高一级的架构决策-1","depth":3},{"value":"成本优化思路","url":"#成本优化思路-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"微信红包高性能复杂度分析","datePublished":"2023-11-15T00:00:00.000Z","dateModified":"2023-11-15T00:00:00.000Z","description":"这篇文章主要讨论了微信红包系统的高性能复杂度分析和成本约束。文章介绍了2014年微信红包的使用数据，并详细分析了发红包、抢红包和看红包的架构设计。同时，文章还探讨了整体架构的设计思路，以及如何在保证高性能的同时进行成本优化。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-11-15-微信红包高性能复杂度分析"}},{"title":"如何全面提升架构设计的质量","date":"2023-11-14T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-11-14T00:00:00.000Z","draft":false,"summary":"这篇文章讨论了软件架构设计中的几个关键方面,包括低成本、安全性、可测试性、可维护性和可观测性。文章强调了在设计架构时需要权衡各种因素,如成本与性能之间的平衡,以及安全性的不同层面。同时,文章指出可观测性是可测试性和可维护性的基础,对于设计良好的架构至关重要。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.96,"time":57600,"words":192},"slug":"Tech/2023-11-14-如何全面提升架构设计的质量","path":"blog/Tech/2023-11-14-如何全面提升架构设计的质量","filePath":"blog/Tech/2023-11-14-如何全面提升架构设计的质量.mdx","toc":[{"value":"低成本","url":"#低成本-1","depth":2},{"value":"安全性","url":"#安全性-1","depth":2},{"value":"可测试性，可维护性，可观测性","url":"#可测试性可维护性可观测性-1","depth":2},{"value":"可测试性","url":"#可测试性-1","depth":3},{"value":"可维护性","url":"#可维护性-1","depth":3},{"value":"可观测性","url":"#可观测性-1","depth":3},{"value":"如何设计更好的架构","url":"#如何设计更好的架构-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"如何全面提升架构设计的质量","datePublished":"2023-11-14T00:00:00.000Z","dateModified":"2023-11-14T00:00:00.000Z","description":"这篇文章讨论了软件架构设计中的几个关键方面,包括低成本、安全性、可测试性、可维护性和可观测性。文章强调了在设计架构时需要权衡各种因素,如成本与性能之间的平衡,以及安全性的不同层面。同时,文章指出可观测性是可测试性和可维护性的基础,对于设计良好的架构至关重要。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-11-14-如何全面提升架构设计的质量"}},{"title":"架构基础知识","date":"2023-11-14T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-11-14T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了软件架构设计的概念、原则和方法。文章强调了架构设计应遵循合适、简单和演化三大原则,并通过具体案例说明了如何应用这些原则进行实际的架构设计。文章还指出,架构设计应该面向复杂度,根据系统的实际需求和团队能力来选择合适的架构方案,而不是盲目追求高大上的架构。","layout":"PostSimple","type":"Blog","readingTime":{"text":"9 min read","minutes":8.86,"time":531600,"words":1772},"slug":"Tech/2023-11-14-架构基础知识","path":"blog/Tech/2023-11-14-架构基础知识","filePath":"blog/Tech/2023-11-14-架构基础知识.mdx","toc":[{"value":"什么是架构","url":"#什么是架构-1","depth":2},{"value":"软件架构4R架构：","url":"#软件架构4r架构-1","depth":3},{"value":"如何画架构图","url":"#如何画架构图-1","depth":2},{"value":"4+1架构视图","url":"#41架构视图-1","depth":3},{"value":"常见架构图介绍和画法","url":"#常见架构图介绍和画法-1","depth":3},{"value":"客户端架构、前端架构","url":"#客户端架构前端架构-1","depth":4},{"value":"系统架构","url":"#系统架构-1","depth":4},{"value":"应用架构","url":"#应用架构-1","depth":4},{"value":"部署架构","url":"#部署架构-1","depth":4},{"value":"系统序列图","url":"#系统序列图-1","depth":3},{"value":"什么是面向复杂度的架构设计","url":"#什么是面向复杂度的架构设计-1","depth":2},{"value":"常见的架构设计方法论","url":"#常见的架构设计方法论-1","depth":3},{"value":"面向复杂度架构设计","url":"#面向复杂度架构设计-1","depth":3},{"value":"架构设计环","url":"#架构设计环-2","depth":4},{"value":"如何做好架构设计","url":"#如何做好架构设计-1","depth":2},{"value":"架构设计三原则","url":"#架构设计三原则-1","depth":3},{"value":"合适原则","url":"#合适原则-1","depth":4},{"value":"简单原则","url":"#简单原则-1","depth":4},{"value":"演化原则","url":"#演化原则-1","depth":4},{"value":"例子","url":"#例子-3","depth":3},{"value":"三网合一，","url":"#三网合一-1","depth":4},{"value":"松鼠厂亿级用户平台","url":"#松鼠厂亿级用户平台-1","depth":4},{"value":"架构设计原则具体应用","url":"#架构设计原则具体应用-1","depth":3},{"value":"架构设计环","url":"#架构设计环-3","depth":3},{"value":"架构设计原则常见判断维度","url":"#架构设计原则常见判断维度-1","depth":3},{"value":"实战-外包学生管理系统","url":"#实战-外包学生管理系统-1","depth":2},{"value":"需求介绍","url":"#需求介绍-1","depth":3},{"value":"学生管理","url":"#学生管理-1","depth":4},{"value":"课程管理","url":"#课程管理-1","depth":4},{"value":"考试管理","url":"#考试管理-1","depth":4},{"value":"权限管理","url":"#权限管理-1","depth":4},{"value":"架构设计分析","url":"#架构设计分析-1","depth":3},{"value":"判断复杂度","url":"#判断复杂度-2","depth":4},{"value":"备选方案1","url":"#备选方案1-1","depth":4},{"value":"备选方案2","url":"#备选方案2-1","depth":4},{"value":"备选方案3","url":"#备选方案3-1","depth":4},{"value":"实战-学生云平台管理","url":"#实战-学生云平台管理-1","depth":2},{"value":"需求背景","url":"#需求背景-1","depth":3},{"value":"系统需求","url":"#系统需求-1","depth":3},{"value":"判断复杂度","url":"#判断复杂度-3","depth":3},{"value":"备选方案1-单机房数据隔离","url":"#备选方案1-单机房数据隔离-1","depth":4},{"value":"双机房数据隔离","url":"#双机房数据隔离-1","depth":4},{"value":"双机房数据服务双隔离","url":"#双机房数据服务双隔离-1","depth":4}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"架构基础知识","datePublished":"2023-11-14T00:00:00.000Z","dateModified":"2023-11-14T00:00:00.000Z","description":"这篇文章主要介绍了软件架构设计的概念、原则和方法。文章强调了架构设计应遵循合适、简单和演化三大原则,并通过具体案例说明了如何应用这些原则进行实际的架构设计。文章还指出,架构设计应该面向复杂度,根据系统的实际需求和团队能力来选择合适的架构方案,而不是盲目追求高大上的架构。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-11-14-架构基础知识"}},{"title":"架构设计复杂度模型","date":"2023-11-14T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-11-14T00:00:00.000Z","draft":false,"summary":"这篇文章主要讨论了软件架构设计中的三个关键方面:可扩展性、高性能和高可用性。文章介绍了通过拆分和复用来提高系统的可扩展性,通过单机优化和集群设计来实现高性能,以及通过冗余和复制等方式来保证系统的高可用性。文章还提出了\"鸡蛋篮子\"理论,强调了在架构设计中合理分配和分解任务的重要性。","layout":"PostSimple","type":"Blog","readingTime":{"text":"3 min read","minutes":2.525,"time":151500,"words":505},"slug":"Tech/2023-11-14-架构设计复杂度模型","path":"blog/Tech/2023-11-14-架构设计复杂度模型","filePath":"blog/Tech/2023-11-14-架构设计复杂度模型.mdx","toc":[{"value":"可扩展","url":"#可扩展-1","depth":3},{"value":"拆分法则","url":"#拆分法则-1","depth":4},{"value":"内部复杂度，外部复杂度 平衡原则","url":"#内部复杂度外部复杂度-平衡原则-1","depth":4},{"value":"封装","url":"#封装-1","depth":4},{"value":"预测的艺术","url":"#预测的艺术-1","depth":5},{"value":"封装的技巧","url":"#封装的技巧-1","depth":5},{"value":"高性能","url":"#高性能-1","depth":3},{"value":"单机高性能复杂度分析","url":"#单机高性能复杂度分析-1","depth":4},{"value":"集群高性能设计","url":"#集群高性能设计-1","depth":4},{"value":"鸡蛋蓝字理论-叠加法则","url":"#鸡蛋蓝字理论-叠加法则-1","depth":5},{"value":"任务分配","url":"#任务分配-1","depth":6},{"value":"任务分解","url":"#任务分解-1","depth":6},{"value":"高可用","url":"#高可用-1","depth":3},{"value":"鸡蛋篮子第三法则 冗余法则","url":"#鸡蛋篮子第三法则-冗余法则-1","depth":4},{"value":"计算高可用","url":"#计算高可用-1","depth":5},{"value":"存储高可用","url":"#存储高可用-1","depth":5}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"架构设计复杂度模型","datePublished":"2023-11-14T00:00:00.000Z","dateModified":"2023-11-14T00:00:00.000Z","description":"这篇文章主要讨论了软件架构设计中的三个关键方面:可扩展性、高性能和高可用性。文章介绍了通过拆分和复用来提高系统的可扩展性,通过单机优化和集群设计来实现高性能,以及通过冗余和复制等方式来保证系统的高可用性。文章还提出了\"鸡蛋篮子\"理论,强调了在架构设计中合理分配和分解任务的重要性。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-11-14-架构设计复杂度模型"}},{"title":"sql_mysql_常用操作","date":"2023-10-20T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-10-20T00:00:00.000Z","draft":false,"summary":"MySQL数据库的基本操作和使用方法","layout":"PostSimple","type":"Blog","readingTime":{"text":"13 min read","minutes":12.1,"time":726000,"words":2420},"slug":"Tech/2023-10-20-sql_mysql_常用操作","path":"blog/Tech/2023-10-20-sql_mysql_常用操作","filePath":"blog/Tech/2023-10-20-sql_mysql_常用操作.mdx","toc":[{"value":"Database 操作","url":"#database-操作-1","depth":2},{"value":"table","url":"#table-1","depth":2},{"value":"数据插入","url":"#数据插入-1","depth":2},{"value":"修改表","url":"#修改表-1","depth":2},{"value":"CRUD","url":"#crud-1","depth":2},{"value":"字符串操作","url":"#字符串操作-1","depth":2},{"value":"对select数据进行改造","url":"#对select数据进行改造-1","depth":2},{"value":"分组，聚合","url":"#分组聚合-1","depth":2},{"value":"数据类型","url":"#数据类型-1","depth":2},{"value":"数值类型","url":"#数值类型-1","depth":3},{"value":"integer","url":"#integer-1","depth":4},{"value":"Fixed point types","url":"#fixed-point-types-1","depth":4},{"value":"floating-point","url":"#floating-point-1","depth":4},{"value":"Bit","url":"#bit-1","depth":4},{"value":"日期和时间类型","url":"#日期和时间类型-1","depth":3},{"value":"DATE","url":"#date-1","depth":4},{"value":"TIME","url":"#time-1","depth":4},{"value":"YEAR","url":"#year-1","depth":4},{"value":"DATETIME","url":"#datetime-1","depth":4},{"value":"TIMESTAMP","url":"#timestamp-1","depth":4},{"value":"字符类型","url":"#字符类型-1","depth":3},{"value":"CAHR VARCHAR","url":"#cahr-varchar-1","depth":4},{"value":"BINARY VARBINARH","url":"#binary-varbinarh-1","depth":4},{"value":"BLOB TEXT","url":"#blob-text-1","depth":4},{"value":"ENUM","url":"#enum-1","depth":4},{"value":"SET","url":"#set-1","depth":4},{"value":"逻辑操作符","url":"#逻辑操作符-1","depth":2},{"value":"内置函数","url":"#内置函数-1","depth":2},{"value":"关系","url":"#关系-1","depth":2},{"value":"一对多","url":"#一对多-1","depth":3},{"value":"多对多","url":"#多对多-1","depth":3},{"value":"mysql编码","url":"#mysql编码-1","depth":2},{"value":"Python sqlalchemy","url":"#python-sqlalchemy-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"sql_mysql_常用操作","datePublished":"2023-10-20T00:00:00.000Z","dateModified":"2023-10-20T00:00:00.000Z","description":"MySQL数据库的基本操作和使用方法","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-10-20-sql_mysql_常用操作"}},{"title":"JS_基础2","date":"2023-10-05T00:00:00.000Z","tags":["前端"],"lastmod":"2023-10-05T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了ES6及之后版本的一些新特性,包括let/const声明、模板字符串、对象和数组的新语法等。同时还讨论了浏览器的进程模型、渲染主线程的工作原理,以及JavaScript中的异步编程、Promise规范和async/await语法。","layout":"PostSimple","type":"Blog","readingTime":{"text":"12 min read","minutes":11.155,"time":669300,"words":2231},"slug":"前端/2023-10-05-JS_基础2","path":"blog/前端/2023-10-05-JS_基础2","filePath":"blog/前端/2023-10-05-JS_基础2.mdx","toc":[{"value":"ES","url":"#es-1","depth":2},{"value":"数组","url":"#数组-3","depth":2},{"value":"对象","url":"#对象-5","depth":2},{"value":"浏览器的进程模型","url":"#浏览器的进程模型-1","depth":2},{"value":"进程","url":"#进程-1","depth":3},{"value":"线程","url":"#线程-1","depth":3},{"value":"浏览器","url":"#浏览器-1","depth":3},{"value":"渲染主线程","url":"#渲染主线程-1","depth":2},{"value":"异步","url":"#异步-1","depth":2},{"value":"消息队列优先级","url":"#消息队列优先级-1","depth":3},{"value":"Promise规范","url":"#promise规范-1","depth":2},{"value":"promise链式处理","url":"#promise链式处理-1","depth":2},{"value":"promise静态方法","url":"#promise静态方法-1","depth":2},{"value":"async await","url":"#async-await-1","depth":2},{"value":"函数执行","url":"#函数执行-1","depth":2},{"value":"闭包-closure","url":"#闭包-closure-1","depth":3},{"value":"执行上下文","url":"#执行上下文-1","depth":3},{"value":"语句","url":"#语句-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"JS_基础2","datePublished":"2023-10-05T00:00:00.000Z","dateModified":"2023-10-05T00:00:00.000Z","description":"这篇文章主要介绍了ES6及之后版本的一些新特性,包括let/const声明、模板字符串、对象和数组的新语法等。同时还讨论了浏览器的进程模型、渲染主线程的工作原理,以及JavaScript中的异步编程、Promise规范和async/await语法。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/前端/2023-10-05-JS_基础2"}},{"title":"css样式","date":"2023-10-05T00:00:00.000Z","tags":["前端"],"lastmod":"2023-10-05T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了CSS3在不同浏览器中的实现和前缀使用情况。文章提到了浏览器厂商前缀的使用，如-webkit、-moz等，以及CSS预处理器和后处理器的概念。此外，文章还简要介绍了一些常用的CSS属性和技巧，如盒模型、浮动和文字居中等。","layout":"PostSimple","type":"Blog","readingTime":{"text":"4 min read","minutes":3.74,"time":224400,"words":748},"slug":"前端/2023-10-05-css样式","path":"blog/前端/2023-10-05-css样式","filePath":"blog/前端/2023-10-05-css样式.mdx","toc":[{"value":"介绍","url":"#介绍-4","depth":2},{"value":"小米商城css","url":"#小米商城css-4","depth":2},{"value":"head 部分","url":"#head-部分-4","depth":2},{"value":"common css","url":"#common-css-4","depth":2},{"value":"a标签处理","url":"#a标签处理-4","depth":3},{"value":"html","url":"#html-4","depth":3},{"value":"浮动","url":"#浮动-4","depth":3},{"value":"文字垂直居中","url":"#文字垂直居中-4","depth":3}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"css样式","datePublished":"2023-10-05T00:00:00.000Z","dateModified":"2023-10-05T00:00:00.000Z","description":"这篇文章主要介绍了CSS3在不同浏览器中的实现和前缀使用情况。文章提到了浏览器厂商前缀的使用，如-webkit、-moz等，以及CSS预处理器和后处理器的概念。此外，文章还简要介绍了一些常用的CSS属性和技巧，如盒模型、浮动和文字居中等。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/前端/2023-10-05-css样式"}},{"title":"前端工程化","date":"2023-10-05T00:00:00.000Z","tags":["前端"],"lastmod":"2023-10-05T00:00:00.000Z","draft":false,"summary":"前端工程化的概念和实践。文章讨论了软件工程学在解决软件开发问题中的应用,并详细介绍了模块化、包管理、Monorepo、Less预处理器和Webpack等前端工程化的关键技术和工具。文章强调了这些技术在提高开发效率、代码质量和项目可维护性方面的重要作用。","layout":"PostSimple","type":"Blog","readingTime":{"text":"8 min read","minutes":7.775,"time":466500,"words":1555},"slug":"前端/2023-10-05-前端工程化","path":"blog/前端/2023-10-05-前端工程化","filePath":"blog/前端/2023-10-05-前端工程化.mdx","toc":[{"value":"模块化","url":"#模块化-1","depth":2},{"value":"Common JS","url":"#common-js-1","depth":3},{"value":"ES Module","url":"#es-module-1","depth":3},{"value":"几种模块化规范对比","url":"#几种模块化规范对比-1","depth":3},{"value":"包管理 npm","url":"#包管理-npm-1","depth":2},{"value":"初始化","url":"#初始化-1","depth":4},{"value":"安装普通依赖(最常见)","url":"#安装普通依赖最常见-1","depth":5},{"value":"安装开发依赖","url":"#安装开发依赖-1","depth":5},{"value":"全局安装","url":"#全局安装-1","depth":4},{"value":"卸载 更新","url":"#卸载-更新-1","depth":4},{"value":"NVM","url":"#nvm-1","depth":2},{"value":"Monorepo","url":"#monorepo-1","depth":2},{"value":"pnpm实现Monorepo","url":"#pnpm实现monorepo-1","depth":3},{"value":"自己的脚手架","url":"#自己的脚手架-1","depth":2},{"value":"Less","url":"#less-1","depth":2},{"value":"webpack","url":"#webpack-1","depth":2},{"value":"页面模板","url":"#页面模板-1","depth":3},{"value":"public目录","url":"#public目录-1","depth":2},{"value":"资源路径","url":"#资源路径-1","depth":3},{"value":"缺省的文件和后缀名","url":"#缺省的文件和后缀名-1","depth":3},{"value":"路径别名","url":"#路径别名-1","depth":3},{"value":"css module","url":"#css-module-1","depth":3}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"前端工程化","datePublished":"2023-10-05T00:00:00.000Z","dateModified":"2023-10-05T00:00:00.000Z","description":"前端工程化的概念和实践。文章讨论了软件工程学在解决软件开发问题中的应用,并详细介绍了模块化、包管理、Monorepo、Less预处理器和Webpack等前端工程化的关键技术和工具。文章强调了这些技术在提高开发效率、代码质量和项目可维护性方面的重要作用。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/前端/2023-10-05-前端工程化"}},{"title":"Git_基础","date":"2023-09-28T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-09-28T00:00:00.000Z","draft":false,"summary":"介绍了Git的基本概念和常用操作。","layout":"PostSimple","type":"Blog","readingTime":{"text":"17 min read","minutes":16.04,"time":962400,"words":3208},"slug":"Tech/2023-09-28-Git_基础","path":"blog/Tech/2023-09-28-Git_基础","filePath":"blog/Tech/2023-09-28-Git_基础.mdx","toc":[{"value":"git config","url":"#git-config-1","depth":2},{"value":"git init","url":"#git-init-1","depth":2},{"value":"本地初始化","url":"#本地初始化-1","depth":3},{"value":".git/config文件","url":"#gitconfig文件-1","depth":4},{"value":"git add","url":"#git-add-1","depth":2},{"value":"object 对象","url":"#object-对象-1","depth":3},{"value":"index","url":"#index-1","depth":3},{"value":"git commit","url":"#git-commit-1","depth":2},{"value":"第一次提交","url":"#第一次提交-1","depth":3},{"value":"第二次提交","url":"#第二次提交-1","depth":3},{"value":"第三次提交","url":"#第三次提交-1","depth":3},{"value":"git文件状态","url":"#git文件状态-1","depth":2},{"value":"Branches","url":"#branches-1","depth":2},{"value":"基础命令","url":"#基础命令-1","depth":3},{"value":"git diff","url":"#git-diff-1","depth":2},{"value":"git merge","url":"#git-merge-1","depth":2},{"value":"fast forward","url":"#fast-forward-1","depth":3},{"value":"3 way merge","url":"#3-way-merge-1","depth":3},{"value":"远程仓库","url":"#远程仓库-1","depth":2},{"value":"pull request","url":"#pull-request-1","depth":2},{"value":"Git ssh Key","url":"#git-ssh-key-1","depth":2},{"value":"git tags","url":"#git-tags-1","depth":2},{"value":"git hooks","url":"#git-hooks-1","depth":2},{"value":"git reset","url":"#git-reset-1","depth":2},{"value":"一些命令行技巧","url":"#一些命令行技巧-1","depth":2},{"value":"git object 压缩","url":"#git-object-压缩-1","depth":3},{"value":"Git stash","url":"#git-stash-1","depth":3},{"value":"git 垃圾对象清理","url":"#git-垃圾对象清理-1","depth":3},{"value":"clone大仓库","url":"#clone大仓库-1","depth":3},{"value":"git log","url":"#git-log-1","depth":2},{"value":"git实践","url":"#git实践-1","depth":2},{"value":"commit message","url":"#commit-message-1","depth":3},{"value":".gitignore","url":"#gitignore-1","depth":3},{"value":"release 分支和tag","url":"#release-分支和tag-1","depth":3},{"value":"修改最后一次commit","url":"#修改最后一次commit-1","depth":3},{"value":"git worktree","url":"#git-worktree-1","depth":3},{"value":"git submodule","url":"#git-submodule-1","depth":2},{"value":"git cherry-pick","url":"#git-cherry-pick-1","depth":2},{"value":"git patch & apply","url":"#git-patch--apply-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Git_基础","datePublished":"2023-09-28T00:00:00.000Z","dateModified":"2023-09-28T00:00:00.000Z","description":"介绍了Git的基本概念和常用操作。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-09-28-Git_基础"}},{"title":"JS基础","date":"2023-09-18T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-09-18T00:00:00.000Z","draft":false,"summary":"JavaScript的一些基础知识和概念。","layout":"PostSimple","type":"Blog","readingTime":{"text":"23 min read","minutes":22.63,"time":1357800,"words":4526},"slug":"Tech/2023-09-18-JS基础","path":"blog/Tech/2023-09-18-JS基础","filePath":"blog/Tech/2023-09-18-JS基础.mdx","toc":[{"value":"数据表达","url":"#数据表达-5","depth":2},{"value":"对象","url":"#对象-10","depth":3},{"value":"对象的属性","url":"#对象的属性-5","depth":4},{"value":"对象分类","url":"#对象分类-5","depth":4},{"value":"数据的运算","url":"#数据的运算-5","depth":2},{"value":"运算符","url":"#运算符-5","depth":3},{"value":"算术（数学）运算","url":"#算术数学运算-5","depth":4},{"value":"字符串拼接","url":"#字符串拼接-5","depth":4},{"value":"赋值运算","url":"#赋值运算-5","depth":4},{"value":"比较运算符","url":"#比较运算符-5","depth":4},{"value":"逻辑运算","url":"#逻辑运算-5","depth":4},{"value":"布尔判定","url":"#布尔判定-5","depth":3},{"value":"类型的隐式转换","url":"#类型的隐式转换-5","depth":3},{"value":"数据的作用域","url":"#数据的作用域-5","depth":2},{"value":"全局对象","url":"#全局对象-5","depth":2},{"value":"构造函数","url":"#构造函数-5","depth":2},{"value":"原型","url":"#原型-5","depth":2},{"value":"this","url":"#this-5","depth":2},{"value":"原型链","url":"#原型链-5","depth":2},{"value":"继承","url":"#继承-5","depth":2},{"value":"标准库","url":"#标准库-5","depth":2},{"value":"String Number","url":"#string-number-5","depth":3},{"value":"数学","url":"#数学-5","depth":3},{"value":"日期","url":"#日期-5","depth":3},{"value":"数组","url":"#数组-5","depth":3},{"value":"对象","url":"#对象-11","depth":3},{"value":"函数","url":"#函数-5","depth":3},{"value":"WebAPI","url":"#webapi-5","depth":2},{"value":"BOM","url":"#bom-5","depth":3},{"value":"DOM","url":"#dom-5","depth":3},{"value":"DOM属性","url":"#dom属性-5","depth":3},{"value":"Dom内容","url":"#dom内容-5","depth":3},{"value":"DOM样式","url":"#dom样式-5","depth":3},{"value":"事件","url":"#事件-5","depth":3},{"value":"注册事件","url":"#注册事件-5","depth":4},{"value":"事件处理函数","url":"#事件处理函数-5","depth":4},{"value":"事件默认行为","url":"#事件默认行为-5","depth":3},{"value":"事件传播机制","url":"#事件传播机制-5","depth":3},{"value":"函数防抖","url":"#函数防抖-5","depth":2},{"value":"异常","url":"#异常-5","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"JS基础","datePublished":"2023-09-18T00:00:00.000Z","dateModified":"2023-09-18T00:00:00.000Z","description":"JavaScript的一些基础知识和概念。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-09-18-JS基础"}},{"title":"golang-基础-1","date":"2023-09-18T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-09-18T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了Go语言的基础语法和特性。文章涵盖了main函数、包声明、字符串处理、基本数据类型、变量声明、方法定义、fmt格式化输出、数组和切片的使用，以及控制结构如for循环、if-else语句和switch语句。文章强调了Go语言的一些独特特性，如rune类型、多返回值函数和切片操作。","layout":"PostSimple","type":"Blog","readingTime":{"text":"9 min read","minutes":8.14,"time":488400,"words":1628},"slug":"Tech/2023-09-18-golang-基础-1","path":"blog/Tech/2023-09-18-golang-基础-1","filePath":"blog/Tech/2023-09-18-golang-基础-1.mdx","toc":[{"value":"main函数","url":"#main函数-1","depth":2},{"value":"String 和基础类型","url":"#string-和基础类型-1","depth":2},{"value":"rune类型","url":"#rune类型-1","depth":3},{"value":"基础类型","url":"#基础类型-1","depth":3},{"value":"变量声明","url":"#变量声明-1","depth":2},{"value":"方法","url":"#方法-3","depth":2},{"value":"fmt格式化输出","url":"#fmt格式化输出-1","depth":2},{"value":"数组和切片","url":"#数组和切片-1","depth":2},{"value":"for","url":"#for-1","depth":2},{"value":"if else","url":"#if-else-1","depth":2},{"value":"switch","url":"#switch-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"golang-基础-1","datePublished":"2023-09-18T00:00:00.000Z","dateModified":"2023-09-18T00:00:00.000Z","description":"这篇文章主要介绍了Go语言的基础语法和特性。文章涵盖了main函数、包声明、字符串处理、基本数据类型、变量声明、方法定义、fmt格式化输出、数组和切片的使用，以及控制结构如for循环、if-else语句和switch语句。文章强调了Go语言的一些独特特性，如rune类型、多返回值函数和切片操作。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-09-18-golang-基础-1"}},{"title":"Driver_CUDA_CUDNN_TensorRT关系","date":"2023-09-11T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-09-11T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了CUDA、CUDNN和TensorRT之间的关系，以及如何选择和安装这些组件的版本。文章指出CUDA版本通常与新一代显卡架构相对应，并建议根据显卡选择合适的CUDA版本。同时，文章还提供了TensorRT的推荐版本以及与CUDA和CUDNN的兼容性信息，并给出了安装过程中的一些注意事项。","layout":"PostSimple","type":"Blog","readingTime":{"text":"3 min read","minutes":2.23,"time":133800,"words":446},"slug":"Tech/2023-09-11-Driver_CUDA_CUDNN_TensorRT关系","path":"blog/Tech/2023-09-11-Driver_CUDA_CUDNN_TensorRT关系","filePath":"blog/Tech/2023-09-11-Driver_CUDA_CUDNN_TensorRT关系.mdx","toc":[{"value":"Driver CUDA CUDNN TensorRT关系","url":"#driver-cuda-cudnn-tensorrt关系-1","depth":2},{"value":"选择版本","url":"#选择版本-1","depth":2},{"value":"安装","url":"#安装-1","depth":2},{"value":"其他安装时候注意的","url":"#其他安装时候注意的-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Driver_CUDA_CUDNN_TensorRT关系","datePublished":"2023-09-11T00:00:00.000Z","dateModified":"2023-09-11T00:00:00.000Z","description":"这篇文章主要介绍了CUDA、CUDNN和TensorRT之间的关系，以及如何选择和安装这些组件的版本。文章指出CUDA版本通常与新一代显卡架构相对应，并建议根据显卡选择合适的CUDA版本。同时，文章还提供了TensorRT的推荐版本以及与CUDA和CUDNN的兼容性信息，并给出了安装过程中的一些注意事项。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-09-11-Driver_CUDA_CUDNN_TensorRT关系"}},{"title":"设计资源网站","date":"2023-08-14T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-08-14T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了多个有用的设计资源网站,包括占位符图片、用户头像、图标和网站配色等。文章还提到了一些CSS相关的资源链接,为网页设计和开发提供了便利工具。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.32,"time":19200,"words":64},"slug":"Ongoing/2023-08-14-设计资源网站","path":"blog/Ongoing/2023-08-14-设计资源网站","filePath":"blog/Ongoing/2023-08-14-设计资源网站.mdx","toc":[{"value":"设计资源网站","url":"#设计资源网站-1","depth":1},{"value":"CSS","url":"#css-1","depth":1}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"设计资源网站","datePublished":"2023-08-14T00:00:00.000Z","dateModified":"2023-08-14T00:00:00.000Z","description":"这篇文章介绍了多个有用的设计资源网站,包括占位符图片、用户头像、图标和网站配色等。文章还提到了一些CSS相关的资源链接,为网页设计和开发提供了便利工具。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Ongoing/2023-08-14-设计资源网站"}},{"title":"马毅-_从人工智能到自主智能_演讲记录","date":"2023-07-02T00:00:00.000Z","tags":["AI"],"lastmod":"2023-07-02T00:00:00.000Z","draft":false,"summary":"人工智能向自主智能的发展趋势。文章回顾了人工智能的历史发展,指出过去十年的AI主要集中在感知和预测方面,而未来的发展方向是从黑盒到白盒、从开环到闭环、从人工到自主和自然。文章还提出了通用计算机制的目标,即适用于所有规模智能系统的机制。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.63,"time":97800,"words":326},"slug":"AI/2023-07-02-马毅-_从人工智能到自主智能_演讲记录","path":"blog/AI/2023-07-02-马毅-_从人工智能到自主智能_演讲记录","filePath":"blog/AI/2023-07-02-马毅-_从人工智能到自主智能_演讲记录.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"马毅-_从人工智能到自主智能_演讲记录","datePublished":"2023-07-02T00:00:00.000Z","dateModified":"2023-07-02T00:00:00.000Z","description":"人工智能向自主智能的发展趋势。文章回顾了人工智能的历史发展,指出过去十年的AI主要集中在感知和预测方面,而未来的发展方向是从黑盒到白盒、从开环到闭环、从人工到自主和自然。文章还提出了通用计算机制的目标,即适用于所有规模智能系统的机制。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-07-02-马毅-_从人工智能到自主智能_演讲记录"}},{"title":"微软中国CTO_韦青_工程师思维-笔记","date":"2023-05-22T00:00:00.000Z","tags":["Life"],"lastmod":"2023-05-22T00:00:00.000Z","draft":false,"summary":"韦青演讲","layout":"PostSimple","type":"Blog","readingTime":{"text":"185 min read","minutes":184.685,"time":11081100,"words":36937},"slug":"Life/2023-05-22-微软中国CTO_韦青_工程师思维-笔记","path":"blog/Life/2023-05-22-微软中国CTO_韦青_工程师思维-笔记","filePath":"blog/Life/2023-05-22-微软中国CTO_韦青_工程师思维-笔记.mdx","toc":[{"value":"01 序章 时代的挑战","url":"#01-序章-时代的挑战-1","depth":2},{"value":"02 上下文 为什么要学习工程师思维","url":"#02-上下文-为什么要学习工程师思维-1","depth":2},{"value":"03 想清楚 如何用第一性原理的方式思考","url":"#03-想清楚-如何用第一性原理的方式思考-1","depth":2},{"value":"04 说明白：报团取暖的时代如何与他人达成共识","url":"#04-说明白报团取暖的时代如何与他人达成共识-1","depth":2},{"value":"05 做得到 如何提高个人人性以面对复杂挑战","url":"#05-做得到-如何提高个人人性以面对复杂挑战-1","depth":2},{"value":"06 基本素质","url":"#06-基本素质-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"微软中国CTO_韦青_工程师思维-笔记","datePublished":"2023-05-22T00:00:00.000Z","dateModified":"2023-05-22T00:00:00.000Z","description":"韦青演讲","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Life/2023-05-22-微软中国CTO_韦青_工程师思维-笔记"}},{"title":"python-视频处理","date":"2023-05-22T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-05-22T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了如何对视频进行笔记，包括解析字幕、提取图片和音频。文章提供了两段Python代码，分别用于将MP4文件转换为MP3音频文件和从视频中提取图片帧。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.1,"time":66000,"words":220},"slug":"Tech/2023-05-22-python-视频处理","path":"blog/Tech/2023-05-22-python-视频处理","filePath":"blog/Tech/2023-05-22-python-视频处理.mdx","toc":[{"value":"mp4转mp3","url":"#mp4转mp3-1","depth":2},{"value":"mp4 提取图片","url":"#mp4-提取图片-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"python-视频处理","datePublished":"2023-05-22T00:00:00.000Z","dateModified":"2023-05-22T00:00:00.000Z","description":"这篇文章介绍了如何对视频进行笔记，包括解析字幕、提取图片和音频。文章提供了两段Python代码，分别用于将MP4文件转换为MP3音频文件和从视频中提取图片帧。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-05-22-python-视频处理"}},{"title":"协同编辑-笔记_01","date":"2023-05-22T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-05-22T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了协同编辑的几种主要技术方法，包括编辑锁、GNU diff-patch、Myer's diff-patch和Operational Transformation (OT)。文章详细解释了OT的工作原理，并根据不同的应用场景和需求，给出了选择协同编辑技术的建议。","layout":"PostSimple","type":"Blog","readingTime":{"text":"3 min read","minutes":2.15,"time":129000,"words":430},"slug":"Tech/2023-05-22-协同编辑-笔记_01","path":"blog/Tech/2023-05-22-协同编辑-笔记_01","filePath":"blog/Tech/2023-05-22-协同编辑-笔记_01.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"协同编辑-笔记_01","datePublished":"2023-05-22T00:00:00.000Z","dateModified":"2023-05-22T00:00:00.000Z","description":"这篇文章介绍了协同编辑的几种主要技术方法，包括编辑锁、GNU diff-patch、Myer's diff-patch和Operational Transformation (OT)。文章详细解释了OT的工作原理，并根据不同的应用场景和需求，给出了选择协同编辑技术的建议。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-05-22-协同编辑-笔记_01"}},{"title":"王坚_天津人工智能主题演讲-2023","date":"2023-05-21T00:00:00.000Z","tags":["Life"],"lastmod":"2023-05-21T00:00:00.000Z","draft":false,"summary":"人工智能的创新过程和历史发展。文章强调创新是一个需要积累的完整系统，并通过GPU技术的演进和人工智能应用的发展来说明这一点。文章还指出，未来人工智能的发展方向将从资源消耗转向提高效率。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.91,"time":114600,"words":382},"slug":"Life/2023-05-21-王坚_天津人工智能主题演讲-2023","path":"blog/Life/2023-05-21-王坚_天津人工智能主题演讲-2023","filePath":"blog/Life/2023-05-21-王坚_天津人工智能主题演讲-2023.mdx","toc":[{"value":"历史发展","url":"#历史发展-1","depth":2},{"value":"创新是一个积累的过程。","url":"#创新是一个积累的过程-1","depth":2},{"value":"资源","url":"#资源-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"王坚_天津人工智能主题演讲-2023","datePublished":"2023-05-21T00:00:00.000Z","dateModified":"2023-05-21T00:00:00.000Z","description":"人工智能的创新过程和历史发展。文章强调创新是一个需要积累的完整系统，并通过GPU技术的演进和人工智能应用的发展来说明这一点。文章还指出，未来人工智能的发展方向将从资源消耗转向提高效率。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Life/2023-05-21-王坚_天津人工智能主题演讲-2023"}},{"title":"让LLM精确计算两数之和","date":"2023-05-14T00:00:00.000Z","tags":["AI"],"lastmod":"2023-05-14T00:00:00.000Z","draft":false,"summary":"如何使用LLM(大型语言模型)来精确计算两个数的和。文章展示了两种方法:使用LLM chain和LLM agent,通过调用Python代码或预定义的工具函数来实现准确计算。此外,文章还简要提到了其他相关工具,如语音转文本、语音合成和图像生成等。","layout":"PostSimple","type":"Blog","readingTime":{"text":"3 min read","minutes":2.845,"time":170700,"words":569},"slug":"AI/2023-05-14-让LLM精确计算两数之和","path":"blog/AI/2023-05-14-让LLM精确计算两数之和","filePath":"blog/AI/2023-05-14-让LLM精确计算两数之和.mdx","toc":[{"value":"LLM chain","url":"#llm-chain-1","depth":2},{"value":"LLM agent","url":"#llm-agent-1","depth":2},{"value":"Other tools","url":"#other-tools-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"让LLM精确计算两数之和","datePublished":"2023-05-14T00:00:00.000Z","dateModified":"2023-05-14T00:00:00.000Z","description":"如何使用LLM(大型语言模型)来精确计算两个数的和。文章展示了两种方法:使用LLM chain和LLM agent,通过调用Python代码或预定义的工具函数来实现准确计算。此外,文章还简要提到了其他相关工具,如语音转文本、语音合成和图像生成等。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-05-14-让LLM精确计算两数之和"}},{"title":"癌症-Note","date":"2023-05-12T00:00:00.000Z","tags":["Life"],"lastmod":"2023-05-12T00:00:00.000Z","draft":false,"summary":"这篇文章主要讨论了癌症的发病率、致癌因素以及治疗方法。文章指出癌症源于基因突变，发病率随年龄增长而上升，并介绍了几种主要的抗癌方法，包括手术、化疗药物和免疫疗法。文章还强调了癌细胞与免疫系统之间的\"密码战\"，以及靶向药物和免疫疗法在这场战斗中的作用。","layout":"PostSimple","type":"Blog","readingTime":{"text":"5 min read","minutes":4.695,"time":281700,"words":939},"slug":"Life/2023-05-12-癌症-Note","path":"blog/Life/2023-05-12-癌症-Note","filePath":"blog/Life/2023-05-12-癌症-Note.mdx","toc":[{"value":"癌症","url":"#癌症-1","depth":2},{"value":"","url":"#-2","depth":3}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"癌症-Note","datePublished":"2023-05-12T00:00:00.000Z","dateModified":"2023-05-12T00:00:00.000Z","description":"这篇文章主要讨论了癌症的发病率、致癌因素以及治疗方法。文章指出癌症源于基因突变，发病率随年龄增长而上升，并介绍了几种主要的抗癌方法，包括手术、化疗药物和免疫疗法。文章还强调了癌细胞与免疫系统之间的\"密码战\"，以及靶向药物和免疫疗法在这场战斗中的作用。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Life/2023-05-12-癌症-Note"}},{"title":"量子力学&相对论&量子计算&芯片-Note","date":"2023-05-12T00:00:00.000Z","tags":["Life"],"lastmod":"2023-05-12T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了现代物理学的两大支柱:量子力学和相对论,以及它们在微观和宏观世界的应用。文章还讨论了量子计算和半导体芯片等前沿技术领域,指出这些技术都是建立在量子力学基础之上的。最后文章提到,虽然中国在芯片领域投入巨大,但与国际巨头相比仍有差距。","layout":"PostSimple","type":"Blog","readingTime":{"text":"10 min read","minutes":9.9,"time":594000,"words":1980},"slug":"Life/2023-05-12-量子力学&相对论&量子计算&芯片-Note","path":"blog/Life/2023-05-12-量子力学&相对论&量子计算&芯片-Note","filePath":"blog/Life/2023-05-12-量子力学&相对论&量子计算&芯片-Note.mdx","toc":[{"value":"量子力学","url":"#量子力学-1","depth":2},{"value":"相对论","url":"#相对论-1","depth":2},{"value":"量子计算","url":"#量子计算-1","depth":2},{"value":"半导体芯片","url":"#半导体芯片-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"量子力学&相对论&量子计算&芯片-Note","datePublished":"2023-05-12T00:00:00.000Z","dateModified":"2023-05-12T00:00:00.000Z","description":"这篇文章主要介绍了现代物理学的两大支柱:量子力学和相对论,以及它们在微观和宏观世界的应用。文章还讨论了量子计算和半导体芯片等前沿技术领域,指出这些技术都是建立在量子力学基础之上的。最后文章提到,虽然中国在芯片领域投入巨大,但与国际巨头相比仍有差距。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Life/2023-05-12-量子力学&相对论&量子计算&芯片-Note"}},{"title":"prompt_example","date":"2023-05-05T00:00:00.000Z","tags":["AI"],"lastmod":"2023-05-05T00:00:00.000Z","draft":false,"summary":"这篇文章总结了ChatGPT提示工程的几种常见技巧和应用场景。主要包括结构化输出、文本摘要、信息提取、情感分析、主题推断以及文本转换(如翻译、语气调整、格式转换等)。这些技巧可以帮助用户更有效地利用ChatGPT完成各种自然语言处理任务。","layout":"PostSimple","type":"Blog","readingTime":{"text":"3 min read","minutes":2.415,"time":144900,"words":483},"slug":"AI/2023-05-05-prompt_example","path":"blog/AI/2023-05-05-prompt_example","filePath":"blog/AI/2023-05-05-prompt_example.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"prompt_example","datePublished":"2023-05-05T00:00:00.000Z","dateModified":"2023-05-05T00:00:00.000Z","description":"这篇文章总结了ChatGPT提示工程的几种常见技巧和应用场景。主要包括结构化输出、文本摘要、信息提取、情感分析、主题推断以及文本转换(如翻译、语气调整、格式转换等)。这些技巧可以帮助用户更有效地利用ChatGPT完成各种自然语言处理任务。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-05-05-prompt_example"}},{"title":"Compare_text_","date":"2023-05-05T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-05-05T00:00:00.000Z","draft":false,"summary":"使用Python的difflib库生成两个序列之间的差异，并以类似Word的track change方式展示。文章提供了一个Python代码示例，展示了如何使用SequenceMatcher类来比较两个字符串，并根据不同的样式选项生成带有HTML标记的差异结果。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.58,"time":34800,"words":116},"slug":"Tech/2023-05-05-Compare_text_","path":"blog/Tech/2023-05-05-Compare_text_","filePath":"blog/Tech/2023-05-05-Compare_text_.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Compare_text_","datePublished":"2023-05-05T00:00:00.000Z","dateModified":"2023-05-05T00:00:00.000Z","description":"使用Python的difflib库生成两个序列之间的差异，并以类似Word的track change方式展示。文章提供了一个Python代码示例，展示了如何使用SequenceMatcher类来比较两个字符串，并根据不同的样式选项生成带有HTML标记的差异结果。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-05-05-Compare_text_"}},{"title":"LLaMA_记录","date":"2023-04-26T00:00:00.000Z","tags":["AI"],"lastmod":"2023-04-26T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了LLaMA模型的训练方法和性能评估结果。LLaMA采用开源数据训练了7B到65B参数的模型,在多个任务上表现优异,13B模型超过GPT-3,65B模型与PaLM 540B相当。文章还指出,在给定计算预算下,在更多数据上训练较小模型比训练最大模型能获得更好的性能。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.35,"time":81000,"words":270},"slug":"AI/2023-04-26-LLaMA_记录","path":"blog/AI/2023-04-26-LLaMA_记录","filePath":"blog/AI/2023-04-26-LLaMA_记录.mdx","toc":[{"value":"方法","url":"#方法","depth":2},{"value":"2.1 预训练数据","url":"#21-预训练数据","depth":3},{"value":"2.2 架构","url":"#22-架构","depth":3},{"value":"3 结果","url":"#3-结果","depth":2},{"value":"常识推理","url":"#常识推理","depth":3},{"value":"QA","url":"#qa","depth":3},{"value":"阅读理解","url":"#阅读理解","depth":3},{"value":"数学推理","url":"#数学推理","depth":3},{"value":"代码生成","url":"#代码生成","depth":3},{"value":"大规模多任务语言理解","url":"#大规模多任务语言理解","depth":3},{"value":"训练过程中的loss","url":"#训练过程中的loss","depth":3}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"LLaMA_记录","datePublished":"2023-04-26T00:00:00.000Z","dateModified":"2023-04-26T00:00:00.000Z","description":"这篇文章介绍了LLaMA模型的训练方法和性能评估结果。LLaMA采用开源数据训练了7B到65B参数的模型,在多个任务上表现优异,13B模型超过GPT-3,65B模型与PaLM 540B相当。文章还指出,在给定计算预算下,在更多数据上训练较小模型比训练最大模型能获得更好的性能。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-04-26-LLaMA_记录"}},{"title":"爬虫-HTTP基础、加密、js调试","date":"2023-04-26T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-04-26T00:00:00.000Z","draft":false,"summary":"HTTP协议的发展历程,从HTTP 0.9到HTTP 2.0,以及HTTPS协议的工作原理。文章还简要介绍了Squid代理服务器的搭建,以及常见的加密算法如MD5、AES、RSA等。最后,文章讨论了前端JavaScript调试的一些技巧。","layout":"PostSimple","type":"Blog","readingTime":{"text":"12 min read","minutes":11.435,"time":686100,"words":2287},"slug":"Tech/2023-04-26-爬虫-HTTP基础、加密、js调试","path":"blog/Tech/2023-04-26-爬虫-HTTP基础、加密、js调试","filePath":"blog/Tech/2023-04-26-爬虫-HTTP基础、加密、js调试.mdx","toc":[{"value":"HTTP网络基础","url":"#http网络基础-1","depth":2},{"value":"HTTP","url":"#http-1","depth":3},{"value":"HTTPS","url":"#https-1","depth":3},{"value":"Squid 搭建代理服务","url":"#squid-搭建代理服务-1","depth":2},{"value":"加密","url":"#加密-1","depth":2},{"value":"前端js调试","url":"#前端js调试-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"爬虫-HTTP基础、加密、js调试","datePublished":"2023-04-26T00:00:00.000Z","dateModified":"2023-04-26T00:00:00.000Z","description":"HTTP协议的发展历程,从HTTP 0.9到HTTP 2.0,以及HTTPS协议的工作原理。文章还简要介绍了Squid代理服务器的搭建,以及常见的加密算法如MD5、AES、RSA等。最后,文章讨论了前端JavaScript调试的一些技巧。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-04-26-爬虫-HTTP基础、加密、js调试"}},{"title":"领域驱动设计-1","date":"2023-04-26T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-04-26T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了领域驱动设计(DDD)的核心概念和方法。文章强调了用户故事、通用语言、战略设计和战术设计在DDD中的重要性,并详细讲解了如何通过Domain Storytelling分析用户故事、建立通用语言、进行领域划分和识别限界上下文。文章还介绍了上下文映射的概念,展示了如何在实践中应用这些DDD方法。","layout":"PostSimple","type":"Blog","readingTime":{"text":"13 min read","minutes":12.125,"time":727500,"words":2425},"slug":"Tech/2023-04-26-领域驱动设计-1","path":"blog/Tech/2023-04-26-领域驱动设计-1","filePath":"blog/Tech/2023-04-26-领域驱动设计-1.mdx","toc":[{"value":"领域驱动设计DDD","url":"#领域驱动设计ddd-3","depth":1},{"value":"1. 用户故事","url":"#1-用户故事-3","depth":2},{"value":"1.1 什么是用户故事及如何描述","url":"#11-什么是用户故事及如何描述-3","depth":3},{"value":"1.1.1 Card(卡片)","url":"#111-card卡片-3","depth":4},{"value":"1.1.2 Conversation（谈话）","url":"#112-conversation谈话-3","depth":4},{"value":"1.1.3 Confirmation（验证）","url":"#113-confirmation验证-3","depth":4},{"value":"2. 使用Domain Storytelling分析用户故事","url":"#2-使用domain-storytelling分析用户故事-3","depth":2},{"value":"2.1 什么是domain storytelling？","url":"#21-什么是domain-storytelling-3","depth":3},{"value":"2.2 domain storytelling图和相关工具","url":"#22-domain-storytelling图和相关工具-3","depth":3},{"value":"3. 建立通用语言","url":"#3-建立通用语言-3","depth":2},{"value":"4. 领域划分","url":"#4-领域划分-3","depth":2},{"value":"4.1 分解用户故事","url":"#41-分解用户故事-3","depth":3},{"value":"4.2 基于用户故事进行领域划分","url":"#42-基于用户故事进行领域划分-3","depth":3},{"value":"5. 限界上下文的识别和上下文映射","url":"#5-限界上下文的识别和上下文映射-3","depth":2},{"value":"5.1 寻找限界上下文","url":"#51-寻找限界上下文-3","depth":3},{"value":"5.2 上下文映射","url":"#52-上下文映射-3","depth":3},{"value":"5.2.1 SmartRM上下文映射","url":"#521-smartrm上下文映射-3","depth":4}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"领域驱动设计-1","datePublished":"2023-04-26T00:00:00.000Z","dateModified":"2023-04-26T00:00:00.000Z","description":"这篇文章介绍了领域驱动设计(DDD)的核心概念和方法。文章强调了用户故事、通用语言、战略设计和战术设计在DDD中的重要性,并详细讲解了如何通过Domain Storytelling分析用户故事、建立通用语言、进行领域划分和识别限界上下文。文章还介绍了上下文映射的概念,展示了如何在实践中应用这些DDD方法。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-04-26-领域驱动设计-1"}},{"title":"高性能计算-basic","date":"2023-04-26T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-04-26T00:00:00.000Z","draft":false,"summary":"SIMD（单指令多数据）和SIMT（单指令多线程）两种并行计算技术，对比了它们在数组相加等任务中的应用和优缺点。文章还讨论了SIMD和SIMT在GPU架构中的实现，以及它们在提高计算效率和灵活性方面的作用。最后，文章探讨了这些技术在深度学习等领域的应用前景。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.33,"time":19800,"words":66},"slug":"Tech/2023-04-26-高性能计算-basic","path":"blog/Tech/2023-04-26-高性能计算-basic","filePath":"blog/Tech/2023-04-26-高性能计算-basic.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"高性能计算-basic","datePublished":"2023-04-26T00:00:00.000Z","dateModified":"2023-04-26T00:00:00.000Z","description":"SIMD（单指令多数据）和SIMT（单指令多线程）两种并行计算技术，对比了它们在数组相加等任务中的应用和优缺点。文章还讨论了SIMD和SIMT在GPU架构中的实现，以及它们在提高计算效率和灵活性方面的作用。最后，文章探讨了这些技术在深度学习等领域的应用前景。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-04-26-高性能计算-basic"}},{"title":"asyncio笔记","date":"2023-03-30T00:00:00.000Z","tags":["Tech"],"lastmod":"2023-03-30T00:00:00.000Z","draft":false,"summary":"Python中asyncio模块的核心概念和使用方法。文章详细解释了事件循环、协程、任务和Future等重要概念,并通过代码示例展示了如何创建和运行异步任务。此外,文章还讨论了yield和yield from在实现协程中的作用,以及它们与asyncio的关系。","layout":"PostSimple","type":"Blog","readingTime":{"text":"12 min read","minutes":11.165,"time":669900,"words":2233},"slug":"Tech/2023-03-30-asyncio笔记","path":"blog/Tech/2023-03-30-asyncio笔记","filePath":"blog/Tech/2023-03-30-asyncio笔记.mdx","toc":[{"value":"asyncio","url":"#asyncio-1","depth":2},{"value":"freezing","url":"#freezing-1","depth":2},{"value":"yield","url":"#yield-1","depth":2},{"value":"yield from","url":"#yield-from-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"asyncio笔记","datePublished":"2023-03-30T00:00:00.000Z","dateModified":"2023-03-30T00:00:00.000Z","description":"Python中asyncio模块的核心概念和使用方法。文章详细解释了事件循环、协程、任务和Future等重要概念,并通过代码示例展示了如何创建和运行异步任务。此外,文章还讨论了yield和yield from在实现协程中的作用,以及它们与asyncio的关系。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2023-03-30-asyncio笔记"}},{"title":"产品笔记-1","date":"2023-03-26T00:00:00.000Z","tags":["Product"],"lastmod":"2023-03-26T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了互联网的发展历程、产品经理的定义和能力要求,以及产品经理的工作内容和成长路径。文章指出,互联网经历了PC时代、移动时代,正在进入万物互联时代。产品经理需要具备好奇心、同理心、逻辑思维和协调能力,负责产品的全生命周期管理。产品经理的工作包括方向设计、功能设计、交互设计、商业化设计和增长设计等方面。","layout":"PostSimple","type":"Blog","readingTime":{"text":"22 min read","minutes":21.775,"time":1306500,"words":4355},"slug":"Product/2023-03-26-产品笔记-1","path":"blog/Product/2023-03-26-产品笔记-1","filePath":"blog/Product/2023-03-26-产品笔记-1.mdx","toc":[{"value":"互联网","url":"#互联网-5","depth":2},{"value":"互联网发展史","url":"#互联网发展史-5","depth":3},{"value":"互联网的三张网","url":"#互联网的三张网-5","depth":3},{"value":"互联网特点","url":"#互联网特点-5","depth":3},{"value":"产品","url":"#产品-5","depth":2},{"value":"产品来源","url":"#产品来源-5","depth":3},{"value":"产品特点","url":"#产品特点-5","depth":3},{"value":"产品经理的定义","url":"#产品经理的定义-5","depth":3},{"value":"产品经理的能力","url":"#产品经理的能力-5","depth":3},{"value":"当下产品经理的现状","url":"#当下产品经理的现状-5","depth":2},{"value":"如何做","url":"#如何做-5","depth":3},{"value":"角色和职责","url":"#角色和职责-5","depth":2},{"value":"产品立项从0-1","url":"#产品立项从0-1-5","depth":3},{"value":"研发流程从1到100","url":"#研发流程从1到100-5","depth":3},{"value":"职责","url":"#职责-5","depth":3},{"value":"产品经理的要求","url":"#产品经理的要求-5","depth":2},{"value":"大厂要求模型","url":"#大厂要求模型-5","depth":3},{"value":"成长要求","url":"#成长要求-5","depth":3},{"value":"产品经理日常问题汇总","url":"#产品经理日常问题汇总-5","depth":2},{"value":"产品经理工作","url":"#产品经理工作-5","depth":2},{"value":"方向设计","url":"#方向设计-5","depth":3},{"value":"功能设计","url":"#功能设计-5","depth":3},{"value":"交互设计","url":"#交互设计-5","depth":3},{"value":"商业化设计","url":"#商业化设计-5","depth":3},{"value":"增长","url":"#增长-5","depth":3},{"value":"Case","url":"#case-5","depth":3},{"value":"推荐书籍","url":"#推荐书籍-5","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"产品笔记-1","datePublished":"2023-03-26T00:00:00.000Z","dateModified":"2023-03-26T00:00:00.000Z","description":"这篇文章主要介绍了互联网的发展历程、产品经理的定义和能力要求,以及产品经理的工作内容和成长路径。文章指出,互联网经历了PC时代、移动时代,正在进入万物互联时代。产品经理需要具备好奇心、同理心、逻辑思维和协调能力,负责产品的全生命周期管理。产品经理的工作包括方向设计、功能设计、交互设计、商业化设计和增长设计等方面。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Product/2023-03-26-产品笔记-1"}},{"title":"Generate_AI_model一些评价角度","date":"2023-03-05T00:00:00.000Z","tags":["AI"],"lastmod":"2023-03-05T00:00:00.000Z","draft":false,"summary":"总结了ChatGPT在多个领域的局限性和失败案例,包括推理、逻辑、数学、事实准确性等方面。同时,文章也探讨了ChatGPT对社会的影响,如隐私、抄袭、环境影响等问题,并指出了未来研究的方向。","layout":"PostSimple","type":"Blog","readingTime":{"text":"8 min read","minutes":7.405,"time":444300,"words":1481},"slug":"AI/2023-03-05-Generate_AI_model一些评价角度","path":"blog/AI/2023-03-05-Generate_AI_model一些评价角度","filePath":"blog/AI/2023-03-05-Generate_AI_model一些评价角度.mdx","toc":[{"value":"推理 Reasoning","url":"#推理-reasoning-1","depth":2},{"value":"spatial reasoning 空间推理","url":"#spatial-reasoning-空间推理-1","depth":3},{"value":"Temporal reasoning 时间推理","url":"#temporal-reasoning-时间推理-1","depth":3},{"value":"Physical reasoning 物理推理","url":"#physical-reasoning-物理推理-1","depth":3},{"value":"Psychological reasoning 心理推理","url":"#psychological-reasoning-心理推理-1","depth":3},{"value":"Logic","url":"#logic-1","depth":2},{"value":"Math and arithmetic 数学与算数","url":"#math-and-arithmetic-数学与算数-1","depth":2},{"value":"Factual Errors","url":"#factual-errors-1","depth":2},{"value":"Bias and Discrimination","url":"#bias-and-discrimination-1","depth":2},{"value":"Wit and Humor 机智 幽默","url":"#wit-and-humor-机智-幽默-1","depth":2},{"value":"Codding","url":"#codding-1","depth":2},{"value":"Syntactic Structure, Spelling, and Grammar","url":"#syntactic-structure-spelling-and-grammar-1","depth":2},{"value":"self awareness","url":"#self-awareness-1","depth":2},{"value":"Ethics and Morality 伦理道德","url":"#ethics-and-morality-伦理道德-1","depth":2},{"value":"Other","url":"#other-1","depth":2},{"value":"对社会的影响","url":"#对社会的影响-1","depth":2},{"value":"Transparency and Trustworthiness 透明度 可信度","url":"#transparency-and-trustworthiness-透明度-可信度-1","depth":3},{"value":"Robustness and Security","url":"#robustness-and-security-1","depth":3},{"value":"Privacy 隐私","url":"#privacy-隐私-1","depth":3},{"value":"Plagiarism 抄袭","url":"#plagiarism-抄袭-1","depth":3},{"value":"Environmental Impact and Sustainability","url":"#environmental-impact-and-sustainability-1","depth":3},{"value":"Future work","url":"#future-work-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Generate_AI_model一些评价角度","datePublished":"2023-03-05T00:00:00.000Z","dateModified":"2023-03-05T00:00:00.000Z","description":"总结了ChatGPT在多个领域的局限性和失败案例,包括推理、逻辑、数学、事实准确性等方面。同时,文章也探讨了ChatGPT对社会的影响,如隐私、抄袭、环境影响等问题,并指出了未来研究的方向。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-03-05-Generate_AI_model一些评价角度"}},{"title":"Sam_Altman,_Elon_Musk_2016年9月采访","date":"2023-02-25T00:00:00.000Z","tags":["Life"],"lastmod":"2023-02-25T00:00:00.000Z","draft":false,"summary":"这篇文章主要讨论了做有意义的事情和人工智能的风险与机遇。作者强调了创造能带来变化的事物的重要性,以及技术进步背后的努力。关于人工智能,文章提出了民主化AI技术和人机融合的观点,认为这可以解决AI控制权的问题。","layout":"PostSimple","type":"Blog","readingTime":{"text":"3 min read","minutes":2.245,"time":134700,"words":449},"slug":"Life/2023-02-25-Sam_Altman,_Elon_Musk_2016年9月采访","path":"blog/Life/2023-02-25-Sam_Altman,_Elon_Musk_2016年9月采访","filePath":"blog/Life/2023-02-25-Sam_Altman,_Elon_Musk_2016年9月采访.mdx","toc":[{"value":"选择做有用的事","url":"#选择做有用的事-1","depth":2},{"value":"人工智能风险，创立OpenAI的初衷","url":"#人工智能风险创立openai的初衷-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Sam_Altman,_Elon_Musk_2016年9月采访","datePublished":"2023-02-25T00:00:00.000Z","dateModified":"2023-02-25T00:00:00.000Z","description":"这篇文章主要讨论了做有意义的事情和人工智能的风险与机遇。作者强调了创造能带来变化的事物的重要性,以及技术进步背后的努力。关于人工智能,文章提出了民主化AI技术和人机融合的观点,认为这可以解决AI控制权的问题。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Life/2023-02-25-Sam_Altman,_Elon_Musk_2016年9月采访"}},{"title":"笔记-nanoGPT","date":"2023-02-12T00:00:00.000Z","tags":["AI"],"lastmod":"2023-02-12T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了GPT模型的结构和实现细节。文章详细描述了GPT模型的核心组件,包括多头自注意力机制、前馈神经网络、位置编码等,并给出了相应的Python代码实现。此外,文章还介绍了GPT模型的训练过程,包括学习率调整策略等。","layout":"PostSimple","type":"Blog","readingTime":{"text":"7 min read","minutes":6.475,"time":388500,"words":1295},"slug":"AI/2023-02-12-笔记-nanoGPT","path":"blog/AI/2023-02-12-笔记-nanoGPT","filePath":"blog/AI/2023-02-12-笔记-nanoGPT.mdx","toc":[{"value":"GPTConfig","url":"#gptconfig","depth":2},{"value":"CausalSelfAttention","url":"#causalselfattention","depth":2},{"value":"MLP","url":"#mlp","depth":2},{"value":"Block","url":"#block","depth":2},{"value":"GPT","url":"#gpt","depth":2},{"value":"generate","url":"#generate","depth":2},{"value":"train","url":"#train","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"笔记-nanoGPT","datePublished":"2023-02-12T00:00:00.000Z","dateModified":"2023-02-12T00:00:00.000Z","description":"这篇文章主要介绍了GPT模型的结构和实现细节。文章详细描述了GPT模型的核心组件,包括多头自注意力机制、前馈神经网络、位置编码等,并给出了相应的Python代码实现。此外,文章还介绍了GPT模型的训练过程,包括学习率调整策略等。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-02-12-笔记-nanoGPT"}},{"title":"GPT2","date":"2023-01-15T00:00:00.000Z","tags":["AI"],"lastmod":"2023-01-15T00:00:00.000Z","draft":false,"summary":"GPT-2语言模型,一个无监督的多任务学习器。GPT-2在多个任务上实现了零样本学习的最先进结果,展示了语言模型作为通用任务学习器的潜力。文章还讨论了增加模型容量可以以对数线性方式提高性能,以及大规模多样化数据集对模型泛化能力的重要性。","layout":"PostSimple","type":"Blog","readingTime":{"text":"7 min read","minutes":6.95,"time":417000,"words":1390},"slug":"AI/2023-01-15-GPT2","path":"blog/AI/2023-01-15-GPT2","filePath":"blog/AI/2023-01-15-GPT2.mdx","toc":[{"value":"Approach","url":"#approach-2","depth":2},{"value":"数据","url":"#数据-2","depth":3},{"value":"数据输入","url":"#数据输入-2","depth":3},{"value":"模型","url":"#模型-2","depth":3},{"value":"实验","url":"#实验-2","depth":2},{"value":"","url":"#-2","depth":2},{"value":"泛化与记忆","url":"#泛化与记忆-2","depth":2},{"value":"相关工作","url":"#相关工作-2","depth":2},{"value":"讨论","url":"#讨论-2","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"GPT2","datePublished":"2023-01-15T00:00:00.000Z","dateModified":"2023-01-15T00:00:00.000Z","description":"GPT-2语言模型,一个无监督的多任务学习器。GPT-2在多个任务上实现了零样本学习的最先进结果,展示了语言模型作为通用任务学习器的潜力。文章还讨论了增加模型容量可以以对数线性方式提高性能,以及大规模多样化数据集对模型泛化能力的重要性。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-01-15-GPT2"}},{"title":"GPT3","date":"2023-01-15T00:00:00.000Z","tags":["AI"],"lastmod":"2023-01-15T00:00:00.000Z","draft":false,"summary":"GPT-3是一个拥有1750亿参数的大型语言模型,通过增大模型规模显著提高了小样本学习能力。在问答、填空、翻译等多项任务上,GPT-3无需微调就能取得不错的性能,但在某些数据集上仍存在困难。该研究还探讨了如何在大规模数据上训练如此庞大的语言模型。","layout":"PostSimple","type":"Blog","readingTime":{"text":"6 min read","minutes":5.845,"time":350700,"words":1169},"slug":"AI/2023-01-15-GPT3","path":"blog/AI/2023-01-15-GPT3","filePath":"blog/AI/2023-01-15-GPT3.mdx","toc":[{"value":"简介","url":"#简介-1","depth":2},{"value":"方法","url":"#方法-4","depth":2},{"value":"模型和架构","url":"#模型和架构-1","depth":3},{"value":"训练数据","url":"#训练数据-1","depth":3},{"value":"训练过程","url":"#训练过程-1","depth":3},{"value":"结果","url":"#结果-5","depth":2},{"value":"Measuring and Preventing Memorization Of Benchmarks","url":"#measuring-and-preventing-memorization-of-benchmarks-1","depth":2},{"value":"局限性","url":"#局限性-1","depth":2},{"value":"instructions","url":"#instructions-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"GPT3","datePublished":"2023-01-15T00:00:00.000Z","dateModified":"2023-01-15T00:00:00.000Z","description":"GPT-3是一个拥有1750亿参数的大型语言模型,通过增大模型规模显著提高了小样本学习能力。在问答、填空、翻译等多项任务上,GPT-3无需微调就能取得不错的性能,但在某些数据集上仍存在困难。该研究还探讨了如何在大规模数据上训练如此庞大的语言模型。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-01-15-GPT3"}},{"title":"自编码-自回归_BERT-GPT-LLM_","date":"2023-01-15T00:00:00.000Z","tags":["AI"],"lastmod":"2023-01-15T00:00:00.000Z","draft":false,"summary":"自回归和自编码模型在自然语言处理中的应用,以及BERT、GPT等大型语言模型的发展。文章重点讨论了BERT及其变体(如ALBERT、RoBERTa等)的改进,以及GPT、XLNet等自回归模型的特点。最后,文章简要概述了大型语言模型(LLM)的发展历程及其在NLP任务中的应用前景。","layout":"PostSimple","type":"Blog","readingTime":{"text":"11 min read","minutes":10.66,"time":639600,"words":2132},"slug":"AI/2023-01-15-自编码-自回归_BERT-GPT-LLM_","path":"blog/AI/2023-01-15-自编码-自回归_BERT-GPT-LLM_","filePath":"blog/AI/2023-01-15-自编码-自回归_BERT-GPT-LLM_.mdx","toc":[{"value":"自回归 和 自编码","url":"#自回归-和-自编码-1","depth":2},{"value":"BERT","url":"#bert-1","depth":2},{"value":"ALBERT","url":"#albert-1","depth":3},{"value":"RoBERTa","url":"#roberta-1","depth":3},{"value":"FinBert","url":"#finbert-1","depth":3},{"value":"K-Bert KG-bert","url":"#k-bert-kg-bert-1","depth":3},{"value":"SpanBert","url":"#spanbert-1","depth":3},{"value":"GPT","url":"#gpt-3","depth":2},{"value":"XLnet","url":"#xlnet-1","depth":2},{"value":"LLM","url":"#llm-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"自编码-自回归_BERT-GPT-LLM_","datePublished":"2023-01-15T00:00:00.000Z","dateModified":"2023-01-15T00:00:00.000Z","description":"自回归和自编码模型在自然语言处理中的应用,以及BERT、GPT等大型语言模型的发展。文章重点讨论了BERT及其变体(如ALBERT、RoBERTa等)的改进,以及GPT、XLNet等自回归模型的特点。最后,文章简要概述了大型语言模型(LLM)的发展历程及其在NLP任务中的应用前景。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-01-15-自编码-自回归_BERT-GPT-LLM_"}},{"title":"Reinforcement_Learning","date":"2023-01-04T00:00:00.000Z","tags":["AI"],"lastmod":"2023-01-04T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了强化学习的基本概念和定义。文章解释了概率密度函数、期望、状态、动作、策略、奖励等基础术语，并定义了回报、折扣回报、动作价值函数、最优动作价值函数和状态价值函数等关键概念。文章还通过马里奥游戏的例子来具体说明这些概念在实际应用中的含义。","layout":"PostSimple","type":"Blog","readingTime":{"text":"4 min read","minutes":3.655,"time":219300,"words":731},"slug":"AI/2023-01-04-Reinforcement_Learning","path":"blog/AI/2023-01-04-Reinforcement_Learning","filePath":"blog/AI/2023-01-04-Reinforcement_Learning.mdx","toc":[{"value":"基础","url":"#基础-2","depth":2},{"value":"术语","url":"#术语-2","depth":2},{"value":"随机性","url":"#随机性-2","depth":2},{"value":"定义","url":"#定义-2","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Reinforcement_Learning","datePublished":"2023-01-04T00:00:00.000Z","dateModified":"2023-01-04T00:00:00.000Z","description":"这篇文章主要介绍了强化学习的基本概念和定义。文章解释了概率密度函数、期望、状态、动作、策略、奖励等基础术语，并定义了回报、折扣回报、动作价值函数、最优动作价值函数和状态价值函数等关键概念。文章还通过马里奥游戏的例子来具体说明这些概念在实际应用中的含义。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-01-04-Reinforcement_Learning"}},{"title":"笔记-产品经理","date":"2022-08-08T00:00:00.000Z","tags":["Product"],"lastmod":"2022-08-08T00:00:00.000Z","draft":false,"summary":"这篇文章主要讨论了产品经理的工作内容和方法。文章涵盖了验证码设计、需求变更管理、产品规划、与开发人员合作、文档编写等多个方面。文章强调了产品经理需要深入理解用户需求,关注产品场景,善于沟通和管理项目,并且要不断学习新技术。总的来说,文章为产品经理提供了全面的工作指导和建议。","layout":"PostSimple","type":"Blog","readingTime":{"text":"21 min read","minutes":20.135,"time":1208100,"words":4027},"slug":"Product/2022-08-08-笔记-产品经理","path":"blog/Product/2022-08-08-笔记-产品经理","filePath":"blog/Product/2022-08-08-笔记-产品经理.mdx","toc":[{"value":"验证码是好设计吗？","url":"#验证码是好设计吗-1","depth":2},{"value":"设计工具","url":"#设计工具-1","depth":2},{"value":"AI时代产品经理","url":"#ai时代产品经理-1","depth":2},{"value":"案例-文本之美-TheGuardian","url":"#案例-文本之美-theguardian-1","depth":2},{"value":"需求变更","url":"#需求变更-1","depth":2},{"value":"案例-Hopper的“人工智能”","url":"#案例-hopper的人工智能-1","depth":2},{"value":"产品抄袭","url":"#产品抄袭-1","depth":2},{"value":"借鉴灵感","url":"#借鉴灵感-1","depth":2},{"value":"案例-LabRdr设计实验","url":"#案例-labrdr设计实验-1","depth":2},{"value":"产品规划","url":"#产品规划-1","depth":2},{"value":"案例-Mimo与LearnPython","url":"#案例-mimo与learnpython-1","depth":2},{"value":"影响力","url":"#影响力-1","depth":2},{"value":"如何和开发打交道","url":"#如何和开发打交道-1","depth":2},{"value":"产品文档","url":"#产品文档-1","depth":2},{"value":"写好文档的方法","url":"#写好文档的方法-1","depth":2},{"value":"产品分析","url":"#产品分析-1","depth":2},{"value":"需求评审","url":"#需求评审-1","depth":2},{"value":"项目管理","url":"#项目管理-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"笔记-产品经理","datePublished":"2022-08-08T00:00:00.000Z","dateModified":"2022-08-08T00:00:00.000Z","description":"这篇文章主要讨论了产品经理的工作内容和方法。文章涵盖了验证码设计、需求变更管理、产品规划、与开发人员合作、文档编写等多个方面。文章强调了产品经理需要深入理解用户需求,关注产品场景,善于沟通和管理项目,并且要不断学习新技术。总的来说,文章为产品经理提供了全面的工作指导和建议。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Product/2022-08-08-笔记-产品经理"}},{"title":"逻辑回归_BASE","date":"2022-06-05T00:00:00.000Z","tags":["AI"],"lastmod":"2022-06-05T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了逻辑回归的核心概念,包括最大似然估计、sigmoid函数和交叉熵。文章通过抛硬币和银行放款的例子来解释这些概念,并提供了一个训练逻辑回归模型的代码notebook。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.215,"time":12900,"words":43},"slug":"AI/2022-06-05-逻辑回归_BASE","path":"blog/AI/2022-06-05-逻辑回归_BASE","filePath":"blog/AI/2022-06-05-逻辑回归_BASE.mdx","toc":[{"value":"银行放款似然函数","url":"#银行放款似然函数-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"逻辑回归_BASE","datePublished":"2022-06-05T00:00:00.000Z","dateModified":"2022-06-05T00:00:00.000Z","description":"这篇文章介绍了逻辑回归的核心概念,包括最大似然估计、sigmoid函数和交叉熵。文章通过抛硬币和银行放款的例子来解释这些概念,并提供了一个训练逻辑回归模型的代码notebook。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-06-05-逻辑回归_BASE"}},{"title":"python_cookbook","date":"2022-04-20T00:00:00.000Z","tags":["Tech"],"lastmod":"2022-04-20T00:00:00.000Z","draft":false,"summary":"Python文件操作和多进程编程的一些技巧。文章讨论了如何处理文件读取时的换行符和编码错误，介绍了Python的-u选项用于关闭输出缓冲，并提供了设置pip源的方法。最后，文章展示了一个使用多进程写文件的Python代码示例。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.295,"time":77700,"words":259},"slug":"Ongoing/2022-04-20-python_cookbook","path":"blog/Ongoing/2022-04-20-python_cookbook","filePath":"blog/Ongoing/2022-04-20-python_cookbook.mdx","toc":[{"value":"python -u","url":"#python--u-1","depth":2},{"value":"pip 源","url":"#pip-源-1","depth":2},{"value":"多进程写文件","url":"#多进程写文件-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"python_cookbook","datePublished":"2022-04-20T00:00:00.000Z","dateModified":"2022-04-20T00:00:00.000Z","description":"Python文件操作和多进程编程的一些技巧。文章讨论了如何处理文件读取时的换行符和编码错误，介绍了Python的-u选项用于关闭输出缓冲，并提供了设置pip源的方法。最后，文章展示了一个使用多进程写文件的Python代码示例。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Ongoing/2022-04-20-python_cookbook"}},{"title":"nginx设置tensorboard转发服务_","date":"2022-04-14T00:00:00.000Z","tags":["Tech"],"lastmod":"2022-04-14T00:00:00.000Z","draft":false,"summary":"本文介绍了如何配置Nginx和启动TensorBoard以实现远程访问。文章包括Nginx配置示例、TensorBoard启动命令，以及访问TensorBoard时需要注意的URL格式。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.19,"time":11400,"words":38},"slug":"Tech/2022-04-14-nginx设置tensorboard转发服务_","path":"blog/Tech/2022-04-14-nginx设置tensorboard转发服务_","filePath":"blog/Tech/2022-04-14-nginx设置tensorboard转发服务_.mdx","toc":[{"value":"nginx conf设置","url":"#nginx-conf设置-1","depth":2},{"value":"tensorboard 启动","url":"#tensorboard-启动-1","depth":2},{"value":"访问","url":"#访问-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"nginx设置tensorboard转发服务_","datePublished":"2022-04-14T00:00:00.000Z","dateModified":"2022-04-14T00:00:00.000Z","description":"本文介绍了如何配置Nginx和启动TensorBoard以实现远程访问。文章包括Nginx配置示例、TensorBoard启动命令，以及访问TensorBoard时需要注意的URL格式。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2022-04-14-nginx设置tensorboard转发服务_"}},{"title":"n-gram检索domain_Adaptation：_Non-Parametric_Adaptation_for_Neural_Machine_Translation","date":"2022-04-01T00:00:00.000Z","tags":["AI"],"lastmod":"2022-04-01T00:00:00.000Z","draft":false,"summary":"这篇文章提出了一种半参数方法,通过n-gram检索来实现神经机器翻译在新领域的无参数适应。作者设计了新的架构来编码源语言和目标语言信息,并通过消融分析验证了方法的有效性。该方法在异构数据和稀有短语翻译上表现良好,避免了微调可能带来的灾难性遗忘问题。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.59,"time":95400,"words":318},"slug":"AI/2022-04-01-n-gram检索domain_Adaptation：_Non-Parametric_Adaptation_for_Neural_Machine_Translation","path":"blog/AI/2022-04-01-n-gram检索domain_Adaptation：_Non-Parametric_Adaptation_for_Neural_Machine_Translation","filePath":"blog/AI/2022-04-01-n-gram检索domain_Adaptation：_Non-Parametric_Adaptation_for_Neural_Machine_Translation.mdx","toc":[{"value":"检索方法","url":"#检索方法-1","depth":2},{"value":"IDF句子检索","url":"#idf句子检索-1","depth":3},{"value":"IDF N-gram检索","url":"#idf-n-gram检索-1","depth":3},{"value":"N-gram向量","url":"#n-gram向量-1","depth":3},{"value":"新架构","url":"#新架构-1","depth":2},{"value":"架构","url":"#架构-1","depth":3},{"value":"CSTM","url":"#cstm-1","depth":3},{"value":"模型效果","url":"#模型效果-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"n-gram检索domain_Adaptation：_Non-Parametric_Adaptation_for_Neural_Machine_Translation","datePublished":"2022-04-01T00:00:00.000Z","dateModified":"2022-04-01T00:00:00.000Z","description":"这篇文章提出了一种半参数方法,通过n-gram检索来实现神经机器翻译在新领域的无参数适应。作者设计了新的架构来编码源语言和目标语言信息,并通过消融分析验证了方法的有效性。该方法在异构数据和稀有短语翻译上表现良好,避免了微调可能带来的灾难性遗忘问题。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-04-01-n-gram检索domain_Adaptation：_Non-Parametric_Adaptation_for_Neural_Machine_Translation"}},{"title":"GEC语法错误纠正-GECToR","date":"2022-03-31T00:00:00.000Z","tags":["AI"],"lastmod":"2022-03-31T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了一种名为GECToR的语法纠错方法,采用序列标注模型对错误tokens进行变换标记,而不是直接重写句子。该方法通过三步训练过程和推理技巧提高了模型性能,在保持高准确率的同时大幅提升了推理速度。","layout":"PostSimple","type":"Blog","readingTime":{"text":"6 min read","minutes":5.24,"time":314400,"words":1048},"slug":"AI/2022-03-31-GEC语法错误纠正-GECToR","path":"blog/AI/2022-03-31-GEC语法错误纠正-GECToR","filePath":"blog/AI/2022-03-31-GEC语法错误纠正-GECToR.mdx","toc":[{"value":"Abstract","url":"#abstract-13","depth":2},{"value":"1. Introduction","url":"#1-introduction-7","depth":2},{"value":"2. 数据","url":"#2-数据-1","depth":2},{"value":"3. Token-level transformations","url":"#3-token-level-transformations-1","depth":2},{"value":"基础变换","url":"#基础变换-1","depth":3},{"value":"g-transformations","url":"#g-transformations-1","depth":3},{"value":"预处理","url":"#预处理-1","depth":3},{"value":"4. Tagging model架构","url":"#4-tagging-model架构-1","depth":2},{"value":"5. 迭代方法","url":"#5-迭代方法-1","depth":2},{"value":"6. Experiments","url":"#6-experiments-1","depth":2},{"value":"三步训练阶段","url":"#三步训练阶段-1","depth":3},{"value":"不同预训练模型作为encoder","url":"#不同预训练模型作为encoder-1","depth":3},{"value":"推理调整","url":"#推理调整-1","depth":3},{"value":"推理速度","url":"#推理速度-1","depth":3},{"value":"M2输出为incor cor文件脚本","url":"#m2输出为incor-cor文件脚本-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"GEC语法错误纠正-GECToR","datePublished":"2022-03-31T00:00:00.000Z","dateModified":"2022-03-31T00:00:00.000Z","description":"这篇文章介绍了一种名为GECToR的语法纠错方法,采用序列标注模型对错误tokens进行变换标记,而不是直接重写句子。该方法通过三步训练过程和推理技巧提高了模型性能,在保持高准确率的同时大幅提升了推理速度。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-03-31-GEC语法错误纠正-GECToR"}},{"title":"MT翻译记忆融合-Encoding_Gated_Translation_Memory_into_Neural_Machine_Translation","date":"2022-03-31T00:00:00.000Z","tags":["AI"],"lastmod":"2022-03-31T00:00:00.000Z","draft":false,"summary":"这篇文章提出了一种将翻译记忆(TM)融入神经机器翻译(NMT)的方法。通过两个独立的编码器对输入和TM匹配进行编码,并使用TM门控网络计算权重,将TM信息加权融入翻译生成过程。实验验证了不同模糊匹配分数(FMS)对结果的影响,并分析了TM门控值与语义相似度的关系。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.735,"time":44100,"words":147},"slug":"AI/2022-03-31-MT翻译记忆融合-Encoding_Gated_Translation_Memory_into_Neural_Machine_Translation","path":"blog/AI/2022-03-31-MT翻译记忆融合-Encoding_Gated_Translation_Memory_into_Neural_Machine_Translation","filePath":"blog/AI/2022-03-31-MT翻译记忆融合-Encoding_Gated_Translation_Memory_into_Neural_Machine_Translation.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"MT翻译记忆融合-Encoding_Gated_Translation_Memory_into_Neural_Machine_Translation","datePublished":"2022-03-31T00:00:00.000Z","dateModified":"2022-03-31T00:00:00.000Z","description":"这篇文章提出了一种将翻译记忆(TM)融入神经机器翻译(NMT)的方法。通过两个独立的编码器对输入和TM匹配进行编码,并使用TM门控网络计算权重,将TM信息加权融入翻译生成过程。实验验证了不同模糊匹配分数(FMS)对结果的影响,并分析了TM门控值与语义相似度的关系。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-03-31-MT翻译记忆融合-Encoding_Gated_Translation_Memory_into_Neural_Machine_Translation"}},{"title":"增强术语翻译（修改输入）-Training_Neural_Machine_Translation_To_Apply_Terminology_Constraints_","date":"2022-03-31T00:00:00.000Z","tags":["AI"],"lastmod":"2022-03-31T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了一种通过在输入中增加目标端术语信息来提高神经机器翻译模型术语翻译能力的方法。该方法使用replace和append两种方式添加术语注解，让模型学习\"复制机制\"，并考虑术语的形态变化。研究结果显示这种方法可以提高术语翻译准确性，但在BLEU评分上有所下降，且通用性有限。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.175,"time":70500,"words":235},"slug":"AI/2022-03-31-增强术语翻译（修改输入）-Training_Neural_Machine_Translation_To_Apply_Terminology_Constraints_","path":"blog/AI/2022-03-31-增强术语翻译（修改输入）-Training_Neural_Machine_Translation_To_Apply_Terminology_Constraints_","filePath":"blog/AI/2022-03-31-增强术语翻译（修改输入）-Training_Neural_Machine_Translation_To_Apply_Terminology_Constraints_.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"增强术语翻译（修改输入）-Training_Neural_Machine_Translation_To_Apply_Terminology_Constraints_","datePublished":"2022-03-31T00:00:00.000Z","dateModified":"2022-03-31T00:00:00.000Z","description":"这篇文章介绍了一种通过在输入中增加目标端术语信息来提高神经机器翻译模型术语翻译能力的方法。该方法使用replace和append两种方式添加术语注解，让模型学习\"复制机制\"，并考虑术语的形态变化。研究结果显示这种方法可以提高术语翻译准确性，但在BLEU评分上有所下降，且通用性有限。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-03-31-增强术语翻译（修改输入）-Training_Neural_Machine_Translation_To_Apply_Terminology_Constraints_"}},{"title":"低资源领域适应MT","date":"2022-03-22T00:00:00.000Z","tags":["AI"],"lastmod":"2022-03-22T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了几种利用丰富通用语料来训练低资源领域机器翻译模型的方法,包括增量训练、集成解码、合并训练数据和数据加权等。其中数据加权方法通过对领域内数据进行过采样,在训练过程中让模型\"见到\"更多领域数据,在领域数据量为50k-500k时效果较好。","layout":"PostSimple","type":"Blog","readingTime":{"text":"4 min read","minutes":3.555,"time":213300,"words":711},"slug":"AI/2022-03-22-低资源领域适应MT","path":"blog/AI/2022-03-22-低资源领域适应MT","filePath":"blog/AI/2022-03-22-低资源领域适应MT.mdx","toc":[{"value":"1. Incremental Training","url":"#1-incremental-training-1","depth":2},{"value":"2. Ensemble Decoding（2 models）","url":"#2-ensemble-decoding2-models-1","depth":2},{"value":"3. Combining Training Data","url":"#3-combining-training-data-1","depth":2},{"value":"4. Data Weighting","url":"#4-data-weighting-1","depth":2},{"value":"4.1 Mixed Fine-Tuning","url":"#41-mixed-fine-tuning-1","depth":3}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"低资源领域适应MT","datePublished":"2022-03-22T00:00:00.000Z","dateModified":"2022-03-22T00:00:00.000Z","description":"这篇文章介绍了几种利用丰富通用语料来训练低资源领域机器翻译模型的方法,包括增量训练、集成解码、合并训练数据和数据加权等。其中数据加权方法通过对领域内数据进行过采样,在训练过程中让模型\"见到\"更多领域数据,在领域数据量为50k-500k时效果较好。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-03-22-低资源领域适应MT"}},{"title":"gcc双版本安装","date":"2022-03-19T00:00:00.000Z","tags":["Tech"],"lastmod":"2022-03-19T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了如何在Linux系统上安装和配置GCC 5.5.0版本。文章详细说明了下载、编译和安装GCC 5.5.0的步骤，以及如何使用update-alternatives命令配置多个GCC版本，使系统能够同时支持GCC 4.8.5和5.5.0版本。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.29,"time":77400,"words":258},"slug":"Tech/2022-03-19-gcc双版本安装","path":"blog/Tech/2022-03-19-gcc双版本安装","filePath":"blog/Tech/2022-03-19-gcc双版本安装.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"gcc双版本安装","datePublished":"2022-03-19T00:00:00.000Z","dateModified":"2022-03-19T00:00:00.000Z","description":"这篇文章介绍了如何在Linux系统上安装和配置GCC 5.5.0版本。文章详细说明了下载、编译和安装GCC 5.5.0的步骤，以及如何使用update-alternatives命令配置多个GCC版本，使系统能够同时支持GCC 4.8.5和5.5.0版本。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2022-03-19-gcc双版本安装"}},{"title":"安装tesseract和Detectron2参考网址","date":"2022-03-19T00:00:00.000Z","tags":["Tech"],"lastmod":"2022-03-19T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了在测试Layout Parser功能时需要安装和使用Detectron2和Tesseract。文章提供了相关的安装文档链接,并详细说明了在CentOS 7系统上安装Tesseract时可能遇到的问题及解决方法,特别是libtool版本不匹配的错误处理。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.77,"time":46200,"words":154},"slug":"Tech/2022-03-19-安装tesseract和Detectron2参考网址","path":"blog/Tech/2022-03-19-安装tesseract和Detectron2参考网址","filePath":"blog/Tech/2022-03-19-安装tesseract和Detectron2参考网址.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"安装tesseract和Detectron2参考网址","datePublished":"2022-03-19T00:00:00.000Z","dateModified":"2022-03-19T00:00:00.000Z","description":"这篇文章主要介绍了在测试Layout Parser功能时需要安装和使用Detectron2和Tesseract。文章提供了相关的安装文档链接,并详细说明了在CentOS 7系统上安装Tesseract时可能遇到的问题及解决方法,特别是libtool版本不匹配的错误处理。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2022-03-19-安装tesseract和Detectron2参考网址"}},{"title":"笔记-（Adaptive）Nearest_Neighbor_Machine_Translation_","date":"2022-03-08T00:00:00.000Z","tags":["AI"],"lastmod":"2022-03-08T00:00:00.000Z","draft":false,"summary":"Nearest Neighbor Machine Translation (KNN-MT)","layout":"PostSimple","type":"Blog","readingTime":{"text":"5 min read","minutes":4.87,"time":292200,"words":974},"slug":"AI/2022-03-08-笔记-（Adaptive）Nearest_Neighbor_Machine_Translation_","path":"blog/AI/2022-03-08-笔记-（Adaptive）Nearest_Neighbor_Machine_Translation_","filePath":"blog/AI/2022-03-08-笔记-（Adaptive）Nearest_Neighbor_Machine_Translation_.mdx","toc":[{"value":"原理：","url":"#原理-1","depth":2},{"value":"KNN概率分布的计算方式","url":"#knn概率分布的计算方式-1","depth":2},{"value":"构建Datastore","url":"#构建datastore-1","depth":3},{"value":"计算KNN的分布","url":"#计算knn的分布-1","depth":3},{"value":"Experiments","url":"#experiments-3","depth":2},{"value":"单一语言对翻译","url":"#单一语言对翻译-1","depth":3},{"value":"多语言模型","url":"#多语言模型-1","depth":3},{"value":"域适应","url":"#域适应-1","depth":3},{"value":"关键超参数调整","url":"#关键超参数调整-1","depth":2},{"value":"softmax temperature","url":"#softmax-temperature-1","depth":3},{"value":"查询neighbors的个数","url":"#查询neighbors的个数-1","depth":3},{"value":"datastore大小","url":"#datastore大小-1","depth":3},{"value":"T和lambda","url":"#t和lambda-1","depth":3},{"value":"案例","url":"#案例-1","depth":2},{"value":"其他优化","url":"#其他优化-1","depth":2},{"value":"Adaptive Nearest Neighbor Machine Translation","url":"#adaptive-nearest-neighbor-machine-translation-1","depth":3},{"value":"Learning Kernel-Smoothed Machine Translation with RetrievedExamples","url":"#learning-kernel-smoothed-machine-translation-with-retrievedexamples-1","depth":3}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"笔记-（Adaptive）Nearest_Neighbor_Machine_Translation_","datePublished":"2022-03-08T00:00:00.000Z","dateModified":"2022-03-08T00:00:00.000Z","description":"Nearest Neighbor Machine Translation (KNN-MT)","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-03-08-笔记-（Adaptive）Nearest_Neighbor_Machine_Translation_"}},{"title":"笔记-Learning_Kernel-Smoothed_Machine_Translation_with_RetrievedExamples","date":"2022-02-25T00:00:00.000Z","tags":["AI"],"lastmod":"2022-02-25T00:00:00.000Z","draft":false,"summary":"KSTER的机器翻译方法,通过可学习的核函数和自适应混合权重来改进基于检索的神经机器翻译。KSTER在领域适应和多领域翻译任务中表现优异,相比基线模型在BLEU分数上提高了1.1-1.5分。该方法通过动态计算检索实例的相关性和自适应混合模型预测与检索结果,在保持通用性能的同时提高了特定领域的翻译质量。","layout":"PostSimple","type":"Blog","readingTime":{"text":"7 min read","minutes":6.025,"time":361500,"words":1205},"slug":"AI/2022-02-25-笔记-Learning_Kernel-Smoothed_Machine_Translation_with_RetrievedExamples","path":"blog/AI/2022-02-25-笔记-Learning_Kernel-Smoothed_Machine_Translation_with_RetrievedExamples","filePath":"blog/AI/2022-02-25-笔记-Learning_Kernel-Smoothed_Machine_Translation_with_RetrievedExamples.mdx","toc":[{"value":"1 Introduction","url":"#1-introduction-6","depth":2},{"value":"2 Related Word","url":"#2-related-word-1","depth":2},{"value":"3 Methodology","url":"#3-methodology-1","depth":2},{"value":"3.1 Kernel-Smoothed Machine Translation","url":"#31-kernel-smoothed-machine-translation-1","depth":3},{"value":"3.2 Learnable Kernel Function","url":"#32-learnable-kernel-function-1","depth":3},{"value":"3.3 Adaptive Mixing of Base Prediction andRetrieved Examples","url":"#33-adaptive-mixing-of-base-prediction-andretrieved-examples-1","depth":3},{"value":"3.4 Training","url":"#34-training-1","depth":3},{"value":"3.5 Retrieval Dropout","url":"#35-retrieval-dropout-1","depth":3},{"value":"4 Experiments","url":"#4-experiments-1","depth":2},{"value":"4.1 Datasets and Implementation Details","url":"#41-datasets-and-implementation-details-1","depth":3},{"value":"4.2 Domain Adaptation for MachineTranslation","url":"#42-domain-adaptation-for-machinetranslation-1","depth":3},{"value":"4.3 Multi-Domain Machine Translation","url":"#43-multi-domain-machine-translation-1","depth":3},{"value":"4.4 推理速度","url":"#44-推理速度-1","depth":3},{"value":"5 分析","url":"#5-分析-1","depth":2},{"value":"5.1 Ablation Studies of Proposed Methods","url":"#51-ablation-studies-of-proposed-methods-1","depth":3},{"value":"5.2 对翻译的细粒度影响","url":"#52-对翻译的细粒度影响-1","depth":3},{"value":"论文复现结果","url":"#论文复现结果-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"笔记-Learning_Kernel-Smoothed_Machine_Translation_with_RetrievedExamples","datePublished":"2022-02-25T00:00:00.000Z","dateModified":"2022-02-25T00:00:00.000Z","description":"KSTER的机器翻译方法,通过可学习的核函数和自适应混合权重来改进基于检索的神经机器翻译。KSTER在领域适应和多领域翻译任务中表现优异,相比基线模型在BLEU分数上提高了1.1-1.5分。该方法通过动态计算检索实例的相关性和自适应混合模型预测与检索结果,在保持通用性能的同时提高了特定领域的翻译质量。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-02-25-笔记-Learning_Kernel-Smoothed_Machine_Translation_with_RetrievedExamples"}},{"title":"笔记-As_Easy_as_1,_2,_3:_Behavioural_Testing_of_NMT_Systemsfor_Numerical_Translation","date":"2022-02-23T00:00:00.000Z","tags":["AI"],"lastmod":"2022-02-23T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了一项针对机器翻译模型数字翻译准确率的测试研究。研究对比了不同类型的翻译模型,总结出四种常见的数字翻译错误类型,并提出了几种可能的改进策略。结果显示,所有测试的模型在各种错误类型上都未能达到100%的准确率。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.725,"time":103500,"words":345},"slug":"AI/2022-02-23-笔记-As_Easy_as_1,_2,_3:_Behavioural_Testing_of_NMT_Systemsfor_Numerical_Translation","path":"blog/AI/2022-02-23-笔记-As_Easy_as_1,_2,_3:_Behavioural_Testing_of_NMT_Systemsfor_Numerical_Translation","filePath":"blog/AI/2022-02-23-笔记-As_Easy_as_1,_2,_3:_Behavioural_Testing_of_NMT_Systemsfor_Numerical_Translation.mdx","toc":[{"value":"错误说明","url":"#错误说明-1","depth":2},{"value":"作者提出的缓解策略","url":"#作者提出的缓解策略-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"笔记-As_Easy_as_1,_2,_3:_Behavioural_Testing_of_NMT_Systemsfor_Numerical_Translation","datePublished":"2022-02-23T00:00:00.000Z","dateModified":"2022-02-23T00:00:00.000Z","description":"这篇文章介绍了一项针对机器翻译模型数字翻译准确率的测试研究。研究对比了不同类型的翻译模型,总结出四种常见的数字翻译错误类型,并提出了几种可能的改进策略。结果显示,所有测试的模型在各种错误类型上都未能达到100%的准确率。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-02-23-笔记-As_Easy_as_1,_2,_3:_Behavioural_Testing_of_NMT_Systemsfor_Numerical_Translation"}},{"title":"小牛论坛笔记（2021）","date":"2022-02-21T00:00:00.000Z","tags":["AI"],"lastmod":"2022-02-21T00:00:00.000Z","draft":false,"summary":"这篇文章主要讨论了神经机器翻译领域的几个研究方向,包括模型压缩、质量评估和训练策略等。文章介绍了减少模型冗余的方法,如深编码器-浅解码器结构和知识蒸馏等。同时还探讨了翻译模型的学习规律,提出了基于课程学习的训练策略。","layout":"PostSimple","type":"Blog","readingTime":{"text":"3 min read","minutes":2.63,"time":157800,"words":526},"slug":"AI/2022-02-21-小牛论坛笔记（2021）","path":"blog/AI/2022-02-21-小牛论坛笔记（2021）","filePath":"blog/AI/2022-02-21-小牛论坛笔记（2021）.mdx","toc":[{"value":"小牛","url":"#小牛-1","depth":2},{"value":"结构冗余","url":"#结构冗余-1","depth":3},{"value":"参数冗余","url":"#参数冗余-1","depth":3},{"value":"计算冗余","url":"#计算冗余-1","depth":3},{"value":"华为分享","url":"#华为分享-1","depth":2},{"value":"NMT Quality Estimation","url":"#nmt-quality-estimation-1","depth":3},{"value":"澳门大学","url":"#澳门大学-1","depth":2},{"value":"科大讯飞","url":"#科大讯飞-1","depth":2},{"value":"南京大学","url":"#南京大学-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"小牛论坛笔记（2021）","datePublished":"2022-02-21T00:00:00.000Z","dateModified":"2022-02-21T00:00:00.000Z","description":"这篇文章主要讨论了神经机器翻译领域的几个研究方向,包括模型压缩、质量评估和训练策略等。文章介绍了减少模型冗余的方法,如深编码器-浅解码器结构和知识蒸馏等。同时还探讨了翻译模型的学习规律,提出了基于课程学习的训练策略。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-02-21-小牛论坛笔记（2021）"}},{"title":"笔记-Improving_Neural_Machine_Translation_by_Bidirectional_Training","date":"2022-02-17T00:00:00.000Z","tags":["AI"],"lastmod":"2022-02-17T00:00:00.000Z","draft":false,"summary":"这篇文章提出了一种名为BiT的新方法,通过使用双向模型作为单向模型的初始化来提高机器翻译性能。BiT方法在训练早期阶段将源语言到目标语言的数据组合为源语言+目标语言到目标语言+源语言的形式进行预训练,然后再使用常规的源语言到目标语言数据进行训练。实验表明,BiT方法在8个语言对上都取得了优于现有最佳方法的性能提升,并且能提高模型的对齐质量和低资源场景下的效果。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.2,"time":72000,"words":240},"slug":"AI/2022-02-17-笔记-Improving_Neural_Machine_Translation_by_Bidirectional_Training","path":"blog/AI/2022-02-17-笔记-Improving_Neural_Machine_Translation_by_Bidirectional_Training","filePath":"blog/AI/2022-02-17-笔记-Improving_Neural_Machine_Translation_by_Bidirectional_Training.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"笔记-Improving_Neural_Machine_Translation_by_Bidirectional_Training","datePublished":"2022-02-17T00:00:00.000Z","dateModified":"2022-02-17T00:00:00.000Z","description":"这篇文章提出了一种名为BiT的新方法,通过使用双向模型作为单向模型的初始化来提高机器翻译性能。BiT方法在训练早期阶段将源语言到目标语言的数据组合为源语言+目标语言到目标语言+源语言的形式进行预训练,然后再使用常规的源语言到目标语言数据进行训练。实验表明,BiT方法在8个语言对上都取得了优于现有最佳方法的性能提升,并且能提高模型的对齐质量和低资源场景下的效果。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-02-17-笔记-Improving_Neural_Machine_Translation_by_Bidirectional_Training"}},{"title":"TranSmart-笔记","date":"2022-02-14T00:00:00.000Z","tags":["AI"],"lastmod":"2022-02-14T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了一个交互式机器翻译系统的主要功能和技术实现。系统的核心功能包括词级和句子级自动补全、增强翻译记忆等,采用了通用翻译模型、词汇约束、基于图的翻译记忆等技术。评估结果显示,该系统在词级准确率和BLEU分数上都有显著提升。","layout":"PostSimple","type":"Blog","readingTime":{"text":"4 min read","minutes":3.33,"time":199800,"words":666},"slug":"AI/2022-02-14-TranSmart-笔记","path":"blog/AI/2022-02-14-TranSmart-笔记","filePath":"blog/AI/2022-02-14-TranSmart-笔记.mdx","toc":[{"value":"2 System Features","url":"#2-system-features-1","depth":2},{"value":"3 Implemented Techniques","url":"#3-implemented-techniques-1","depth":2},{"value":"3.1 Generic Translation Model","url":"#31-generic-translation-model-1","depth":3},{"value":"Data Rejuvenation","url":"#data-rejuvenation-1","depth":4},{"value":"Data Augmentation","url":"#data-augmentation-1","depth":4},{"value":"3.2 General Word-level Autocompletion","url":"#32-general-word-level-autocompletion-1","depth":3},{"value":"3.3 Sentence-level Autocompletion by Lexical Constraints","url":"#33-sentence-level-autocompletion-by-lexical-constraints-1","depth":3},{"value":"3.4 Graph based Translation Memory","url":"#34-graph-based-translation-memory-1","depth":3},{"value":"3.5 others","url":"#35-others-1","depth":3},{"value":"word alignment","url":"#word-alignment-1","depth":4},{"value":"5 System Evaluation","url":"#5-system-evaluation-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"TranSmart-笔记","datePublished":"2022-02-14T00:00:00.000Z","dateModified":"2022-02-14T00:00:00.000Z","description":"这篇文章介绍了一个交互式机器翻译系统的主要功能和技术实现。系统的核心功能包括词级和句子级自动补全、增强翻译记忆等,采用了通用翻译模型、词汇约束、基于图的翻译记忆等技术。评估结果显示,该系统在词级准确率和BLEU分数上都有显著提升。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-02-14-TranSmart-笔记"}},{"title":"opennmt-tf_验证","date":"2022-02-10T00:00:00.000Z","tags":["AI"],"lastmod":"2022-02-10T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了使用OpenNMT-tf进行机器翻译模型训练的步骤,包括创建词汇表、配置训练参数、开始训练、模型推理和BLEU评分计算。文章还比较了不同模型平均数量和beam search参数对BLEU评分的影响,最终得到最佳的模型配置。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.21,"time":72600,"words":242},"slug":"AI/2022-02-10-opennmt-tf_验证","path":"blog/AI/2022-02-10-opennmt-tf_验证","filePath":"blog/AI/2022-02-10-opennmt-tf_验证.mdx","toc":[{"value":"创建vocab","url":"#创建vocab-1","depth":2},{"value":"开始训练","url":"#开始训练-3","depth":2},{"value":"Inference","url":"#inference-3","depth":2},{"value":"BLEU计算","url":"#bleu计算-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"opennmt-tf_验证","datePublished":"2022-02-10T00:00:00.000Z","dateModified":"2022-02-10T00:00:00.000Z","description":"这篇文章介绍了使用OpenNMT-tf进行机器翻译模型训练的步骤,包括创建词汇表、配置训练参数、开始训练、模型推理和BLEU评分计算。文章还比较了不同模型平均数量和beam search参数对BLEU评分的影响,最终得到最佳的模型配置。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-02-10-opennmt-tf_验证"}},{"title":"频率派vs贝叶斯派","date":"2022-02-10T00:00:00.000Z","tags":["AI"],"lastmod":"2022-02-10T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了频率派和贝叶斯派对概率的不同诠释。频率派认为参数θ是常量，通过最大似然估计求解；贝叶斯派则认为θ满足先验分布，通过最大后验估计求解。文章还简要对比了两种方法的发展方向，频率派演变为优化问题，贝叶斯派发展为概率图模型。","layout":"PostSimple","type":"Blog","readingTime":{"text":"3 min read","minutes":2.51,"time":150600,"words":502},"slug":"AI/2022-02-10-频率派vs贝叶斯派","path":"blog/AI/2022-02-10-频率派vs贝叶斯派","filePath":"blog/AI/2022-02-10-频率派vs贝叶斯派.mdx","toc":[{"value":"Introduction","url":"#introduction-19","depth":1},{"value":"频率派的观点","url":"#频率派的观点-1","depth":2},{"value":"贝叶斯派的观点","url":"#贝叶斯派的观点-1","depth":2},{"value":"小结","url":"#小结-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"频率派vs贝叶斯派","datePublished":"2022-02-10T00:00:00.000Z","dateModified":"2022-02-10T00:00:00.000Z","description":"这篇文章主要介绍了频率派和贝叶斯派对概率的不同诠释。频率派认为参数θ是常量，通过最大似然估计求解；贝叶斯派则认为θ满足先验分布，通过最大后验估计求解。文章还简要对比了两种方法的发展方向，频率派演变为优化问题，贝叶斯派发展为概率图模型。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-02-10-频率派vs贝叶斯派"}},{"title":"笔记-A_Novel_Hybrid_Approach_to_Improve_Neural_Machine_Translation_Decoding_using_Phrase-Based_Statistical_Machine_Translation","date":"2022-01-25T00:00:00.000Z","tags":["AI"],"lastmod":"2022-01-25T00:00:00.000Z","draft":false,"summary":"这篇文章提出了一种结合短语统计机器翻译(SMT)来改进神经机器翻译(NMT)解码的混合方法。在beam search过程中,如果SMT翻译的token存在于beam中,就将其概率提升至beam中的最大概率。实验结果显示,该方法在某些策略下可以小幅提升BLEU和METEOR分数。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.83,"time":109800,"words":366},"slug":"AI/2022-01-25-笔记-A_Novel_Hybrid_Approach_to_Improve_Neural_Machine_Translation_Decoding_using_Phrase-Based_Statistical_Machine_Translation","path":"blog/AI/2022-01-25-笔记-A_Novel_Hybrid_Approach_to_Improve_Neural_Machine_Translation_Decoding_using_Phrase-Based_Statistical_Machine_Translation","filePath":"blog/AI/2022-01-25-笔记-A_Novel_Hybrid_Approach_to_Improve_Neural_Machine_Translation_Decoding_using_Phrase-Based_Statistical_Machine_Translation.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"笔记-A_Novel_Hybrid_Approach_to_Improve_Neural_Machine_Translation_Decoding_using_Phrase-Based_Statistical_Machine_Translation","datePublished":"2022-01-25T00:00:00.000Z","dateModified":"2022-01-25T00:00:00.000Z","description":"这篇文章提出了一种结合短语统计机器翻译(SMT)来改进神经机器翻译(NMT)解码的混合方法。在beam search过程中,如果SMT翻译的token存在于beam中,就将其概率提升至beam中的最大概率。实验结果显示,该方法在某些策略下可以小幅提升BLEU和METEOR分数。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-01-25-笔记-A_Novel_Hybrid_Approach_to_Improve_Neural_Machine_Translation_Decoding_using_Phrase-Based_Statistical_Machine_Translation"}},{"title":"笔记-Dynamic_Terminology_Integration_for_COVID-19_and_other_EmergingDomains","date":"2022-01-25T00:00:00.000Z","tags":["AI"],"lastmod":"2022-01-25T00:00:00.000Z","draft":false,"summary":"这篇文章提出了一种动态术语集成方法,用于提高新兴领域如COVID-19的机器翻译准确率。作者通过术语过滤、识别和集成等步骤,在不干扰训练过程的情况下提高了术语翻译的准确性,在测试集上实现了94%的COVID-19术语准确率。文章强调了高质量术语集的重要性,并指出术语改进对BLEU分数影响不大可能导致这方面研究被忽视。","layout":"PostSimple","type":"Blog","readingTime":{"text":"4 min read","minutes":3.79,"time":227400,"words":758},"slug":"AI/2022-01-25-笔记-Dynamic_Terminology_Integration_for_COVID-19_and_other_EmergingDomains","path":"blog/AI/2022-01-25-笔记-Dynamic_Terminology_Integration_for_COVID-19_and_other_EmergingDomains","filePath":"blog/AI/2022-01-25-笔记-Dynamic_Terminology_Integration_for_COVID-19_and_other_EmergingDomains.mdx","toc":[{"value":"2. Methods","url":"#2-methods-1","depth":2},{"value":"2.1 术语过滤","url":"#21-术语过滤-1","depth":3},{"value":"2.2 术语识别","url":"#22-术语识别-1","depth":3},{"value":"2.3 集成术语约束","url":"#23-集成术语约束-1","depth":3},{"value":"Result","url":"#result-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"笔记-Dynamic_Terminology_Integration_for_COVID-19_and_other_EmergingDomains","datePublished":"2022-01-25T00:00:00.000Z","dateModified":"2022-01-25T00:00:00.000Z","description":"这篇文章提出了一种动态术语集成方法,用于提高新兴领域如COVID-19的机器翻译准确率。作者通过术语过滤、识别和集成等步骤,在不干扰训练过程的情况下提高了术语翻译的准确性,在测试集上实现了94%的COVID-19术语准确率。文章强调了高质量术语集的重要性,并指出术语改进对BLEU分数影响不大可能导致这方面研究被忽视。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-01-25-笔记-Dynamic_Terminology_Integration_for_COVID-19_and_other_EmergingDomains"}},{"title":"xml文件修复","date":"2022-01-25T00:00:00.000Z","tags":["Tech"],"lastmod":"2022-01-25T00:00:00.000Z","draft":false,"summary":"这段代码使用BeautifulSoup库解析XML文件。它打开指定路径的文件，读取内容，并使用BeautifulSoup将其解析为格式化的XML结构。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.075,"time":4500,"words":15},"slug":"Tech/2022-01-25-xml文件修复","path":"blog/Tech/2022-01-25-xml文件修复","filePath":"blog/Tech/2022-01-25-xml文件修复.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"xml文件修复","datePublished":"2022-01-25T00:00:00.000Z","dateModified":"2022-01-25T00:00:00.000Z","description":"这段代码使用BeautifulSoup库解析XML文件。它打开指定路径的文件，读取内容，并使用BeautifulSoup将其解析为格式化的XML结构。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2022-01-25-xml文件修复"}},{"title":"cudnn_安装","date":"2022-01-19T00:00:00.000Z","tags":["Tech"],"lastmod":"2022-01-19T00:00:00.000Z","draft":false,"summary":"本文介绍了cuDNN的安装步骤,包括下载对应版本压缩包、解压文件、配置环境变量、复制头文件等操作。文章还提供了查看cuDNN版本的方法,以及CUDA、NVIDIA驱动和cuDNN之间的版本兼容性查询链接。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.915,"time":54900,"words":183},"slug":"Tech/2022-01-19-cudnn_安装","path":"blog/Tech/2022-01-19-cudnn_安装","filePath":"blog/Tech/2022-01-19-cudnn_安装.mdx","toc":[{"value":"cuDNN安装","url":"#cudnn安装-1","depth":2},{"value":"相关帮助链接：","url":"#相关帮助链接-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"cudnn_安装","datePublished":"2022-01-19T00:00:00.000Z","dateModified":"2022-01-19T00:00:00.000Z","description":"本文介绍了cuDNN的安装步骤,包括下载对应版本压缩包、解压文件、配置环境变量、复制头文件等操作。文章还提供了查看cuDNN版本的方法,以及CUDA、NVIDIA驱动和cuDNN之间的版本兼容性查询链接。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2022-01-19-cudnn_安装"}},{"title":"Google-GNMT","date":"2022-01-10T00:00:00.000Z","tags":["AI"],"lastmod":"2022-01-10T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了Google的神经机器翻译系统,采用了深层LSTM、残差连接、注意力机制等技术来提高翻译质量。系统使用wordpiece模型来处理稀有词,并通过强化学习、beam search优化等方法进一步改进性能。在WMT14英法和英德翻译任务上取得了最佳结果,人工评测中比短语翻译系统错误减少60%。","layout":"PostSimple","type":"Blog","readingTime":{"text":"6 min read","minutes":5.21,"time":312600,"words":1042},"slug":"AI/2022-01-10-Google-GNMT","path":"blog/AI/2022-01-10-Google-GNMT","filePath":"blog/AI/2022-01-10-Google-GNMT.mdx","toc":[{"value":"Abstract","url":"#abstract-12","depth":2},{"value":"1 Introduction","url":"#1-introduction-5","depth":2},{"value":"3 Model Architecture","url":"#3-model-architecture-1","depth":2},{"value":"3.1 Residual Connections","url":"#31-residual-connections-1","depth":3},{"value":"3.2 Bi-directional Encoder for First Layer","url":"#32-bi-directional-encoder-for-first-layer-1","depth":3},{"value":"3.3 Model Parallelism","url":"#33-model-parallelism-1","depth":3},{"value":"4. Segmentation Approaches","url":"#4-segmentation-approaches-1","depth":2},{"value":"4.1 Wordpiece Model","url":"#41-wordpiece-model-1","depth":3},{"value":"4.2 Mixed Word/character Model","url":"#42-mixed-wordcharacter-model-1","depth":3},{"value":"5. Training Criteria","url":"#5-training-criteria-1","depth":2},{"value":"6. Quantizable Model and Quantized Inference","url":"#6-quantizable-model-and-quantized-inference-1","depth":2},{"value":"7. Decoder","url":"#7-decoder-1","depth":2},{"value":"8. Experiments and Results","url":"#8-experiments-and-results-1","depth":2},{"value":"8.1 Datasets","url":"#81-datasets-1","depth":3},{"value":"8.2 Evaluation Metrics","url":"#82-evaluation-metrics-1","depth":3},{"value":"8.3 Training Procedure","url":"#83-training-procedure-1","depth":3},{"value":"Evaluation after Maximum Likelihood Training","url":"#evaluation-after-maximum-likelihood-training-1","depth":3},{"value":"8.5 Evaliation of RL-refined Models","url":"#85-evaliation-of-rl-refined-models-1","depth":3},{"value":"8.6 Model Ensemble and Human Evaluation","url":"#86-model-ensemble-and-human-evaluation-1","depth":3},{"value":"8.7 Results on Production Data","url":"#87-results-on-production-data-1","depth":3}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Google-GNMT","datePublished":"2022-01-10T00:00:00.000Z","dateModified":"2022-01-10T00:00:00.000Z","description":"这篇文章介绍了Google的神经机器翻译系统,采用了深层LSTM、残差连接、注意力机制等技术来提高翻译质量。系统使用wordpiece模型来处理稀有词,并通过强化学习、beam search优化等方法进一步改进性能。在WMT14英法和英德翻译任务上取得了最佳结果,人工评测中比短语翻译系统错误减少60%。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2022-01-10-Google-GNMT"}},{"title":"MAC问题列表","date":"2021-12-24T00:00:00.000Z","tags":["Tech"],"lastmod":"2021-12-24T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了两个技术问题的解决方法。第一个是解决Mac系统上文件损坏的问题，通过在终端中输入特定命令来移除应用程序的隔离属性。第二个是关于Docker中docker.raw文件占用空间过大的问题，文章提供了一张图片展示如何调整相关设置。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.32,"time":19200,"words":64},"slug":"Ongoing/2021-12-24-MAC问题列表","path":"blog/Ongoing/2021-12-24-MAC问题列表","filePath":"blog/Ongoing/2021-12-24-MAC问题列表.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"MAC问题列表","datePublished":"2021-12-24T00:00:00.000Z","dateModified":"2021-12-24T00:00:00.000Z","description":"这篇文章介绍了两个技术问题的解决方法。第一个是解决Mac系统上文件损坏的问题，通过在终端中输入特定命令来移除应用程序的隔离属性。第二个是关于Docker中docker.raw文件占用空间过大的问题，文章提供了一张图片展示如何调整相关设置。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Ongoing/2021-12-24-MAC问题列表"}},{"title":"MT_paper简单笔记","date":"2021-12-23T00:00:00.000Z","tags":["AI"],"lastmod":"2021-12-23T00:00:00.000Z","draft":false,"summary":"这篇文章探讨了定制化神经机器翻译模型的开发，介绍了几个相关的开源项目。文章还证明了当前方法在领域适应、数据清洗和数据增强方面的实用性。另外，文章对句子级BLEU评分的平滑技术进行了系统比较，探讨了BLEU评分的应用原因。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.33,"time":19800,"words":66},"slug":"AI/2021-12-23-MT_paper简单笔记","path":"blog/AI/2021-12-23-MT_paper简单笔记","filePath":"blog/AI/2021-12-23-MT_paper简单笔记.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"MT_paper简单笔记","datePublished":"2021-12-23T00:00:00.000Z","dateModified":"2021-12-23T00:00:00.000Z","description":"这篇文章探讨了定制化神经机器翻译模型的开发，介绍了几个相关的开源项目。文章还证明了当前方法在领域适应、数据清洗和数据增强方面的实用性。另外，文章对句子级BLEU评分的平滑技术进行了系统比较，探讨了BLEU评分的应用原因。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-12-23-MT_paper简单笔记"}},{"title":"计算机辅助翻译-coursera课程1-3","date":"2021-12-23T00:00:00.000Z","tags":["AI"],"lastmod":"2021-12-23T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了计算机辅助翻译(CAT)的相关知识,包括翻译过程、译员能力评估、翻译问题分类等。文章还讨论了翻译技术的组成,如翻译记忆、术语管理等,以及语料库在翻译研究和实践中的应用。最后介绍了一些常用的语料库检索工具。","layout":"PostSimple","type":"Blog","readingTime":{"text":"9 min read","minutes":8.815,"time":528900,"words":1763},"slug":"AI/2021-12-23-计算机辅助翻译-coursera课程1-3","path":"blog/AI/2021-12-23-计算机辅助翻译-coursera课程1-3","filePath":"blog/AI/2021-12-23-计算机辅助翻译-coursera课程1-3.mdx","toc":[{"value":"翻译过程的论述","url":"#翻译过程的论述-1","depth":2},{"value":"译员翻译能力评估","url":"#译员翻译能力评估-1","depth":2},{"value":"翻译问题分类","url":"#翻译问题分类-1","depth":2},{"value":"辞典问题","url":"#辞典问题-1","depth":2},{"value":"翻译技术组成","url":"#翻译技术组成-1","depth":2},{"value":"常用工具","url":"#常用工具-1","depth":3},{"value":"自动化翻译","url":"#自动化翻译-1","depth":3},{"value":"商用计算机辅助翻译软件","url":"#商用计算机辅助翻译软件-1","depth":3},{"value":"语料库","url":"#语料库-1","depth":3},{"value":"互联网搜索引擎/信息服务翻译实践","url":"#互联网搜索引擎信息服务翻译实践-1","depth":2},{"value":"搜索引擎的分类","url":"#搜索引擎的分类-1","depth":3},{"value":"基本工作原理","url":"#基本工作原理-1","depth":3},{"value":"使用规则","url":"#使用规则-1","depth":3},{"value":"学术数据库 电子期刊数据库","url":"#学术数据库-电子期刊数据库-1","depth":3},{"value":"学术数据库一般流程","url":"#学术数据库一般流程-1","depth":3},{"value":"语料库与翻译研究","url":"#语料库与翻译研究-1","depth":2},{"value":"语料库产生背景","url":"#语料库产生背景-1","depth":3},{"value":"语料库建设","url":"#语料库建设-1","depth":3},{"value":"语料库特点","url":"#语料库特点-1","depth":3},{"value":"语料库支持的翻译研究和实践","url":"#语料库支持的翻译研究和实践-1","depth":3},{"value":"语料库检索工具","url":"#语料库检索工具-1","depth":3}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"计算机辅助翻译-coursera课程1-3","datePublished":"2021-12-23T00:00:00.000Z","dateModified":"2021-12-23T00:00:00.000Z","description":"这篇文章主要介绍了计算机辅助翻译(CAT)的相关知识,包括翻译过程、译员能力评估、翻译问题分类等。文章还讨论了翻译技术的组成,如翻译记忆、术语管理等,以及语料库在翻译研究和实践中的应用。最后介绍了一些常用的语料库检索工具。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-12-23-计算机辅助翻译-coursera课程1-3"}},{"title":"Deep_Transformer（DLCL,_pre-norm）","date":"2021-12-14T00:00:00.000Z","tags":["AI"],"lastmod":"2021-12-14T00:00:00.000Z","draft":false,"summary":"这篇文章提出了两种方法来改进Transformer模型用于机器翻译:pre-norm和dlcl。这些方法可以训练更深的网络,缓解梯度消失问题,同时减小模型大小并加快训练速度。实验结果显示BLEU分数提升0.4-2.4分,但整体性能提升不大。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.645,"time":38700,"words":129},"slug":"AI/2021-12-14-Deep_Transformer（DLCL,_pre-norm）","path":"blog/AI/2021-12-14-Deep_Transformer（DLCL,_pre-norm）","filePath":"blog/AI/2021-12-14-Deep_Transformer（DLCL,_pre-norm）.mdx","toc":[{"value":"pre-norm","url":"#pre-norm-1","depth":2},{"value":"Dynamic Linear Combination of Layers","url":"#dynamic-linear-combination-of-layers-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Deep_Transformer（DLCL,_pre-norm）","datePublished":"2021-12-14T00:00:00.000Z","dateModified":"2021-12-14T00:00:00.000Z","description":"这篇文章提出了两种方法来改进Transformer模型用于机器翻译:pre-norm和dlcl。这些方法可以训练更深的网络,缓解梯度消失问题,同时减小模型大小并加快训练速度。实验结果显示BLEU分数提升0.4-2.4分,但整体性能提升不大。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-12-14-Deep_Transformer（DLCL,_pre-norm）"}},{"title":"tensor2tensor框架记录","date":"2021-12-09T00:00:00.000Z","tags":["AI"],"lastmod":"2021-12-09T00:00:00.000Z","draft":false,"summary":"这篇文章主要讨论了tensor2tensor和tensorflow的版本依赖问题，以及一些重要参数的设置。文章重点介绍了学习率的计算方式，包括constant、linear_warmup、rsqrt_decay和rsqrt_hidden_size四个部分，并提供了一个Python函数来计算学习率。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.635,"time":38100,"words":127},"slug":"AI/2021-12-09-tensor2tensor框架记录","path":"blog/AI/2021-12-09-tensor2tensor框架记录","filePath":"blog/AI/2021-12-09-tensor2tensor框架记录.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"tensor2tensor框架记录","datePublished":"2021-12-09T00:00:00.000Z","dateModified":"2021-12-09T00:00:00.000Z","description":"这篇文章主要讨论了tensor2tensor和tensorflow的版本依赖问题，以及一些重要参数的设置。文章重点介绍了学习率的计算方式，包括constant、linear_warmup、rsqrt_decay和rsqrt_hidden_size四个部分，并提供了一个Python函数来计算学习率。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-12-09-tensor2tensor框架记录"}},{"title":"邻近搜索","date":"2021-12-05T00:00:00.000Z","tags":["AI"],"lastmod":"2021-12-05T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了几种用于大数据场景下邻近搜索的算法,包括Annoy、HNSW、KD Tree和LSH。文章重点讲解了Annoy和HNSW两种算法的原理和实现方法,Annoy通过建立二叉树来实现快速查找,HNSW则是基于图结构并引入了分层机制来提高搜索效率。","layout":"PostSimple","type":"Blog","readingTime":{"text":"5 min read","minutes":4.115,"time":246900,"words":823},"slug":"AI/2021-12-05-邻近搜索","path":"blog/AI/2021-12-05-邻近搜索","filePath":"blog/AI/2021-12-05-邻近搜索.mdx","toc":[{"value":"邻近搜索","url":"#邻近搜索-1","depth":3},{"value":"Annoy","url":"#annoy-1","depth":4},{"value":"HNSW","url":"#hnsw-1","depth":4},{"value":"KD Tree","url":"#kd-tree-1","depth":4},{"value":"LSH 局部敏感哈希","url":"#lsh-局部敏感哈希-1","depth":4}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"邻近搜索","datePublished":"2021-12-05T00:00:00.000Z","dateModified":"2021-12-05T00:00:00.000Z","description":"这篇文章主要介绍了几种用于大数据场景下邻近搜索的算法,包括Annoy、HNSW、KD Tree和LSH。文章重点讲解了Annoy和HNSW两种算法的原理和实现方法,Annoy通过建立二叉树来实现快速查找,HNSW则是基于图结构并引入了分层机制来提高搜索效率。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-12-05-邻近搜索"}},{"title":"HMM_参数估计","date":"2021-11-28T00:00:00.000Z","tags":["AI"],"lastmod":"2021-11-28T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了隐马尔可夫模型(HMM)的基本概念和两个主要任务:推断和参数估计。文章详细讲解了完整数据和不完整数据情况下的参数估计方法,包括EM算法、前向-后向算法等,并给出了估计初始概率分布、发射概率和转移概率矩阵的具体步骤。","layout":"PostSimple","type":"Blog","readingTime":{"text":"3 min read","minutes":2.425,"time":145500,"words":485},"slug":"AI/2021-11-28-HMM_参数估计","path":"blog/AI/2021-11-28-HMM_参数估计","filePath":"blog/AI/2021-11-28-HMM_参数估计.mdx","toc":[{"value":"HMM基本概念","url":"#hmm基本概念-1","depth":2},{"value":"参数","url":"#参数-1","depth":3},{"value":"Two Major Tasks","url":"#two-major-tasks-1","depth":3},{"value":"Inference","url":"#inference-2","depth":4},{"value":"参数估计","url":"#参数估计-1","depth":4},{"value":"Complete Case","url":"#complete-case-1","depth":5},{"value":"Incomplete Case","url":"#incomplete-case-1","depth":5},{"value":"估计PI","url":"#估计pi-1","depth":6},{"value":"估计B","url":"#估计b-1","depth":6},{"value":"估计A","url":"#估计a-1","depth":6}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"HMM_参数估计","datePublished":"2021-11-28T00:00:00.000Z","dateModified":"2021-11-28T00:00:00.000Z","description":"这篇文章主要介绍了隐马尔可夫模型(HMM)的基本概念和两个主要任务:推断和参数估计。文章详细讲解了完整数据和不完整数据情况下的参数估计方法,包括EM算法、前向-后向算法等,并给出了估计初始概率分布、发射概率和转移概率矩阵的具体步骤。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-11-28-HMM_参数估计"}},{"title":"梯度消失和BN","date":"2021-11-28T00:00:00.000Z","tags":["AI"],"lastmod":"2021-11-28T00:00:00.000Z","draft":false,"summary":"这篇文章主要讨论了深度学习中的梯度消失问题及其解决方案,以及不同的归一化方法(如BN、LN、WN等)。文章指出,归一化方法可以缓解协变量偏移问题,加速网络收敛,并具有权重和数据伸缩不变性,从而提高模型的鲁棒性和泛化能力。","layout":"PostSimple","type":"Blog","readingTime":{"text":"8 min read","minutes":7.25,"time":435000,"words":1450},"slug":"AI/2021-11-28-梯度消失和BN","path":"blog/AI/2021-11-28-梯度消失和BN","filePath":"blog/AI/2021-11-28-梯度消失和BN.mdx","toc":[{"value":"梯度消失","url":"#梯度消失-1","depth":2},{"value":"Normalization BN/LN/WN","url":"#normalization-bnlnwn-1","depth":2},{"value":"Covariate shift问题：","url":"#covariate-shift问题-1","depth":3},{"value":"BN","url":"#bn-1","depth":3},{"value":"LN","url":"#ln-1","depth":3},{"value":"WN","url":"#wn-1","depth":3},{"value":"CN-Cosine Normalization","url":"#cn-cosine-normalization-1","depth":3},{"value":"Normalization为什么有效","url":"#normalization为什么有效-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"梯度消失和BN","datePublished":"2021-11-28T00:00:00.000Z","dateModified":"2021-11-28T00:00:00.000Z","description":"这篇文章主要讨论了深度学习中的梯度消失问题及其解决方案,以及不同的归一化方法(如BN、LN、WN等)。文章指出,归一化方法可以缓解协变量偏移问题,加速网络收敛,并具有权重和数据伸缩不变性,从而提高模型的鲁棒性和泛化能力。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-11-28-梯度消失和BN"}},{"title":"生物医学BERT","date":"2021-11-23T00:00:00.000Z","tags":["AI"],"lastmod":"2021-11-23T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了几个生物医学领域的预训练语言模型,包括BioBERT、中文MC-BERT、Clinical BERT和Med-BERT。这些模型都是在大规模生物医学文本数据上进行预训练,以适应生物医学文本挖掘任务。文章还比较了不同模型的训练数据、训练策略和下游任务表现。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.455,"time":87300,"words":291},"slug":"AI/2021-11-23-生物医学BERT","path":"blog/AI/2021-11-23-生物医学BERT","filePath":"blog/AI/2021-11-23-生物医学BERT.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"生物医学BERT","datePublished":"2021-11-23T00:00:00.000Z","dateModified":"2021-11-23T00:00:00.000Z","description":"这篇文章介绍了几个生物医学领域的预训练语言模型,包括BioBERT、中文MC-BERT、Clinical BERT和Med-BERT。这些模型都是在大规模生物医学文本数据上进行预训练,以适应生物医学文本挖掘任务。文章还比较了不同模型的训练数据、训练策略和下游任务表现。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-11-23-生物医学BERT"}},{"title":"常用正则_python_re","date":"2021-11-22T00:00:00.000Z","tags":["Tech"],"lastmod":"2021-11-22T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了使用Python的re模块进行文本处理的几个实用技巧。主要包括移除标点符号、拆分连在一起的英文句子、匹配特殊符号以及替换多余空格等操作，展示了正则表达式在文本清理和格式化中的应用。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.88,"time":52800,"words":176},"slug":"Ongoing/2021-11-22-常用正则_python_re","path":"blog/Ongoing/2021-11-22-常用正则_python_re","filePath":"blog/Ongoing/2021-11-22-常用正则_python_re.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"常用正则_python_re","datePublished":"2021-11-22T00:00:00.000Z","dateModified":"2021-11-22T00:00:00.000Z","description":"这篇文章介绍了使用Python的re模块进行文本处理的几个实用技巧。主要包括移除标点符号、拆分连在一起的英文句子、匹配特殊符号以及替换多余空格等操作，展示了正则表达式在文本清理和格式化中的应用。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Ongoing/2021-11-22-常用正则_python_re"}},{"title":"不同数据噪音对SMT_NMT模型的影响","date":"2021-11-18T00:00:00.000Z","tags":["AI"],"lastmod":"2021-11-18T00:00:00.000Z","draft":false,"summary":"这篇文章研究了不同类型噪音数据对神经机器翻译(NMT)和统计机器翻译(SMT)的影响。结果表明，NMT对噪音数据更敏感，特别是未翻译句子对NMT影响最大；而SMT对噪音数据的抵抗力较强。短句段(2-5个词)对两种模型都有轻微的增强作用。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.955,"time":57300,"words":191},"slug":"AI/2021-11-18-不同数据噪音对SMT_NMT模型的影响","path":"blog/AI/2021-11-18-不同数据噪音对SMT_NMT模型的影响","filePath":"blog/AI/2021-11-18-不同数据噪音对SMT_NMT模型的影响.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"不同数据噪音对SMT_NMT模型的影响","datePublished":"2021-11-18T00:00:00.000Z","dateModified":"2021-11-18T00:00:00.000Z","description":"这篇文章研究了不同类型噪音数据对神经机器翻译(NMT)和统计机器翻译(SMT)的影响。结果表明，NMT对噪音数据更敏感，特别是未翻译句子对NMT影响最大；而SMT对噪音数据的抵抗力较强。短句段(2-5个词)对两种模型都有轻微的增强作用。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-11-18-不同数据噪音对SMT_NMT模型的影响"}},{"title":"机器翻译模型架构记录","date":"2021-11-17T00:00:00.000Z","tags":["AI"],"lastmod":"2021-11-17T00:00:00.000Z","draft":false,"summary":"这篇文章主要讨论了机器翻译架构的一些研究发现。文章指出LSTM作为解码器在某些情况下性能优于Transformer解码器,并探讨了embedding大小、双向LSTM、注意力机制等因素对翻译性能的影响。文章还比较了不同架构的训练时间和BLEU得分,发现LSTM训练速度快,而基础Transformer模型效果较好。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.645,"time":98700,"words":329},"slug":"AI/2021-11-17-机器翻译模型架构记录","path":"blog/AI/2021-11-17-机器翻译模型架构记录","filePath":"blog/AI/2021-11-17-机器翻译模型架构记录.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"机器翻译模型架构记录","datePublished":"2021-11-17T00:00:00.000Z","dateModified":"2021-11-17T00:00:00.000Z","description":"这篇文章主要讨论了机器翻译架构的一些研究发现。文章指出LSTM作为解码器在某些情况下性能优于Transformer解码器,并探讨了embedding大小、双向LSTM、注意力机制等因素对翻译性能的影响。文章还比较了不同架构的训练时间和BLEU得分,发现LSTM训练速度快,而基础Transformer模型效果较好。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-11-17-机器翻译模型架构记录"}},{"title":"Facebook_AI_2021_WMT论文笔记","date":"2021-11-15T00:00:00.000Z","tags":["AI"],"lastmod":"2021-11-15T00:00:00.000Z","draft":false,"summary":"Facebook AI在WMT21新闻翻译任务中采用了多语言翻译模型和Mixture-of-Expert技术，在14个翻译方向上取得了第一名的成绩。他们使用了加深的Transformer模型作为基线，并通过大规模回译、增加训练数据、模型微调和模型平均等技术进一步提升了翻译质量。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.165,"time":69900,"words":233},"slug":"AI/2021-11-15-Facebook_AI_2021_WMT论文笔记","path":"blog/AI/2021-11-15-Facebook_AI_2021_WMT论文笔记","filePath":"blog/AI/2021-11-15-Facebook_AI_2021_WMT论文笔记.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Facebook_AI_2021_WMT论文笔记","datePublished":"2021-11-15T00:00:00.000Z","dateModified":"2021-11-15T00:00:00.000Z","description":"Facebook AI在WMT21新闻翻译任务中采用了多语言翻译模型和Mixture-of-Expert技术，在14个翻译方向上取得了第一名的成绩。他们使用了加深的Transformer模型作为基线，并通过大规模回译、增加训练数据、模型微调和模型平均等技术进一步提升了翻译质量。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-11-15-Facebook_AI_2021_WMT论文笔记"}},{"title":"Transformer模型训练技巧","date":"2021-11-10T00:00:00.000Z","tags":["AI"],"lastmod":"2021-11-10T00:00:00.000Z","draft":false,"summary":"这篇文章主要探讨了影响Transformer模型训练质量和效率的各种参数设置。作者通过大量实验分析了batch size、学习率、warmup steps、最大句子长度等参数对模型性能的影响,并给出了一些实用的调参建议。文章还比较了不同GPU配置下的训练效果,以及checkpoint averaging等技巧对提升BLEU分数的作用。","layout":"PostSimple","type":"Blog","readingTime":{"text":"9 min read","minutes":8.49,"time":509400,"words":1698},"slug":"AI/2021-11-10-Transformer模型训练技巧","path":"blog/AI/2021-11-10-Transformer模型训练技巧","filePath":"blog/AI/2021-11-10-Transformer模型训练技巧.mdx","toc":[{"value":"摘要","url":"#摘要-3","depth":2},{"value":"评估方法","url":"#评估方法-1","depth":2},{"value":"模型训练停止条件","url":"#模型训练停止条件-1","depth":3},{"value":"数据 与 预处理","url":"#数据-与-预处理-1","depth":2},{"value":"实验","url":"#实验-2","depth":2},{"value":"计算速度 数据吞吐量","url":"#计算速度-数据吞吐量-1","depth":3},{"value":"训练数据大小","url":"#训练数据大小-1","depth":3},{"value":"模型大小","url":"#模型大小-1","depth":3},{"value":"最大训练句子长度","url":"#最大训练句子长度-1","depth":3},{"value":"batch size","url":"#batch-size-1","depth":3},{"value":"学习率和Warmup steps","url":"#学习率和warmup-steps-1","depth":3},{"value":"GPUs","url":"#gpus-1","depth":3},{"value":"多GPU下学习率和warmup step","url":"#多gpu下学习率和warmup-step-1","depth":3},{"value":"重新开始训练","url":"#重新开始训练-1","depth":3},{"value":"checkpoint averaging","url":"#checkpoint-averaging-1","depth":3},{"value":"WMT17 比较","url":"#wmt17-比较-1","depth":2},{"value":"结论","url":"#结论-3","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Transformer模型训练技巧","datePublished":"2021-11-10T00:00:00.000Z","dateModified":"2021-11-10T00:00:00.000Z","description":"这篇文章主要探讨了影响Transformer模型训练质量和效率的各种参数设置。作者通过大量实验分析了batch size、学习率、warmup steps、最大句子长度等参数对模型性能的影响,并给出了一些实用的调参建议。文章还比较了不同GPU配置下的训练效果,以及checkpoint averaging等技巧对提升BLEU分数的作用。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-11-10-Transformer模型训练技巧"}},{"title":"As_I_began_to_love_myself..._-_Charlie_Chaplin","date":"2021-11-10T00:00:00.000Z","tags":["Life"],"lastmod":"2021-11-10T00:00:00.000Z","draft":false,"summary":"这篇文章探讨了自爱的重要性及其带来的积极影响。作者通过一系列\"当我开始真正爱自己\"的陈述，阐述了自爱如何引导人们获得真实、尊重、成熟、自信等品质。文章强调了接纳自我、活在当下、追求简单和内心智慧的重要性，最终指出生命中的冲突和挑战都是成长的机会。","layout":"PostSimple","type":"Blog","readingTime":{"text":"6 min read","minutes":5.47,"time":328200,"words":1094},"slug":"Life/2021-11-10-As_I_began_to_love_myself..._-_Charlie_Chaplin","path":"blog/Life/2021-11-10-As_I_began_to_love_myself..._-_Charlie_Chaplin","filePath":"blog/Life/2021-11-10-As_I_began_to_love_myself..._-_Charlie_Chaplin.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"As_I_began_to_love_myself..._-_Charlie_Chaplin","datePublished":"2021-11-10T00:00:00.000Z","dateModified":"2021-11-10T00:00:00.000Z","description":"这篇文章探讨了自爱的重要性及其带来的积极影响。作者通过一系列\"当我开始真正爱自己\"的陈述，阐述了自爱如何引导人们获得真实、尊重、成熟、自信等品质。文章强调了接纳自我、活在当下、追求简单和内心智慧的重要性，最终指出生命中的冲突和挑战都是成长的机会。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Life/2021-11-10-As_I_began_to_love_myself..._-_Charlie_Chaplin"}},{"title":"2021_EMNLP_机器翻译预训练和回译的互补性","date":"2021-11-09T00:00:00.000Z","tags":["AI"],"lastmod":"2021-11-09T00:00:00.000Z","draft":false,"summary":"研究了预训练(PT)和反向翻译(BT)对神经机器翻译模型的影响。研究发现PT主要作用于编码器,BT主要作用于解码器,两者具有互补性。结合PT和BT可以提高翻译质量,在WMT16英语-罗马尼亚语和英语-俄语任务上取得了最先进的结果。","layout":"PostSimple","type":"Blog","readingTime":{"text":"5 min read","minutes":4.965,"time":297900,"words":993},"slug":"AI/2021-11-09-2021_EMNLP_机器翻译预训练和回译的互补性","path":"blog/AI/2021-11-09-2021_EMNLP_机器翻译预训练和回译的互补性","filePath":"blog/AI/2021-11-09-2021_EMNLP_机器翻译预训练和回译的互补性.mdx","toc":[{"value":"摘要","url":"#摘要-2","depth":2},{"value":"介绍","url":"#介绍-3","depth":2},{"value":"预备知识","url":"#预备知识-1","depth":2},{"value":"背景","url":"#背景-3","depth":3},{"value":"实验设置","url":"#实验设置-1","depth":3},{"value":"理解PT和BT","url":"#理解pt和bt-1","depth":2},{"value":"使用BT和PT提升","url":"#使用bt和pt提升-1","depth":2},{"value":"未来工作","url":"#未来工作-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"2021_EMNLP_机器翻译预训练和回译的互补性","datePublished":"2021-11-09T00:00:00.000Z","dateModified":"2021-11-09T00:00:00.000Z","description":"研究了预训练(PT)和反向翻译(BT)对神经机器翻译模型的影响。研究发现PT主要作用于编码器,BT主要作用于解码器,两者具有互补性。结合PT和BT可以提高翻译质量,在WMT16英语-罗马尼亚语和英语-俄语任务上取得了最先进的结果。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-11-09-2021_EMNLP_机器翻译预训练和回译的互补性"}},{"title":"机器翻译中域内小样本微调的正则","date":"2021-11-04T00:00:00.000Z","tags":["AI"],"lastmod":"2021-11-04T00:00:00.000Z","draft":false,"summary":"探讨了在神经机器翻译中使用小规模领域数据进行微调时的过拟合问题。作者测试了三种正则化技术(Dropout、MAP-L2和Tuneout)来防止过拟合,发现使用Dropout和MAP-L2的组合可以使训练更加稳定,并显著提高BLEU评分。实验结果表明,正则化技术可以有效缓解微调过程中的过拟合问题,提高模型在小数据集上的泛化能力。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.88,"time":112800,"words":376},"slug":"AI/2021-11-04-机器翻译中域内小样本微调的正则","path":"blog/AI/2021-11-04-机器翻译中域内小样本微调的正则","filePath":"blog/AI/2021-11-04-机器翻译中域内小样本微调的正则.mdx","toc":[{"value":"正则化技术","url":"#正则化技术-1","depth":2},{"value":"Dropout","url":"#dropout-1","depth":3},{"value":"MAP-L2","url":"#map-l2-1","depth":3},{"value":"Tuneout","url":"#tuneout-1","depth":3},{"value":"结果","url":"#结果-4","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"机器翻译中域内小样本微调的正则","datePublished":"2021-11-04T00:00:00.000Z","dateModified":"2021-11-04T00:00:00.000Z","description":"探讨了在神经机器翻译中使用小规模领域数据进行微调时的过拟合问题。作者测试了三种正则化技术(Dropout、MAP-L2和Tuneout)来防止过拟合,发现使用Dropout和MAP-L2的组合可以使训练更加稳定,并显著提高BLEU评分。实验结果表明,正则化技术可以有效缓解微调过程中的过拟合问题,提高模型在小数据集上的泛化能力。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-11-04-机器翻译中域内小样本微调的正则"}},{"title":"对比学习-减少翻译漏词错误","date":"2021-11-02T00:00:00.000Z","tags":["AI"],"lastmod":"2021-11-02T00:00:00.000Z","draft":false,"summary":"一种基于对比学习的方法来减少神经机器翻译中的词语遗漏错误。通过随机遗漏、按词频遗漏和按词性遗漏三种方式构建负例，并使用最大边际损失来微调翻译模型，从而提高翻译质量。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.365,"time":21900,"words":73},"slug":"AI/2021-11-02-对比学习-减少翻译漏词错误","path":"blog/AI/2021-11-02-对比学习-减少翻译漏词错误","filePath":"blog/AI/2021-11-02-对比学习-减少翻译漏词错误.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"对比学习-减少翻译漏词错误","datePublished":"2021-11-02T00:00:00.000Z","dateModified":"2021-11-02T00:00:00.000Z","description":"一种基于对比学习的方法来减少神经机器翻译中的词语遗漏错误。通过随机遗漏、按词频遗漏和按词性遗漏三种方式构建负例，并使用最大边际损失来微调翻译模型，从而提高翻译质量。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-11-02-对比学习-减少翻译漏词错误"}},{"title":"2021_transformer_综述（部分）","date":"2021-11-01T00:00:00.000Z","tags":["AI"],"lastmod":"2021-11-01T00:00:00.000Z","draft":false,"summary":"Transformer模型的发展和优化方向。文章分析了Transformer在模型效率、泛化能力和领域适应性方面的改进,并将优化工作分为架构改进、预训练和应用三个方面。文章重点讨论了注意力机制的优化,包括稀疏注意力、线性化注意力等方法,以解决长序列计算复杂度高和缺乏归纳偏置的问题。","layout":"PostSimple","type":"Blog","readingTime":{"text":"6 min read","minutes":5.7,"time":342000,"words":1140},"slug":"AI/2021-11-01-2021_transformer_综述（部分）","path":"blog/AI/2021-11-01-2021_transformer_综述（部分）","filePath":"blog/AI/2021-11-01-2021_transformer_综述（部分）.mdx","toc":[{"value":"1 Introduction","url":"#1-introduction-4","depth":2},{"value":"2. BACKGROUND","url":"#2-background-1","depth":2},{"value":"2.3 Model Analysis","url":"#23-model-analysis-1","depth":3},{"value":"2.4 与其他模型对比","url":"#24-与其他模型对比-1","depth":3},{"value":"self attention分析","url":"#self-attention分析-1","depth":4},{"value":"归纳偏差","url":"#归纳偏差-1","depth":4},{"value":"3. Transformer分类","url":"#3-transformer分类-1","depth":2},{"value":"4. Attention","url":"#4-attention-1","depth":2},{"value":"Sparse Attention","url":"#sparse-attention-1","depth":3},{"value":"基于位置","url":"#基于位置-1","depth":4},{"value":"基于内容","url":"#基于内容-1","depth":4},{"value":"Linearized Attention","url":"#linearized-attention-1","depth":3},{"value":"待续...","url":"#待续-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"2021_transformer_综述（部分）","datePublished":"2021-11-01T00:00:00.000Z","dateModified":"2021-11-01T00:00:00.000Z","description":"Transformer模型的发展和优化方向。文章分析了Transformer在模型效率、泛化能力和领域适应性方面的改进,并将优化工作分为架构改进、预训练和应用三个方面。文章重点讨论了注意力机制的优化,包括稀疏注意力、线性化注意力等方法,以解决长序列计算复杂度高和缺乏归纳偏置的问题。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-11-01-2021_transformer_综述（部分）"}},{"title":"truecase和detruecase使用","date":"2021-10-25T00:00:00.000Z","tags":["AI"],"lastmod":"2021-10-25T00:00:00.000Z","draft":false,"summary":"truecase模型文件的结构和使用方法。文章解释了模型如何记录单词的大小写出现次数,以及在truecase过程中如何保留某些词的原有大小写形式。最后提到通常需要在truecase后进行detruecase,以恢复句首字母的大写。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.775,"time":46500,"words":155},"slug":"AI/2021-10-25-truecase和detruecase使用","path":"blog/AI/2021-10-25-truecase和detruecase使用","filePath":"blog/AI/2021-10-25-truecase和detruecase使用.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"truecase和detruecase使用","datePublished":"2021-10-25T00:00:00.000Z","dateModified":"2021-10-25T00:00:00.000Z","description":"truecase模型文件的结构和使用方法。文章解释了模型如何记录单词的大小写出现次数,以及在truecase过程中如何保留某些词的原有大小写形式。最后提到通常需要在truecase后进行detruecase,以恢复句首字母的大写。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-10-25-truecase和detruecase使用"}},{"title":"2018-2019_Tecent_AI_Lab_machine_translation_相关内容","date":"2021-10-13T00:00:00.000Z","tags":["AI"],"lastmod":"2021-10-13T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了机器翻译中的语言理解和条件生成两个关键问题。文章讨论了深度网络、多头注意力机制和自注意力网络等方面的改进,以提高语言理解能力。在条件生成方面,文章提出了鲁棒transformer、全面转换和信息流等方法来优化生成过程。","layout":"PostSimple","type":"Blog","readingTime":{"text":"4 min read","minutes":3.865,"time":231900,"words":773},"slug":"AI/2021-10-13-2018-2019_Tecent_AI_Lab_machine_translation_相关内容","path":"blog/AI/2021-10-13-2018-2019_Tecent_AI_Lab_machine_translation_相关内容","filePath":"blog/AI/2021-10-13-2018-2019_Tecent_AI_Lab_machine_translation_相关内容.mdx","toc":[{"value":"Language Understanding","url":"#language-understanding-1","depth":2},{"value":"Deep Networks","url":"#deep-networks-1","depth":3},{"value":"Multi-Head Attention","url":"#multi-head-attention-1","depth":3},{"value":"Self-Attention","url":"#self-attention-1","depth":3},{"value":"Encoder Representation Interpretation","url":"#encoder-representation-interpretation-1","depth":3},{"value":"Conditional Generation","url":"#conditional-generation-1","depth":2},{"value":"Robust Transformer","url":"#robust-transformer-1","depth":3},{"value":"Full transformation","url":"#full-transformation-1","depth":3},{"value":"Information Flow","url":"#information-flow-1","depth":3},{"value":"2018 CIPS Summer","url":"#2018-cips-summer-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"2018-2019_Tecent_AI_Lab_machine_translation_相关内容","datePublished":"2021-10-13T00:00:00.000Z","dateModified":"2021-10-13T00:00:00.000Z","description":"这篇文章主要介绍了机器翻译中的语言理解和条件生成两个关键问题。文章讨论了深度网络、多头注意力机制和自注意力网络等方面的改进,以提高语言理解能力。在条件生成方面,文章提出了鲁棒transformer、全面转换和信息流等方法来优化生成过程。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-10-13-2018-2019_Tecent_AI_Lab_machine_translation_相关内容"}},{"title":"为什么使用self-attention,机器翻译下的评估","date":"2021-10-09T00:00:00.000Z","tags":["AI"],"lastmod":"2021-10-09T00:00:00.000Z","draft":false,"summary":"这篇文章主要比较了RNNs、CNNs和self-attention网络在机器翻译中的表现。实验发现,在长距离主谓一致任务中,RNNs的表现优于CNNs和self-attention网络;而在词义消歧任务中,self-attention网络(Transformer)的语义特征提取能力最强。文章指出评估神经机器翻译模型架构需要考虑内在因素的权衡,而不仅仅关注BLEU分数。","layout":"PostSimple","type":"Blog","readingTime":{"text":"6 min read","minutes":5.5,"time":330000,"words":1100},"slug":"AI/2021-10-09-为什么使用self-attention,机器翻译下的评估","path":"blog/AI/2021-10-09-为什么使用self-attention,机器翻译下的评估","filePath":"blog/AI/2021-10-09-为什么使用self-attention,机器翻译下的评估.mdx","toc":[{"value":"Introduction","url":"#introduction-18","depth":2},{"value":"相关工作","url":"#相关工作-2","depth":2},{"value":"背景","url":"#背景-2","depth":2},{"value":"主谓一致","url":"#主谓一致-1","depth":2},{"value":"针对CNNs研究","url":"#针对cnns研究-1","depth":3},{"value":"RNNs vs. Transformer","url":"#rnns-vs-transformer-1","depth":3},{"value":"WSD词义消歧","url":"#wsd词义消歧-1","depth":2},{"value":"Post-publication Experiments","url":"#post-publication-experiments-1","depth":2},{"value":"结论","url":"#结论-2","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"为什么使用self-attention,机器翻译下的评估","datePublished":"2021-10-09T00:00:00.000Z","dateModified":"2021-10-09T00:00:00.000Z","description":"这篇文章主要比较了RNNs、CNNs和self-attention网络在机器翻译中的表现。实验发现,在长距离主谓一致任务中,RNNs的表现优于CNNs和self-attention网络;而在词义消歧任务中,self-attention网络(Transformer)的语义特征提取能力最强。文章指出评估神经机器翻译模型架构需要考虑内在因素的权衡,而不仅仅关注BLEU分数。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-10-09-为什么使用self-attention,机器翻译下的评估"}},{"title":"2021_Facebook_AI_BPE对Transformer模型记忆力的影响","date":"2021-10-08T00:00:00.000Z","tags":["AI"],"lastmod":"2021-10-08T00:00:00.000Z","draft":false,"summary":"这篇文章主要研究了BPE词表大小对Transformer模型记忆能力的影响。实验表明,增加BPE词表大小可以提高模型的记忆能力,原因可能是BPE减少了训练序列的长度。作者通过三个任务验证了这一结论,并排除了其他可能的解释,最终确定序列长度的减少是观察到记忆效果增强的主要因素。","layout":"PostSimple","type":"Blog","readingTime":{"text":"6 min read","minutes":5.495,"time":329700,"words":1099},"slug":"AI/2021-10-08-2021_Facebook_AI_BPE对Transformer模型记忆力的影响","path":"blog/AI/2021-10-08-2021_Facebook_AI_BPE对Transformer模型记忆力的影响","filePath":"blog/AI/2021-10-08-2021_Facebook_AI_BPE对Transformer模型记忆力的影响.mdx","toc":[{"value":"学习记忆任务","url":"#学习记忆任务-1","depth":2},{"value":"学习随机标签映射","url":"#学习随机标签映射-1","depth":3},{"value":"成员推理","url":"#成员推理-1","depth":3},{"value":"训练数据恢复","url":"#训练数据恢复-1","depth":3},{"value":"模型和超参数","url":"#模型和超参数-1","depth":2},{"value":"BPE 设置","url":"#bpe-设置-1","depth":3},{"value":"控制学习参数的数量","url":"#控制学习参数的数量-1","depth":3},{"value":"改变模型为分类器","url":"#改变模型为分类器-1","depth":3},{"value":"模型和训练细节","url":"#模型和训练细节-1","depth":3},{"value":"BPE影响记忆实验","url":"#bpe影响记忆实验-1","depth":2},{"value":"解释","url":"#解释-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"2021_Facebook_AI_BPE对Transformer模型记忆力的影响","datePublished":"2021-10-08T00:00:00.000Z","dateModified":"2021-10-08T00:00:00.000Z","description":"这篇文章主要研究了BPE词表大小对Transformer模型记忆能力的影响。实验表明,增加BPE词表大小可以提高模型的记忆能力,原因可能是BPE减少了训练序列的长度。作者通过三个任务验证了这一结论,并排除了其他可能的解释,最终确定序列长度的减少是观察到记忆效果增强的主要因素。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-10-08-2021_Facebook_AI_BPE对Transformer模型记忆力的影响"}},{"title":"2018_ACL_迭代回译","date":"2021-09-29T00:00:00.000Z","tags":["AI"],"lastmod":"2021-09-29T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了迭代回译技术在神经机器翻译中的应用。研究表明,使用高质量的模型进行回译可以显著提升翻译质量,在高资源和低资源场景下都能取得良好效果。文章还探讨了单语数据利用、模型质量影响等相关问题,为迭代回译技术的应用提供了实践指导。","layout":"PostSimple","type":"Blog","readingTime":{"text":"4 min read","minutes":3.78,"time":226800,"words":756},"slug":"AI/2021-09-29-2018_ACL_迭代回译","path":"blog/AI/2021-09-29-2018_ACL_迭代回译","filePath":"blog/AI/2021-09-29-2018_ACL_迭代回译.mdx","toc":[{"value":"单语数据利用相关工作","url":"#单语数据利用相关工作-1","depth":2},{"value":"模型回译质量的影响","url":"#模型回译质量的影响-1","depth":2},{"value":"高资源数据实验","url":"#高资源数据实验-1","depth":2},{"value":"低资源数据实验","url":"#低资源数据实验-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"2018_ACL_迭代回译","datePublished":"2021-09-29T00:00:00.000Z","dateModified":"2021-09-29T00:00:00.000Z","description":"这篇文章主要介绍了迭代回译技术在神经机器翻译中的应用。研究表明,使用高质量的模型进行回译可以显著提升翻译质量,在高资源和低资源场景下都能取得良好效果。文章还探讨了单语数据利用、模型质量影响等相关问题,为迭代回译技术的应用提供了实践指导。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-09-29-2018_ACL_迭代回译"}},{"title":"2018_ACL_The_Best_of_Both_Worlds:_Combining_Recent_Advances_in_Neural_Machine_翻译笔记","date":"2021-09-28T00:00:00.000Z","tags":["AI"],"lastmod":"2021-09-28T00:00:00.000Z","draft":false,"summary":"这篇论文提出了改进的RNMT+模型,单模型效果优于Transformer和原始RNN。作者对多头注意力、层归一化等技术进行了消融分析,并通过混合Transformer和RNMT+的编码器和解码器,实验出了更好的模型架构。","layout":"PostSimple","type":"Blog","readingTime":{"text":"7 min read","minutes":6.87,"time":412200,"words":1374},"slug":"AI/2021-09-28-2018_ACL_The_Best_of_Both_Worlds:_Combining_Recent_Advances_in_Neural_Machine_翻译笔记","path":"blog/AI/2021-09-28-2018_ACL_The_Best_of_Both_Worlds:_Combining_Recent_Advances_in_Neural_Machine_翻译笔记","filePath":"blog/AI/2021-09-28-2018_ACL_The_Best_of_Both_Worlds:_Combining_Recent_Advances_in_Neural_Machine_翻译笔记.mdx","toc":[{"value":"Introduction","url":"#introduction-17","depth":2},{"value":"Background","url":"#background-3","depth":2},{"value":"RNN-based NMT Models -RNMT","url":"#rnn-based-nmt-models--rnmt-1","depth":3},{"value":"Convolutional NMT Models - ConvS2S","url":"#convolutional-nmt-models---convs2s-1","depth":2},{"value":"Conditional Transformation-based NMT Models - Transformer","url":"#conditional-transformation-based-nmt-models---transformer-1","depth":3},{"value":"A Theory-Based Characterization of NMT Architectures","url":"#a-theory-based-characterization-of-nmt-architectures-1","depth":3},{"value":"Experiment Setup","url":"#experiment-setup-1","depth":2},{"value":"RNMT+","url":"#rnmt-1","depth":2},{"value":"模型分析比较","url":"#模型分析比较-1","depth":3},{"value":"消融研究","url":"#消融研究-1","depth":2},{"value":"混合NMT模型","url":"#混合nmt模型-1","depth":2},{"value":"Conclusion","url":"#conclusion-1","depth":2},{"value":"模型参数说明","url":"#模型参数说明-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"2018_ACL_The_Best_of_Both_Worlds:_Combining_Recent_Advances_in_Neural_Machine_翻译笔记","datePublished":"2021-09-28T00:00:00.000Z","dateModified":"2021-09-28T00:00:00.000Z","description":"这篇论文提出了改进的RNMT+模型,单模型效果优于Transformer和原始RNN。作者对多头注意力、层归一化等技术进行了消融分析,并通过混合Transformer和RNMT+的编码器和解码器,实验出了更好的模型架构。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-09-28-2018_ACL_The_Best_of_Both_Worlds:_Combining_Recent_Advances_in_Neural_Machine_翻译笔记"}},{"title":"机器翻译的理解","date":"2021-09-27T00:00:00.000Z","tags":["AI"],"lastmod":"2021-09-27T00:00:00.000Z","draft":false,"summary":"这篇文章主要讨论了机器翻译和大规模预训练语言模型在语义理解和系统性知识利用方面的不足。文章指出,当前机器翻译主要依赖于数据和统计规则,缺乏深层语义理解和世界知识的应用,导致翻译质量受限。同时,大规模预训练语言模型虽然规模庞大,但在语义和知识利用方面仍存在不足,需要更合理的内部结构和机制支撑。","layout":"PostSimple","type":"Blog","readingTime":{"text":"3 min read","minutes":2.345,"time":140700,"words":469},"slug":"AI/2021-09-27-机器翻译的理解","path":"blog/AI/2021-09-27-机器翻译的理解","filePath":"blog/AI/2021-09-27-机器翻译的理解.mdx","toc":[{"value":"深度学习机器翻译","url":"#深度学习机器翻译-1","depth":2},{"value":"大规模预训练语言模型","url":"#大规模预训练语言模型-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"机器翻译的理解","datePublished":"2021-09-27T00:00:00.000Z","dateModified":"2021-09-27T00:00:00.000Z","description":"这篇文章主要讨论了机器翻译和大规模预训练语言模型在语义理解和系统性知识利用方面的不足。文章指出,当前机器翻译主要依赖于数据和统计规则,缺乏深层语义理解和世界知识的应用,导致翻译质量受限。同时,大规模预训练语言模型虽然规模庞大,但在语义和知识利用方面仍存在不足,需要更合理的内部结构和机制支撑。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-09-27-机器翻译的理解"}},{"title":"GPT2_领域数据微调","date":"2021-09-16T00:00:00.000Z","tags":["AI"],"lastmod":"2021-09-16T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了如何使用transformers 4.11.0对GPT2-small 12层模型进行微调。文章详细说明了环境准备、数据准备和训练过程，包括使用run_clm.py脚本进行单机多卡训练的具体步骤。最后，文章还解释了如何计算模型的困惑度，即对模型输出的损失进行指数运算。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.845,"time":110700,"words":369},"slug":"AI/2021-09-16-GPT2_领域数据微调","path":"blog/AI/2021-09-16-GPT2_领域数据微调","filePath":"blog/AI/2021-09-16-GPT2_领域数据微调.mdx","toc":[{"value":"环境准备","url":"#环境准备-1","depth":2},{"value":"数据准备","url":"#数据准备-1","depth":2},{"value":"开始训练","url":"#开始训练-2","depth":2},{"value":"困惑度的计算","url":"#困惑度的计算-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"GPT2_领域数据微调","datePublished":"2021-09-16T00:00:00.000Z","dateModified":"2021-09-16T00:00:00.000Z","description":"这篇文章介绍了如何使用transformers 4.11.0对GPT2-small 12层模型进行微调。文章详细说明了环境准备、数据准备和训练过程，包括使用run_clm.py脚本进行单机多卡训练的具体步骤。最后，文章还解释了如何计算模型的困惑度，即对模型输出的损失进行指数运算。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-09-16-GPT2_领域数据微调"}},{"title":"EM算法","date":"2021-09-11T00:00:00.000Z","tags":["AI"],"lastmod":"2021-09-11T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了Jensen不等式和期望最大化(EM)算法。文章首先定义了Jensen不等式,并给出了一个图形化的例子。然后详细推导了EM算法,包括E步和M步,并用抛硬币的例子说明了EM算法的应用过程。","layout":"PostSimple","type":"Blog","readingTime":{"text":"4 min read","minutes":3.29,"time":197400,"words":658},"slug":"AI/2021-09-11-EM算法","path":"blog/AI/2021-09-11-EM算法","filePath":"blog/AI/2021-09-11-EM算法.mdx","toc":[{"value":"Jensen's Inequality","url":"#jensens-inequality-1","depth":2},{"value":"定义","url":"#定义-2","depth":3},{"value":"例子","url":"#例子-5","depth":3},{"value":"Expectation Maximization","url":"#expectation-maximization-1","depth":2},{"value":"硬币的例子","url":"#硬币的例子-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"EM算法","datePublished":"2021-09-11T00:00:00.000Z","dateModified":"2021-09-11T00:00:00.000Z","description":"这篇文章主要介绍了Jensen不等式和期望最大化(EM)算法。文章首先定义了Jensen不等式,并给出了一个图形化的例子。然后详细推导了EM算法,包括E步和M步,并用抛硬币的例子说明了EM算法的应用过程。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-09-11-EM算法"}},{"title":"sentencepiece_user_defined&control_symbols","date":"2021-09-09T00:00:00.000Z","tags":["AI"],"lastmod":"2021-09-09T00:00:00.000Z","draft":false,"summary":"SentencePiece库中用户自定义符号和控制符号的使用方法。用户自定义符号在任何上下文中都被视为一个token，可以在输入句子中出现；而控制符号只保留ID，即使出现在输入文本中也不会被作为一个token处理，用户需要在编码后显式插入ID。","layout":"PostSimple","type":"Blog","readingTime":{"text":"1 min read","minutes":0.845,"time":50700,"words":169},"slug":"AI/2021-09-09-sentencepiece_user_defined&control_symbols","path":"blog/AI/2021-09-09-sentencepiece_user_defined&control_symbols","filePath":"blog/AI/2021-09-09-sentencepiece_user_defined&control_symbols.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"sentencepiece_user_defined&control_symbols","datePublished":"2021-09-09T00:00:00.000Z","dateModified":"2021-09-09T00:00:00.000Z","description":"SentencePiece库中用户自定义符号和控制符号的使用方法。用户自定义符号在任何上下文中都被视为一个token，可以在输入句子中出现；而控制符号只保留ID，即使出现在输入文本中也不会被作为一个token处理，用户需要在编码后显式插入ID。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-09-09-sentencepiece_user_defined&control_symbols"}},{"title":"概率分布-熵","date":"2021-09-09T00:00:00.000Z","tags":["AI"],"lastmod":"2021-09-09T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了概率论中的一些基本概念和特性，包括均值、方差、期望、熵等。文章还通过一个具体的天气预报例子，展示了如何计算联合熵、条件熵和互信息，说明了随机变量之间的相互依赖关系。","layout":"PostSimple","type":"Blog","readingTime":{"text":"4 min read","minutes":3.235,"time":194100,"words":647},"slug":"AI/2021-09-09-概率分布-熵","path":"blog/AI/2021-09-09-概率分布-熵","filePath":"blog/AI/2021-09-09-概率分布-熵.mdx","toc":[{"value":"数据样本集合的特性","url":"#数据样本集合的特性-1","depth":2},{"value":"均值","url":"#均值-1","depth":3},{"value":"方差","url":"#方差-2","depth":3},{"value":"概率分布的特性","url":"#概率分布的特性-1","depth":2},{"value":"期望","url":"#期望-1","depth":3},{"value":"方差","url":"#方差-3","depth":3},{"value":"熵","url":"#熵-1","depth":3},{"value":"联合熵","url":"#联合熵-1","depth":3},{"value":"条件熵","url":"#条件熵-1","depth":3},{"value":"互信息","url":"#互信息-1","depth":3},{"value":"例子","url":"#例子-4","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"概率分布-熵","datePublished":"2021-09-09T00:00:00.000Z","dateModified":"2021-09-09T00:00:00.000Z","description":"这篇文章主要介绍了概率论中的一些基本概念和特性，包括均值、方差、期望、熵等。文章还通过一个具体的天气预报例子，展示了如何计算联合熵、条件熵和互信息，说明了随机变量之间的相互依赖关系。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-09-09-概率分布-熵"}},{"title":"使用SMT特征提高NMT-2016_AAAI_百度","date":"2021-09-07T00:00:00.000Z","tags":["AI"],"lastmod":"2021-09-07T00:00:00.000Z","draft":false,"summary":"这篇文章提出了一种在对数线性框架下将统计机器翻译(SMT)特征与神经机器翻译(NMT)模型集成的方法,以改进NMT的性能。作者组合了三个SMT特征:翻译模型、单词奖励特征和n-gram语言模型,解决了NMT中的OOV问题、翻译不充分问题,并利用了大规模单语数据。实验结果表明,该方法在NIST中英翻译测试集上提升了2.33 BLEU分。","layout":"PostSimple","type":"Blog","readingTime":{"text":"6 min read","minutes":5.335,"time":320100,"words":1067},"slug":"AI/2021-09-07-使用SMT特征提高NMT-2016_AAAI_百度","path":"blog/AI/2021-09-07-使用SMT特征提高NMT-2016_AAAI_百度","filePath":"blog/AI/2021-09-07-使用SMT特征提高NMT-2016_AAAI_百度.mdx","toc":[{"value":"Abstract","url":"#abstract-11","depth":2},{"value":"Introduction","url":"#introduction-16","depth":2},{"value":"Background","url":"#background-2","depth":2},{"value":"log-linear NMT","url":"#log-linear-nmt-1","depth":2},{"value":"Feature Definetion","url":"#feature-definetion-1","depth":3},{"value":"Handling the OOV problem","url":"#handling-the-oov-problem-1","depth":3},{"value":"Decoding","url":"#decoding-1","depth":3},{"value":"Experiments","url":"#experiments-2","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"使用SMT特征提高NMT-2016_AAAI_百度","datePublished":"2021-09-07T00:00:00.000Z","dateModified":"2021-09-07T00:00:00.000Z","description":"这篇文章提出了一种在对数线性框架下将统计机器翻译(SMT)特征与神经机器翻译(NMT)模型集成的方法,以改进NMT的性能。作者组合了三个SMT特征:翻译模型、单词奖励特征和n-gram语言模型,解决了NMT中的OOV问题、翻译不充分问题,并利用了大规模单语数据。实验结果表明,该方法在NIST中英翻译测试集上提升了2.33 BLEU分。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-09-07-使用SMT特征提高NMT-2016_AAAI_百度"}},{"title":"翻译-Finding_the_Words_to_Say:_Hiddent_State_Visualizations_for_Language_Models","date":"2021-08-31T00:00:00.000Z","tags":["AI"],"lastmod":"2021-08-31T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了通过可视化GPT2-XL语言模型隐层状态来探索模型思考过程的方法。文章展示了如何将隐层状态映射到词表并使用softmax计算概率,以及如何查看每层输出token的排名变化,从而分析模型在不同层级的决策过程。通过这些可视化技术,可以洞察模型的内部工作机制,包括句子结构识别、关键词预测以及潜在的性别偏见等。","layout":"PostSimple","type":"Blog","readingTime":{"text":"4 min read","minutes":3.76,"time":225600,"words":752},"slug":"AI/2021-08-31-翻译-Finding_the_Words_to_Say:_Hiddent_State_Visualizations_for_Language_Models","path":"blog/AI/2021-08-31-翻译-Finding_the_Words_to_Say:_Hiddent_State_Visualizations_for_Language_Models","filePath":"blog/AI/2021-08-31-翻译-Finding_the_Words_to_Say:_Hiddent_State_Visualizations_for_Language_Models.mdx","toc":[{"value":"将隐层映射到词表并softmax","url":"#将隐层映射到词表并softmax-1","depth":2},{"value":"查看每层的输出token的排名","url":"#查看每层的输出token的排名-1","depth":2},{"value":"比较相同位置的多个token排名","url":"#比较相同位置的多个token排名-1","depth":2},{"value":"探索的偏见","url":"#探索的偏见-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"翻译-Finding_the_Words_to_Say:_Hiddent_State_Visualizations_for_Language_Models","datePublished":"2021-08-31T00:00:00.000Z","dateModified":"2021-08-31T00:00:00.000Z","description":"这篇文章介绍了通过可视化GPT2-XL语言模型隐层状态来探索模型思考过程的方法。文章展示了如何将隐层状态映射到词表并使用softmax计算概率,以及如何查看每层输出token的排名变化,从而分析模型在不同层级的决策过程。通过这些可视化技术,可以洞察模型的内部工作机制,包括句子结构识别、关键词预测以及潜在的性别偏见等。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-31-翻译-Finding_the_Words_to_Say:_Hiddent_State_Visualizations_for_Language_Models"}},{"title":"PR-ROC-AUC曲线","date":"2021-08-24T00:00:00.000Z","tags":["AI"],"lastmod":"2021-08-24T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了PR曲线和ROC-AUC曲线的概念及特点。PR曲线反映了查准率和查全率之间的关系,通过调节置信度阈值来绘制。ROC-AUC曲线则反映了真正类率和假正类率的关系,其面积不受正负样本比例影响。","layout":"PostSimple","type":"Blog","readingTime":{"text":"3 min read","minutes":2.88,"time":172800,"words":576},"slug":"AI/2021-08-24-PR-ROC-AUC曲线","path":"blog/AI/2021-08-24-PR-ROC-AUC曲线","filePath":"blog/AI/2021-08-24-PR-ROC-AUC曲线.mdx","toc":[{"value":"PR曲线","url":"#pr曲线-1","depth":2},{"value":"ROC-AUC","url":"#roc-auc-1","depth":3}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"PR-ROC-AUC曲线","datePublished":"2021-08-24T00:00:00.000Z","dateModified":"2021-08-24T00:00:00.000Z","description":"这篇文章主要介绍了PR曲线和ROC-AUC曲线的概念及特点。PR曲线反映了查准率和查全率之间的关系,通过调节置信度阈值来绘制。ROC-AUC曲线则反映了真正类率和假正类率的关系,其面积不受正负样本比例影响。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-24-PR-ROC-AUC曲线"}},{"title":"ubuntu18.04_GPU环境搭建","date":"2021-08-23T00:00:00.000Z","tags":["Tech"],"lastmod":"2021-08-23T00:00:00.000Z","draft":false,"summary":"在Linux系统上安装GPU驱动、CUDA和PyTorch的步骤和注意事项。文章详细说明了安装NVIDIA驱动、CUDA工具包的过程,以及可能遇到的问题和解决方法。此外,还提供了验证安装是否成功的方法,以及更换pip源和apt源的相关信息。","layout":"PostSimple","type":"Blog","readingTime":{"text":"4 min read","minutes":3.385,"time":203100,"words":677},"slug":"Tech/2021-08-23-ubuntu18.04_GPU环境搭建","path":"blog/Tech/2021-08-23-ubuntu18.04_GPU环境搭建","filePath":"blog/Tech/2021-08-23-ubuntu18.04_GPU环境搭建.mdx","toc":[{"value":"安装GPU驱动","url":"#安装gpu驱动-1","depth":2},{"value":"安装驱动","url":"#安装驱动-1","depth":3},{"value":"检查驱动是否安装成功","url":"#检查驱动是否安装成功-1","depth":3},{"value":"安装CUDA","url":"#安装cuda-1","depth":3},{"value":"其他错误","url":"#其他错误-1","depth":3},{"value":"pytorch","url":"#pytorch-1","depth":3}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"ubuntu18.04_GPU环境搭建","datePublished":"2021-08-23T00:00:00.000Z","dateModified":"2021-08-23T00:00:00.000Z","description":"在Linux系统上安装GPU驱动、CUDA和PyTorch的步骤和注意事项。文章详细说明了安装NVIDIA驱动、CUDA工具包的过程,以及可能遇到的问题和解决方法。此外,还提供了验证安装是否成功的方法,以及更换pip源和apt源的相关信息。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2021-08-23-ubuntu18.04_GPU环境搭建"}},{"title":"基于字典的跨域神经机器翻译数据增强","date":"2021-08-19T00:00:00.000Z","tags":["AI"],"lastmod":"2021-08-19T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了一种基于字典的数据增强方法,用于跨领域神经机器翻译。该方法通过使用平行领域字典和非领域平行语料,创建伪领域平行语料,主要步骤包括短语句子嵌入、匹配、对齐和替换。实验结果表明,该方法可以有效提高领域覆盖率,改善跨领域神经机器翻译的性能。","layout":"PostSimple","type":"Blog","readingTime":{"text":"3 min read","minutes":2.59,"time":155400,"words":518},"slug":"AI/2021-08-19-基于字典的跨域神经机器翻译数据增强","path":"blog/AI/2021-08-19-基于字典的跨域神经机器翻译数据增强","filePath":"blog/AI/2021-08-19-基于字典的跨域神经机器翻译数据增强.mdx","toc":[{"value":"Dictionary-based Data Augmentation for Cross-domain NMT","url":"#dictionary-based-data-augmentation-for-cross-domain-nmt-1","depth":2},{"value":"Phrase and Sentence Embedding","url":"#phrase-and-sentence-embedding-1","depth":3},{"value":"Phrase-sentence Matching","url":"#phrase-sentence-matching-1","depth":3},{"value":"Phrase Matching, Alignment and Substitution","url":"#phrase-matching-alignment-and-substitution-1","depth":3},{"value":"Experiment settings","url":"#experiment-settings-1","depth":2},{"value":"Further Analysis","url":"#further-analysis-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"基于字典的跨域神经机器翻译数据增强","datePublished":"2021-08-19T00:00:00.000Z","dateModified":"2021-08-19T00:00:00.000Z","description":"这篇文章介绍了一种基于字典的数据增强方法,用于跨领域神经机器翻译。该方法通过使用平行领域字典和非领域平行语料,创建伪领域平行语料,主要步骤包括短语句子嵌入、匹配、对齐和替换。实验结果表明,该方法可以有效提高领域覆盖率,改善跨领域神经机器翻译的性能。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-19-基于字典的跨域神经机器翻译数据增强"}},{"title":"WMT2021-新闻-wechat","date":"2021-08-18T00:00:00.000Z","tags":["AI"],"lastmod":"2021-08-18T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了WeChat在WMT21机器翻译比赛中使用的神经机器翻译系统。主要通过改进模型架构(如Pre-Norm和Post-Norm Transformer、AAN等)和大规模合成数据生成(如反向翻译、知识蒸馏等)来提高翻译性能。文章还探讨了一些先进的微调技术和基于Self-BLEU的模型集成方法,以进一步提升系统效果。","layout":"PostSimple","type":"Blog","readingTime":{"text":"10 min read","minutes":9.625,"time":577500,"words":1925},"slug":"AI/2021-08-18-WMT2021-新闻-wechat","path":"blog/AI/2021-08-18-WMT2021-新闻-wechat","filePath":"blog/AI/2021-08-18-WMT2021-新闻-wechat.mdx","toc":[{"value":"Abstract","url":"#abstract-10","depth":2},{"value":"Introduction","url":"#introduction-15","depth":2},{"value":"Model Archtectures","url":"#model-archtectures-1","depth":2},{"value":"model configurations","url":"#model-configurations-1","depth":3},{"value":"Transformer with Diffetent Layer-Norm","url":"#transformer-with-diffetent-layer-norm-1","depth":3},{"value":"Average Attention Transformer","url":"#average-attention-transformer-1","depth":3},{"value":"Weighted Attention Transformer","url":"#weighted-attention-transformer-1","depth":3},{"value":"Mix-AAN Transformer","url":"#mix-aan-transformer-1","depth":3},{"value":"Talking-Heads Attention","url":"#talking-heads-attention-1","depth":3},{"value":"System Overview","url":"#system-overview-5","depth":2},{"value":"Data Filter","url":"#data-filter-1","depth":3},{"value":"General Domain Synthetic Data","url":"#general-domain-synthetic-data-1","depth":3},{"value":"结果","url":"#结果-3","depth":2},{"value":"不同技巧的BLEU","url":"#不同技巧的bleu-1","depth":3},{"value":"深度宽度网络和Mix-AAN网络的集成效果对比","url":"#深度宽度网络和mix-aan网络的集成效果对比-1","depth":3},{"value":"搜索算法的时间和性能","url":"#搜索算法的时间和性能-1","depth":3},{"value":"不同微调方法","url":"#不同微调方法-1","depth":3}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"WMT2021-新闻-wechat","datePublished":"2021-08-18T00:00:00.000Z","dateModified":"2021-08-18T00:00:00.000Z","description":"这篇文章介绍了WeChat在WMT21机器翻译比赛中使用的神经机器翻译系统。主要通过改进模型架构(如Pre-Norm和Post-Norm Transformer、AAN等)和大规模合成数据生成(如反向翻译、知识蒸馏等)来提高翻译性能。文章还探讨了一些先进的微调技术和基于Self-BLEU的模型集成方法,以进一步提升系统效果。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-18-WMT2021-新闻-wechat"}},{"title":"linux常用命令","date":"2021-08-17T00:00:00.000Z","tags":["Tech"],"lastmod":"2021-08-17T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了一些常用的Linux命令行操作。文章涵盖了端口管理、文件处理、压缩解压、FTP下载等多个方面的命令示例。此外,还包含了一个简短的Python代码片段,用于修改目录下的文件名。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.29,"time":77400,"words":258},"slug":"Ongoing/2021-08-17-linux常用命令","path":"blog/Ongoing/2021-08-17-linux常用命令","filePath":"blog/Ongoing/2021-08-17-linux常用命令.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"linux常用命令","datePublished":"2021-08-17T00:00:00.000Z","dateModified":"2021-08-17T00:00:00.000Z","description":"这篇文章主要介绍了一些常用的Linux命令行操作。文章涵盖了端口管理、文件处理、压缩解压、FTP下载等多个方面的命令示例。此外,还包含了一个简短的Python代码片段,用于修改目录下的文件名。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Ongoing/2021-08-17-linux常用命令"}},{"title":"WMT2019-新闻-Facebook","date":"2021-08-16T00:00:00.000Z","tags":["AI"],"lastmod":"2021-08-16T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了一个机器翻译系统,主要针对英德和英俄翻译方向。系统采用了大规模反向翻译、数据过滤、模型集成和噪声信道模型重排等技术,相比2018年提升了4.5个BLEU分。文章详细描述了数据预处理、模型训练和解码等各个环节的具体做法。","layout":"PostSimple","type":"Blog","readingTime":{"text":"5 min read","minutes":4.355,"time":261300,"words":871},"slug":"AI/2021-08-16-WMT2019-新闻-Facebook","path":"blog/AI/2021-08-16-WMT2019-新闻-Facebook","filePath":"blog/AI/2021-08-16-WMT2019-新闻-Facebook.mdx","toc":[{"value":"Abstract","url":"#abstract-9","depth":2},{"value":"Introduction","url":"#introduction-14","depth":2},{"value":"Data","url":"#data-1","depth":2},{"value":"Data preprocessing","url":"#data-preprocessing-1","depth":3},{"value":"Data filtering","url":"#data-filtering-1","depth":3},{"value":"System Overview","url":"#system-overview-4","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"WMT2019-新闻-Facebook","datePublished":"2021-08-16T00:00:00.000Z","dateModified":"2021-08-16T00:00:00.000Z","description":"这篇文章介绍了一个机器翻译系统,主要针对英德和英俄翻译方向。系统采用了大规模反向翻译、数据过滤、模型集成和噪声信道模型重排等技术,相比2018年提升了4.5个BLEU分。文章详细描述了数据预处理、模型训练和解码等各个环节的具体做法。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-16-WMT2019-新闻-Facebook"}},{"title":"CCMT2020-OPPO","date":"2021-08-15T00:00:00.000Z","tags":["AI"],"lastmod":"2021-08-15T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了OPPO在CCMT 2020机器翻译比赛中的系统设计和发现。OPPO在7个任务方向中的6个排名第一,主要采用了Transformer模型,并使用了回译、领域微调、知识蒸馏等技术。文章还发现,在低资源语料上简单应用不同的中文分词工具,可以在多个任务中带来明显的性能提升。","layout":"PostSimple","type":"Blog","readingTime":{"text":"8 min read","minutes":7.745,"time":464700,"words":1549},"slug":"AI/2021-08-15-CCMT2020-OPPO","path":"blog/AI/2021-08-15-CCMT2020-OPPO","filePath":"blog/AI/2021-08-15-CCMT2020-OPPO.mdx","toc":[{"value":"Introduction","url":"#introduction-12","depth":2},{"value":"Applying Multiple Word Segmentation Tools","url":"#applying-multiple-word-segmentation-tools-1","depth":2},{"value":"English ↔ Chinese Machine Translation Task","url":"#english--chinese-machine-translation-task-1","depth":2},{"value":"Japanese → English Translation Task (Patent Domain)","url":"#japanese--english-translation-task-patent-domain-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"CCMT2020-OPPO","datePublished":"2021-08-15T00:00:00.000Z","dateModified":"2021-08-15T00:00:00.000Z","description":"这篇文章主要介绍了OPPO在CCMT 2020机器翻译比赛中的系统设计和发现。OPPO在7个任务方向中的6个排名第一,主要采用了Transformer模型,并使用了回译、领域微调、知识蒸馏等技术。文章还发现,在低资源语料上简单应用不同的中文分词工具,可以在多个任务中带来明显的性能提升。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-15-CCMT2020-OPPO"}},{"title":"WMT2020-新闻-小牛","date":"2021-08-15T00:00:00.000Z","tags":["AI"],"lastmod":"2021-08-15T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了NiuTrans团队在WMT20机器翻译评测中的系统。该系统在日英和英日翻译方向上排名第一,主要应用了迭代回译、宽深Transformer模型、迭代知识蒸馏和迭代微调等技术。系统的训练步骤包括数据预处理、生成伪数据、多样化翻译模型、知识蒸馏、领域微调和后处理等。","layout":"PostSimple","type":"Blog","readingTime":{"text":"6 min read","minutes":5.065,"time":303900,"words":1013},"slug":"AI/2021-08-15-WMT2020-新闻-小牛","path":"blog/AI/2021-08-15-WMT2020-新闻-小牛","filePath":"blog/AI/2021-08-15-WMT2020-新闻-小牛.mdx","toc":[{"value":"Introduction","url":"#introduction-13","depth":2},{"value":"System overview","url":"#system-overview-3","depth":2},{"value":"Data Preprocessing and Filtering","url":"#data-preprocessing-and-filtering-1","depth":3},{"value":"Iterativa Back Translation","url":"#iterativa-back-translation-1","depth":3},{"value":"Multilingual Model","url":"#multilingual-model-1","depth":3},{"value":"Model Architectures and Ensemble","url":"#model-architectures-and-ensemble-1","depth":3},{"value":"Iterative KD and Fine-tuning","url":"#iterative-kd-and-fine-tuning-1","depth":3},{"value":"Reranking","url":"#reranking-3","depth":3},{"value":"Post Editing","url":"#post-editing-1","depth":3},{"value":"Experiment","url":"#experiment-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"WMT2020-新闻-小牛","datePublished":"2021-08-15T00:00:00.000Z","dateModified":"2021-08-15T00:00:00.000Z","description":"这篇文章介绍了NiuTrans团队在WMT20机器翻译评测中的系统。该系统在日英和英日翻译方向上排名第一,主要应用了迭代回译、宽深Transformer模型、迭代知识蒸馏和迭代微调等技术。系统的训练步骤包括数据预处理、生成伪数据、多样化翻译模型、知识蒸馏、领域微调和后处理等。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-15-WMT2020-新闻-小牛"}},{"title":"Atman机器翻译模型笔记","date":"2021-08-13T00:00:00.000Z","tags":["AI"],"lastmod":"2021-08-13T00:00:00.000Z","draft":false,"summary":"这篇文章主要介绍了机器翻译模型的训练过程和数据处理方法。文章详细描述了从大规模语料训练基础模型到领域精调的完整流程,包括使用平行语料和单语回译语料进行训练,以及采用联合训练、EWC约束等技术来优化模型性能。此外,文章还讨论了语料清洗和数据增强的方法,如使用语言模型、句对相似度和统计规则进行数据筛选,以及通过反向翻译和对偶学习等技术来扩充训练数据。","layout":"PostSimple","type":"Blog","readingTime":{"text":"8 min read","minutes":7.215,"time":432900,"words":1443},"slug":"AI/2021-08-13-Atman机器翻译模型笔记","path":"blog/AI/2021-08-13-Atman机器翻译模型笔记","filePath":"blog/AI/2021-08-13-Atman机器翻译模型笔记.mdx","toc":[{"value":"Atman","url":"#atman-1","depth":3}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Atman机器翻译模型笔记","datePublished":"2021-08-13T00:00:00.000Z","dateModified":"2021-08-13T00:00:00.000Z","description":"这篇文章主要介绍了机器翻译模型的训练过程和数据处理方法。文章详细描述了从大规模语料训练基础模型到领域精调的完整流程,包括使用平行语料和单语回译语料进行训练,以及采用联合训练、EWC约束等技术来优化模型性能。此外,文章还讨论了语料清洗和数据增强的方法,如使用语言模型、句对相似度和统计规则进行数据筛选,以及通过反向翻译和对偶学习等技术来扩充训练数据。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-13-Atman机器翻译模型笔记"}},{"title":"WMT2020-生物医学-华为","date":"2021-08-13T00:00:00.000Z","tags":["AI"],"lastmod":"2021-08-13T00:00:00.000Z","draft":false,"summary":"华为在WMT20生物医学翻译任务中的方法。研究者探讨了领域内字典对提高跨领域神经机器翻译性能的影响,并利用预训练机器翻译模型进行迁移学习。通过领域数据增强、重排序等技术,在英-法、英-德、英-意大利语对上取得了最先进的结果。","layout":"PostSimple","type":"Blog","readingTime":{"text":"4 min read","minutes":3.58,"time":214800,"words":716},"slug":"AI/2021-08-13-WMT2020-生物医学-华为","path":"blog/AI/2021-08-13-WMT2020-生物医学-华为","filePath":"blog/AI/2021-08-13-WMT2020-生物医学-华为.mdx","toc":[{"value":"Abstract","url":"#abstract-7","depth":2},{"value":"Introduction","url":"#introduction-10","depth":2},{"value":"The Data","url":"#the-data-1","depth":2},{"value":"The Approaches","url":"#the-approaches-1","depth":2},{"value":"In-domain dictionary","url":"#in-domain-dictionary-1","depth":3},{"value":"Reranking","url":"#reranking-2","depth":3},{"value":"Data Processing","url":"#data-processing-1","depth":3},{"value":"Experimental Results","url":"#experimental-results-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"WMT2020-生物医学-华为","datePublished":"2021-08-13T00:00:00.000Z","dateModified":"2021-08-13T00:00:00.000Z","description":"华为在WMT20生物医学翻译任务中的方法。研究者探讨了领域内字典对提高跨领域神经机器翻译性能的影响,并利用预训练机器翻译模型进行迁移学习。通过领域数据增强、重排序等技术,在英-法、英-德、英-意大利语对上取得了最先进的结果。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-13-WMT2020-生物医学-华为"}},{"title":"理解大规模反向翻译","date":"2021-08-13T00:00:00.000Z","tags":["AI"],"lastmod":"2021-08-13T00:00:00.000Z","draft":false,"summary":"1. 研究发现在反向翻译中,使用采样(sampling)或带噪声的束搜索(noised beam search)生成合成数据比标准束搜索或贪心搜索更有效,可以提供更强的训练信号。2. 通过大规模实验比较了合成数据和真实双语数据的效果,以及不同领域数据的影响,在WMT14英德翻译任务上达到了35 BLEU的最佳结果。","layout":"PostSimple","type":"Blog","readingTime":{"text":"7 min read","minutes":6.845,"time":410700,"words":1369},"slug":"AI/2021-08-13-理解大规模反向翻译","path":"blog/AI/2021-08-13-理解大规模反向翻译","filePath":"blog/AI/2021-08-13-理解大规模反向翻译.mdx","toc":[{"value":"Abstract","url":"#abstract-8","depth":2},{"value":"Introduction","url":"#introduction-11","depth":2},{"value":"Generating synthetic sources","url":"#generating-synthetic-sources-1","depth":2},{"value":"Model and hyperparameters","url":"#model-and-hyperparameters-1","depth":2},{"value":"Results","url":"#results-1","depth":2},{"value":"生成方法对比","url":"#生成方法对比-1","depth":3},{"value":"生成方法分析","url":"#生成方法分析-1","depth":3},{"value":"低资源和高资源设置","url":"#低资源和高资源设置-1","depth":3},{"value":"领域的合成数据","url":"#领域的合成数据-1","depth":3},{"value":"bitext上采样","url":"#bitext上采样-1","depth":3},{"value":"大规模上的结果","url":"#大规模上的结果-1","depth":3},{"value":"\bWMT18","url":"#wmt18-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"理解大规模反向翻译","datePublished":"2021-08-13T00:00:00.000Z","dateModified":"2021-08-13T00:00:00.000Z","description":"1. 研究发现在反向翻译中,使用采样(sampling)或带噪声的束搜索(noised beam search)生成合成数据比标准束搜索或贪心搜索更有效,可以提供更强的训练信号。2. 通过大规模实验比较了合成数据和真实双语数据的效果,以及不同领域数据的影响,在WMT14英德翻译任务上达到了35 BLEU的最佳结果。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-13-理解大规模反向翻译"}},{"title":"features","date":"2021-08-07T15:32:14.000Z","tags":["next-js","tailwind","guide"],"lastmod":"2021-02-01T00:00:00.000Z","draft":false,"summary":"An overview of the new features released in v1 - code block copy, multiple authors, frontmatter layout and more","layout":"PostSimple","type":"Blog","readingTime":{"text":"13 min read","minutes":12.5,"time":750000,"words":2500},"slug":"features","path":"blog/features","filePath":"blog/features.mdx","toc":[{"value":"Overview","url":"#overview-1","depth":2},{"value":"Theme colors","url":"#theme-colors-1","depth":2},{"value":"Xdm MDX compiler","url":"#xdm-mdx-compiler-1","depth":2},{"value":"Table of contents component","url":"#table-of-contents-component-1","depth":2},{"value":"Layouts","url":"#layouts-1","depth":2},{"value":"Adding new templates","url":"#adding-new-templates-1","depth":3},{"value":"Configuring a blog post frontmatter","url":"#configuring-a-blog-post-frontmatter-1","depth":3},{"value":"Extend","url":"#extend-1","depth":3},{"value":"Analytics","url":"#analytics-1","depth":2},{"value":"Blog comments system","url":"#blog-comments-system-1","depth":2},{"value":"Multiple authors","url":"#multiple-authors-1","depth":2},{"value":"Multiple authors in blog post","url":"#multiple-authors-in-blog-post-1","depth":3},{"value":"Copy button for code blocks","url":"#copy-button-for-code-blocks-1","depth":2},{"value":"Line highlighting and line numbers","url":"#line-highlighting-and-line-numbers-1","depth":2},{"value":"Newletter component (v1.1.3)","url":"#newletter-component-v113-1","depth":2},{"value":"Bibliography and Citations (v1.2.1)","url":"#bibliography-and-citations-v121-1","depth":2},{"value":"Self-hosted font (v1.5.0)","url":"#self-hosted-font-v150-1","depth":2},{"value":"Upgrade guide","url":"#upgrade-guide-1","depth":2},{"value":"git hub alert","url":"#git-hub-alert-1","depth":2},{"value":"图片","url":"#图片-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"features","datePublished":"2021-08-07T15:32:14.000Z","dateModified":"2021-02-01T00:00:00.000Z","description":"An overview of the new features released in v1 - code block copy, multiple authors, frontmatter layout and more","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/features"}},{"title":"PyTorch矩阵乘法","date":"2020-01-19T00:00:00.000Z","tags":["Tech"],"lastmod":"2020-01-19T00:00:00.000Z","draft":false,"summary":"这篇文章介绍了PyTorch中不同类型的乘法操作及其特性。文章详细解释了element-wise乘法（*）、矩阵乘法（@）、mm()、bmm()、mul()和matmul()等函数的用法和区别。同时，文章还讨论了这些操作对广播（broadcast）的支持情况，并简要说明了广播的规则。","layout":"PostSimple","type":"Blog","readingTime":{"text":"2 min read","minutes":1.91,"time":114600,"words":382},"slug":"Tech/2020-01-19-PyTorch矩阵乘法","path":"blog/Tech/2020-01-19-PyTorch矩阵乘法","filePath":"blog/Tech/2020-01-19-PyTorch矩阵乘法.mdx","toc":[{"value":"$$*$：element-wise乘法，对应元素相乘","url":"#element-wise乘法对应元素相乘-1","depth":3},{"value":"$$@$：矩阵乘法,不支持broadcast操作","url":"#矩阵乘法不支持broadcast操作-1","depth":3},{"value":"二维矩阵乘法 mm()","url":"#二维矩阵乘法-mm-1","depth":3},{"value":"三维带batch的矩阵乘法 bmm()","url":"#三维带batch的矩阵乘法-bmm-1","depth":3},{"value":"element-wise mul()","url":"#element-wise-mul-1","depth":3},{"value":"多维矩阵乘法 matmul()","url":"#多维矩阵乘法-matmul-1","depth":3},{"value":"broadcast","url":"#broadcast-1","depth":3}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"PyTorch矩阵乘法","datePublished":"2020-01-19T00:00:00.000Z","dateModified":"2020-01-19T00:00:00.000Z","description":"这篇文章介绍了PyTorch中不同类型的乘法操作及其特性。文章详细解释了element-wise乘法（*）、矩阵乘法（@）、mm()、bmm()、mul()和matmul()等函数的用法和区别。同时，文章还讨论了这些操作对广播（broadcast）的支持情况，并简要说明了广播的规则。","image":"/static/images/twitter-card.png","url":"https://tailwind-nextjs-starter-blog.vercel.app/blog/Tech/2020-01-19-PyTorch矩阵乘法"}}],"initialDisplayPosts":["$3","$e","$17","$26","$2c"],"pagination":{"currentPage":21,"totalPages":22},"title":"All Posts"}]],null],null]},["$","$L39",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","page","children","$3a","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3b",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},["$","$L39",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","page","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3b",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},["$","$L39",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3b",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"zh-cn","className":"__variable_587f35 scroll-smooth ","suppressHydrationWarning":true,"children":[["$","link",null,{"rel":"apple-touch-icon","sizes":"76x76","href":"/static/favicons/apple-touch-icon.png"}],["$","link",null,{"rel":"icon","type":"image/png","sizes":"32x32","href":"/static/favicons/favicon-32x32.png"}],["$","link",null,{"rel":"icon","type":"image/png","sizes":"16x16","href":"/static/favicons/favicon-16x16.png"}],["$","link",null,{"rel":"icon","type":"image/png","href":"/static/favicons/favicon.ico"}],["$","link",null,{"rel":"manifest","href":"/static/favicons/site.webmanifest"}],["$","link",null,{"rel":"mask-icon","href":"/static/favicons/safari-pinned-tab.svg","color":"#5bbad5"}],["$","meta",null,{"name":"msapplication-TileColor","content":"#000000"}],["$","meta",null,{"name":"theme-color","media":"(prefers-color-scheme: light)","content":"#fff"}],["$","meta",null,{"name":"theme-color","media":"(prefers-color-scheme: dark)","content":"#000"}],["$","link",null,{"rel":"alternate","type":"application/rss+xml","href":"/feed.xml"}],["$","body",null,{"className":"scrollbar-track-slate-400 bg-background pl-[calc(100vw-100%)] antialiased ","children":[["$","$L3c",null,{"gaId":"G-JJL8NM5GV2"}],["$","$L3d",null,{"children":[["$undefined","$undefined","$undefined",["$","$L3e",null,{"async":true,"defer":true,"data-website-id":"$undefined","src":"https://analytics.umami.is/script.js"}],"$undefined","$undefined"],["$","section",null,{"className":"mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0","children":["$","div",null,{"className":"flex h-screen flex-col justify-between font-sans","children":[["$","$L3f",null,{"kbarConfig":{"searchDocumentsPath":"search.json"},"children":[["$","$L40",null,{}],["$","main",null,{"className":"mb-auto pt-20","children":["$","$L39",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3b",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"flex flex-col items-start justify-start md:mt-24 md:flex-row md:items-center md:justify-center md:space-x-6","children":[["$","div",null,{"className":"space-x-2 pb-8 pt-6 md:space-y-5","children":["$","h1",null,{"className":"text-6xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 md:border-r-2 md:px-6 md:text-8xl md:leading-14","children":"404"}]}],["$","div",null,{"className":"max-w-md","children":[["$","p",null,{"className":"mb-4 text-xl font-bold leading-normal md:text-2xl","children":"Sorry we couldn't find this page."}],["$","p",null,{"className":"mb-8","children":"But dont worry, you can find plenty of other things on our homepage."}],["$","$L41",null,{"href":"/","className":"focus:shadow-outline-blue inline rounded-lg border border-transparent bg-blue-600 px-4 py-2 text-sm font-medium leading-5 text-white shadow transition-colors duration-150 hover:bg-blue-700 focus:outline-none dark:hover:bg-blue-500","children":"Back to homepage"}]]}]]}],"notFoundStyles":[],"styles":null}]}]]}],["$","footer",null,{"children":["$","div",null,{"className":"mt-16 flex flex-col items-center","children":[["$","div",null,{"className":"mb-3 flex space-x-4","children":[["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"mailto:tztw4723@gmail.com","children":[["$","span",null,{"className":"sr-only","children":"mail"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 20 20","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Mail"}],["$","path",null,{"d":"M2.003 5.884L10 9.882l7.997-3.998A2 2 0 0016 4H4a2 2 0 00-1.997 1.884z"}],["$","path",null,{"d":"M18 8.118l-8 4-8-4V14a2 2 0 002 2h12a2 2 0 002-2V8.118z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://github.com/taoztw","children":[["$","span",null,{"className":"sr-only","children":"github"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Github"}],["$","path",null,{"d":"M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://facebook.com","children":[["$","span",null,{"className":"sr-only","children":"facebook"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Facebook"}],["$","path",null,{"d":"M24 12.073c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.99 4.388 10.954 10.125 11.854v-8.385H7.078v-3.47h3.047V9.43c0-3.007 1.792-4.669 4.533-4.669 1.312 0 2.686.235 2.686.235v2.953H15.83c-1.491 0-1.956.925-1.956 1.874v2.25h3.328l-.532 3.47h-2.796v8.385C19.612 23.027 24 18.062 24 12.073z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://youtube.com","children":[["$","span",null,{"className":"sr-only","children":"youtube"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Youtube"}],["$","path",null,{"d":"M23.499 6.203a3.008 3.008 0 00-2.089-2.089c-1.87-.501-9.4-.501-9.4-.501s-7.509-.01-9.399.501a3.008 3.008 0 00-2.088 2.09A31.258 31.26 0 000 12.01a31.258 31.26 0 00.523 5.785 3.008 3.008 0 002.088 2.089c1.869.502 9.4.502 9.4.502s7.508 0 9.399-.502a3.008 3.008 0 002.089-2.09 31.258 31.26 0 00.5-5.784 31.258 31.26 0 00-.5-5.808zm-13.891 9.4V8.407l6.266 3.604z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://www.linkedin.com","children":[["$","span",null,{"className":"sr-only","children":"linkedin"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Linkedin"}],["$","path",null,{"d":"M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 01-2.063-2.065 2.064 2.064 0 112.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"}]]}]]}],null,["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://twitter.com/x","children":[["$","span",null,{"className":"sr-only","children":"x"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"X"}],["$","path",null,{"d":"M18.901 1.153h3.68l-8.04 9.19L24 22.846h-7.406l-5.8-7.584-6.638 7.584H.474l8.6-9.83L0 1.154h7.594l5.243 6.932ZM17.61 20.644h2.039L6.486 3.24H4.298Z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://www.instagram.com","children":[["$","span",null,{"className":"sr-only","children":"instagram"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Instagram"}],["$","path",null,{"d":"$42"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://www.threads.net","children":[["$","span",null,{"className":"sr-only","children":"threads"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Threads"}],["$","path",null,{"d":"$43"}]]}]]}]]}],["$","div",null,{"className":"mb-2 flex space-x-2 text-sm text-gray-500 dark:text-gray-400","children":[["$","div",null,{"children":"Tz"}],["$","div",null,{"children":" • "}],["$","div",null,{"children":"© 2024"}],["$","div",null,{"children":" • "}],["$","a",null,{"target":"_blank","rel":"noopener noreferrer","href":"https://beian.miit.gov.cn/","children":"京ICP备2023010160号"}]]}],["$","div",null,{"className":"mb-8 text-sm text-gray-500 dark:text-gray-400","children":["$","a",null,{"target":"_blank","rel":"noopener noreferrer","href":"https://github.com/timlrx/tailwind-nextjs-starter-blog","children":"Tailwind Nextjs Theme"}]}]]}]}]]}]}]]}]]}]]}],null],null],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/59b28d0bb4759951.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/4fdcd319ea1029e9.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","2",{"rel":"stylesheet","href":"/_next/static/css/32b8489dadaace50.css","precedence":"next","crossOrigin":"$undefined"}]],"$L44"]]]]
44:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Tz Blog"}],["$","meta","3",{"name":"description","content":"博客记录学习和生活。"}],["$","meta","4",{"name":"robots","content":"index, follow"}],["$","meta","5",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","6",{"rel":"canonical","href":"https://tailwind-nextjs-starter-blog.vercel.app/blog/page/21"}],["$","link","7",{"rel":"alternate","type":"application/rss+xml","href":"https://tailwind-nextjs-starter-blog.vercel.app/feed.xml"}],["$","meta","8",{"property":"og:title","content":"Tz Blog"}],["$","meta","9",{"property":"og:description","content":"博客记录学习和生活。"}],["$","meta","10",{"property":"og:url","content":"https://tailwind-nextjs-starter-blog.vercel.app/blog/page/21"}],["$","meta","11",{"property":"og:site_name","content":"Tz Blog"}],["$","meta","12",{"property":"og:locale","content":"en_US"}],["$","meta","13",{"property":"og:image","content":"https://tailwind-nextjs-starter-blog.vercel.app/static/images/twitter-card.png"}],["$","meta","14",{"property":"og:type","content":"website"}],["$","meta","15",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","16",{"name":"twitter:title","content":"Tz Blog"}],["$","meta","17",{"name":"twitter:description","content":"博客记录学习和生活。"}],["$","meta","18",{"name":"twitter:image","content":"https://tailwind-nextjs-starter-blog.vercel.app/static/images/twitter-card.png"}],["$","meta","19",{"name":"next-size-adjust"}]]
1:null
