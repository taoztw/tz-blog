3:I[9275,[],""]
5:I[1343,[],""]
6:I[8700,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","315","static/chunks/315-eb1313f9959f8658.js","185","static/chunks/app/layout-2b56166b020f55f9.js"],"ThemeProviders"]
7:I[4080,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","315","static/chunks/315-eb1313f9959f8658.js","185","static/chunks/app/layout-2b56166b020f55f9.js"],""]
8:I[9032,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","315","static/chunks/315-eb1313f9959f8658.js","185","static/chunks/app/layout-2b56166b020f55f9.js"],"KBarSearchProvider"]
9:I[5133,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","315","static/chunks/315-eb1313f9959f8658.js","185","static/chunks/app/layout-2b56166b020f55f9.js"],"default"]
a:I[231,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","797","static/chunks/app/blog/%5B...slug%5D/page-611054ae17c70393.js"],""]
4:["slug","AI/2021-08-13-Atman%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0","c"]
b:T69f,M12 0C8.74 0 8.333.015 7.053.072 5.775.132 4.905.333 4.14.63c-.789.306-1.459.717-2.126 1.384S.935 3.35.63 4.14C.333 4.905.131 5.775.072 7.053.012 8.333 0 8.74 0 12s.015 3.667.072 4.947c.06 1.277.261 2.148.558 2.913.306.788.717 1.459 1.384 2.126.667.666 1.336 1.079 2.126 1.384.766.296 1.636.499 2.913.558C8.333 23.988 8.74 24 12 24s3.667-.015 4.947-.072c1.277-.06 2.148-.262 2.913-.558.788-.306 1.459-.718 2.126-1.384.666-.667 1.079-1.335 1.384-2.126.296-.765.499-1.636.558-2.913.06-1.28.072-1.687.072-4.947s-.015-3.667-.072-4.947c-.06-1.277-.262-2.149-.558-2.913-.306-.789-.718-1.459-1.384-2.126C21.319 1.347 20.651.935 19.86.63c-.765-.297-1.636-.499-2.913-.558C15.667.012 15.26 0 12 0zm0 2.16c3.203 0 3.585.016 4.85.071 1.17.055 1.805.249 2.227.415.562.217.96.477 1.382.896.419.42.679.819.896 1.381.164.422.36 1.057.413 2.227.057 1.266.07 1.646.07 4.85s-.015 3.585-.074 4.85c-.061 1.17-.256 1.805-.421 2.227-.224.562-.479.96-.899 1.382-.419.419-.824.679-1.38.896-.42.164-1.065.36-2.235.413-1.274.057-1.649.07-4.859.07-3.211 0-3.586-.015-4.859-.074-1.171-.061-1.816-.256-2.236-.421-.569-.224-.96-.479-1.379-.899-.421-.419-.69-.824-.9-1.38-.165-.42-.359-1.065-.42-2.235-.045-1.26-.061-1.649-.061-4.844 0-3.196.016-3.586.061-4.861.061-1.17.255-1.814.42-2.234.21-.57.479-.96.9-1.381.419-.419.81-.689 1.379-.898.42-.166 1.051-.361 2.221-.421 1.275-.045 1.65-.06 4.859-.06l.045.03zm0 3.678c-3.405 0-6.162 2.76-6.162 6.162 0 3.405 2.76 6.162 6.162 6.162 3.405 0 6.162-2.76 6.162-6.162 0-3.405-2.76-6.162-6.162-6.162zM12 16c-2.21 0-4-1.79-4-4s1.79-4 4-4 4 1.79 4 4-1.79 4-4 4zm7.846-10.405c0 .795-.646 1.44-1.44 1.44-.795 0-1.44-.646-1.44-1.44 0-.794.646-1.439 1.44-1.439.793-.001 1.44.645 1.44 1.439zc:T498,M12.186 24h-.007c-3.581-.024-6.334-1.205-8.184-3.509C2.35 18.44 1.5 15.586 1.472 12.01v-.017c.03-3.579.879-6.43 2.525-8.482C5.845 1.205 8.6.024 12.18 0h.014c2.746.02 5.043.725 6.826 2.098 1.677 1.29 2.858 3.13 3.509 5.467l-2.04.569c-1.104-3.96-3.898-5.984-8.304-6.015-2.91.022-5.11.936-6.54 2.717C4.307 6.504 3.616 8.914 3.589 12c.027 3.086.718 5.496 2.057 7.164 1.43 1.783 3.631 2.698 6.54 2.717 2.623-.02 4.358-.631 5.8-2.045 1.647-1.613 1.618-3.593 1.09-4.798-.31-.71-.873-1.3-1.634-1.75-.192 1.352-.622 2.446-1.284 3.272-.886 1.102-2.14 1.704-3.73 1.79-1.202.065-2.361-.218-3.259-.801-1.063-.689-1.685-1.74-1.752-2.964-.065-1.19.408-2.285 1.33-3.082.88-.76 2.119-1.207 3.583-1.291a13.853 13.853 0 0 1 3.02.142c-.126-.742-.375-1.332-.75-1.757-.513-.586-1.308-.883-2.359-.89h-.029c-.844 0-1.992.232-2.721 1.32L7.734 7.847c.98-1.454 2.568-2.256 4.478-2.256h.044c3.194.02 5.097 1.975 5.287 5.388.108.046.216.094.321.142 1.49.7 2.58 1.761 3.154 3.07.797 1.82.871 4.79-1.548 7.158-1.85 1.81-4.094 2.628-7.277 2.65Zm1.003-11.69c-.242 0-.487.007-.739.021-1.836.103-2.98.946-2.916 2.143.067 1.256 1.452 1.839 2.784 1.767 1.224-.065 2.818-.543 3.086-3.71a10.5 10.5 0 0 0-2.215-.221z0:["F7zjO8Aul_EEzbsWxRjLL",[[["",{"children":["blog",{"children":[["slug","AI/2021-08-13-Atman%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0","c"],{"children":["__PAGE__?{\"slug\":[\"AI\",\"2021-08-13-Atman机器翻译模型笔记\"]}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["blog",{"children":[["slug","AI/2021-08-13-Atman%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/ddb77e5ad3e10c15.css","precedence":"next","crossOrigin":"$undefined"}]]}],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"zh-cn","className":"__variable_587f35 scroll-smooth ","suppressHydrationWarning":true,"children":[["$","link",null,{"rel":"apple-touch-icon","sizes":"76x76","href":"/static/favicons/apple-touch-icon.png"}],["$","link",null,{"rel":"icon","type":"image/png","sizes":"32x32","href":"/static/favicons/favicon-32x32.png"}],["$","link",null,{"rel":"icon","type":"image/png","sizes":"16x16","href":"/static/favicons/favicon-16x16.png"}],["$","link",null,{"rel":"icon","type":"image/png","href":"/static/favicons/favicon.ico"}],["$","link",null,{"rel":"manifest","href":"/static/favicons/site.webmanifest"}],["$","link",null,{"rel":"mask-icon","href":"/static/favicons/safari-pinned-tab.svg","color":"#5bbad5"}],["$","meta",null,{"name":"msapplication-TileColor","content":"#000000"}],["$","meta",null,{"name":"theme-color","media":"(prefers-color-scheme: light)","content":"#fff"}],["$","meta",null,{"name":"theme-color","media":"(prefers-color-scheme: dark)","content":"#000"}],["$","link",null,{"rel":"alternate","type":"application/rss+xml","href":"/feed.xml"}],["$","body",null,{"className":"scrollbar-track-slate-400 bg-background pl-[calc(100vw-100%)] antialiased ","children":["$","$L6",null,{"children":[["$undefined","$undefined","$undefined",["$","$L7",null,{"async":true,"defer":true,"data-website-id":"$undefined","src":"https://analytics.umami.is/script.js"}],"$undefined","$undefined"],["$","section",null,{"className":"mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0","children":["$","div",null,{"className":"flex h-screen flex-col justify-between font-sans","children":[["$","$L8",null,{"kbarConfig":{"searchDocumentsPath":"search.json"},"children":[["$","$L9",null,{}],["$","main",null,{"className":"mb-auto pt-20","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"flex flex-col items-start justify-start md:mt-24 md:flex-row md:items-center md:justify-center md:space-x-6","children":[["$","div",null,{"className":"space-x-2 pb-8 pt-6 md:space-y-5","children":["$","h1",null,{"className":"text-6xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 md:border-r-2 md:px-6 md:text-8xl md:leading-14","children":"404"}]}],["$","div",null,{"className":"max-w-md","children":[["$","p",null,{"className":"mb-4 text-xl font-bold leading-normal md:text-2xl","children":"Sorry we couldn't find this page."}],["$","p",null,{"className":"mb-8","children":"But dont worry, you can find plenty of other things on our homepage."}],["$","$La",null,{"href":"/","className":"focus:shadow-outline-blue inline rounded-lg border border-transparent bg-blue-600 px-4 py-2 text-sm font-medium leading-5 text-white shadow transition-colors duration-150 hover:bg-blue-700 focus:outline-none dark:hover:bg-blue-500","children":"Back to homepage"}]]}]]}],"notFoundStyles":[],"styles":null}]}]]}],["$","footer",null,{"children":["$","div",null,{"className":"mt-16 flex flex-col items-center","children":[["$","div",null,{"className":"mb-3 flex space-x-4","children":[["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"mailto:tztw4723@gmail.com","children":[["$","span",null,{"className":"sr-only","children":"mail"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 20 20","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Mail"}],["$","path",null,{"d":"M2.003 5.884L10 9.882l7.997-3.998A2 2 0 0016 4H4a2 2 0 00-1.997 1.884z"}],["$","path",null,{"d":"M18 8.118l-8 4-8-4V14a2 2 0 002 2h12a2 2 0 002-2V8.118z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://github.com/taoztw","children":[["$","span",null,{"className":"sr-only","children":"github"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Github"}],["$","path",null,{"d":"M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://facebook.com","children":[["$","span",null,{"className":"sr-only","children":"facebook"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Facebook"}],["$","path",null,{"d":"M24 12.073c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.99 4.388 10.954 10.125 11.854v-8.385H7.078v-3.47h3.047V9.43c0-3.007 1.792-4.669 4.533-4.669 1.312 0 2.686.235 2.686.235v2.953H15.83c-1.491 0-1.956.925-1.956 1.874v2.25h3.328l-.532 3.47h-2.796v8.385C19.612 23.027 24 18.062 24 12.073z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://youtube.com","children":[["$","span",null,{"className":"sr-only","children":"youtube"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Youtube"}],["$","path",null,{"d":"M23.499 6.203a3.008 3.008 0 00-2.089-2.089c-1.87-.501-9.4-.501-9.4-.501s-7.509-.01-9.399.501a3.008 3.008 0 00-2.088 2.09A31.258 31.26 0 000 12.01a31.258 31.26 0 00.523 5.785 3.008 3.008 0 002.088 2.089c1.869.502 9.4.502 9.4.502s7.508 0 9.399-.502a3.008 3.008 0 002.089-2.09 31.258 31.26 0 00.5-5.784 31.258 31.26 0 00-.5-5.808zm-13.891 9.4V8.407l6.266 3.604z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://www.linkedin.com","children":[["$","span",null,{"className":"sr-only","children":"linkedin"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Linkedin"}],["$","path",null,{"d":"M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 01-2.063-2.065 2.064 2.064 0 112.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"}]]}]]}],null,["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://twitter.com/x","children":[["$","span",null,{"className":"sr-only","children":"x"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"X"}],["$","path",null,{"d":"M18.901 1.153h3.68l-8.04 9.19L24 22.846h-7.406l-5.8-7.584-6.638 7.584H.474l8.6-9.83L0 1.154h7.594l5.243 6.932ZM17.61 20.644h2.039L6.486 3.24H4.298Z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://www.instagram.com","children":[["$","span",null,{"className":"sr-only","children":"instagram"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Instagram"}],["$","path",null,{"d":"$b"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://www.threads.net","children":[["$","span",null,{"className":"sr-only","children":"threads"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Threads"}],["$","path",null,{"d":"$c"}]]}]]}]]}],["$","div",null,{"className":"mb-2 flex space-x-2 text-sm text-gray-500 dark:text-gray-400","children":[["$","div",null,{"children":"Tz"}],["$","div",null,{"children":" • "}],["$","div",null,{"children":"© 2024"}],["$","div",null,{"children":" • "}],["$","a",null,{"target":"_blank","rel":"noopener noreferrer","href":"https://beian.miit.gov.cn/","children":"京ICP备2023010160号"}]]}],["$","div",null,{"className":"mb-8 text-sm text-gray-500 dark:text-gray-400","children":["$","a",null,{"target":"_blank","rel":"noopener noreferrer","href":"https://github.com/timlrx/tailwind-nextjs-starter-blog","children":"Tailwind Nextjs Theme"}]}]]}]}]]}]}]]}]}]]}],null],null],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/751c196f8892167f.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/7ac11882585948a1.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","2",{"rel":"stylesheet","href":"/_next/static/css/32b8489dadaace50.css","precedence":"next","crossOrigin":"$undefined"}]],"$Ld"]]]]
e:I[4347,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","797","static/chunks/app/blog/%5B...slug%5D/page-611054ae17c70393.js"],"default"]
f:I[408,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","797","static/chunks/app/blog/%5B...slug%5D/page-611054ae17c70393.js"],"default"]
10:I[9629,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","797","static/chunks/app/blog/%5B...slug%5D/page-611054ae17c70393.js"],"default"]
2:[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BlogPosting\",\"headline\":\"Atman机器翻译模型笔记\",\"datePublished\":\"2021-08-13T00:00:00.000Z\",\"dateModified\":\"2021-08-13T00:00:00.000Z\",\"description\":\"这篇文章主要介绍了机器翻译模型的训练过程和数据处理方法。文章详细描述了从大规模语料训练基础模型到领域精调的完整流程,包括使用平行语料和单语回译语料进行训练,以及采用联合训练、EWC约束等技术来优化模型性能。此外,文章还讨论了语料清洗和数据增强的方法,如使用语言模型、句对相似度和统计规则进行数据筛选,以及通过反向翻译和对偶学习等技术来扩充训练数据。\",\"image\":\"/static/images/twitter-card.png\",\"url\":\"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-13-Atman机器翻译模型笔记\",\"author\":[{\"@type\":\"Person\",\"name\":\"Tz\"}]}"}}],["$","section",null,{"className":"mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0","children":[["$","$Le",null,{}],["$","article",null,{"children":["$","div",null,{"children":[["$","header",null,{"children":["$","div",null,{"className":"space-y-1 border-b border-gray-200 pb-10 text-center dark:border-gray-700","children":[["$","dl",null,{"children":["$","div",null,{"children":[["$","dt",null,{"className":"sr-only","children":"Published on"}],["$","dd",null,{"className":"text-base font-medium leading-6 text-gray-500 dark:text-gray-400","children":["$","time",null,{"dateTime":"2021-08-13T00:00:00.000Z","children":"August 13, 2021"}]}]]}]}],["$","div",null,{"children":["$","h1",null,{"className":"text-3xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 sm:text-4xl sm:leading-10 md:text-5xl md:leading-14","children":"Atman机器翻译模型笔记"}]}]]}]}],["$","div",null,{"className":"grid-rows-[auto_1fr] divide-y divide-gray-200 pb-8 dark:divide-gray-700 xl:divide-y-0","children":[["$","div",null,{"className":"divide-y divide-gray-200 dark:divide-gray-700 xl:col-span-3 xl:row-span-2 xl:pb-0","children":["$","div",null,{"className":"prose max-w-none pb-8 pt-10 dark:prose-invert","children":[["$","h3",null,{"className":"content-header","id":"atman","children":[["$","a",null,{"href":"#atman","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"Atman"]}],["$","$Lf",null,{"className":"language-markdown","children":["$","code",null,{"className":"language-markdown code-highlight","children":[["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token important title","children":[["$","span",null,{"className":"token punctuation","children":"#"}]," 数据"]}],"\n"]}],["$","span",null,{"className":"code-line","children":"\n"}],["$","span",null,{"className":"code-line","children":"大规模的通用领域语料 + 领域内语料（平行 和 单语）\n"}],["$","span",null,{"className":"code-line","children":"\n"}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token important title","children":[["$","span",null,{"className":"token punctuation","children":"#"}]," 训练"]}],"\n"]}],["$","span",null,{"className":"code-line","children":"\n"}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token punctuation list","children":"1."}]," 使用 所有平行语料 训练两个基础模型（英中 中英）\n"]}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token punctuation list","children":"2."}]," 使用 所有平行预料和单语回译语料 继续训练\n"]}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token punctuation list","children":"3."}]," 使用联合训练方法训练数轮 微软：Achieving Human Parity on Automatic Chinese to English News Translation\n"]}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token punctuation list","children":"4."}]," 精调阶段：领域内的数据训练，EWC约束确保对基础模型影响较大的参数不要变太多。然后再进行精调，在每一轮精调过程中，随机采样一些句子进行翻译，用人工评判翻译质量，找到其中的翻译问题。然后，从训练集中找出与有特定问题的翻译句子相似的语料来精调模型，直到这些翻译问题得以缓解。（加入MedDRA术语资源来约束翻译解码，确保关键字翻译的准确和一致）\n"]}],["$","span",null,{"className":"code-line","children":"   Progressive NN ：Progressive Neural Networks 渐进式神经网络https://www.cnblogs.com/zeze/p/8268388.html\n"}],["$","span",null,{"className":"code-line","children":"   pathnet：是progressive nn的generalization。一开始我们每一层都有N个候选模块，对每一个potential的网络，每一层可以使用k个模块。然后我们随机若干个网络（也就是path，如何连接这些模块），然后训练若干episodes。训练了之后，我们用遗传算法，把不好的path都淘汰，留下好的path，然后对这些path进行变异，然后继续训练。最后我们就能获得一个很好的path。\n"}],["$","span",null,{"className":"code-line","children":"   EWC约束：DeepMind：Overcoming catastrophic forgetting in neural networks\n"}],["$","span",null,{"className":"code-line","children":"\n"}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token punctuation list","children":"5."}]," 多模型融合 和 重排序技术 进一步增强翻译效果\n"]}]]}]}],["$","$Lf",null,{"className":"language-markdown","children":["$","code",null,{"className":"language-markdown code-highlight","children":[["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token punctuation blockquote","children":">"}]," 语料问题：双语对齐，领域内外数据，单语质量\n"]}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token punctuation blockquote","children":">"}]," 错别字，乱码，语法错误，不符合所属语言或领域表达习惯\n"]}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token punctuation blockquote","children":">"}]," 如何判断是领域数据？\n"]}],["$","span",null,{"className":"code-line","children":"\n"}],["$","span",null,{"className":"code-line","children":"数据越大、质量越好，模型翻译效果就会越好\n"}],["$","span",null,{"className":"code-line","children":"\n"}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token important title","children":[["$","span",null,{"className":"token punctuation","children":"#"}]," Atman语料清洗"]}],"\n"]}],["$","span",null,{"className":"code-line","children":"\n"}],["$","span",null,{"className":"code-line","children":"语言模型、句对相似度、对齐模型、统计规则\n"}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token bold","children":[["$","span",null,{"className":"token punctuation","children":"**"}],["$","span",null,{"className":"token content","children":"语言模型"}],["$","span",null,{"className":"token punctuation","children":"**"}]]}],"：\n"]}],["$","span",null,{"className":"code-line","children":"进行打分\n"}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token bold","children":[["$","span",null,{"className":"token punctuation","children":"**"}],["$","span",null,{"className":"token content","children":"句对相似度"}],["$","span",null,{"className":"token punctuation","children":"**"}]]}],"：\n"]}],["$","span",null,{"className":"code-line","children":"将每一对训练语料的对调（目标语言句子改作源语言句子，原来的源语言句子作为目标语言句子）也加入训练中去，利用某个领域高质量的平行语料训练一个神经机器双向翻译模型，让编码器学习把源语言句子和目标语言句子都压缩到同一个向量空间中去，然后计算语义相似度。\n"}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token bold","children":[["$","span",null,{"className":"token punctuation","children":"**"}],["$","span",null,{"className":"token content","children":"对齐模型"}],["$","span",null,{"className":"token punctuation","children":"**"}]]}],"：\n"]}],["$","span",null,{"className":"code-line","children":"双语语料词对齐关系，一句英到中的句对翻译，英文单词数是10，中文单词数是8，如果中文中的8个词对应到了英文中的5个词，那对齐比例就是1/2（5：10），那这个比例就偏小，\n"}],["$","span",null,{"className":"code-line","children":"数据利用效率？\n"}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token bold","children":[["$","span",null,{"className":"token punctuation","children":"**"}],["$","span",null,{"className":"token content","children":"统计规则"}],["$","span",null,{"className":"token punctuation","children":"**"}]]}],"：1. 句子中词序列的长度比例 2. 单词的长度，如果单词的长度过长，那么就认为该句话空格丢失 3. 句子中每个词的重复次数，如果某个词在一句话汇总重复次数过多，则可认为不符合表达习惯 4. 句子中关键词（数字，URL等）是否对应出现。\n"]}],["$","span",null,{"className":"code-line","children":["假定这些规则的取值服从某个高斯分布，通过计算这些取值的",["$","span",null,{"className":"token bold","children":[["$","span",null,{"className":"token punctuation","children":"**"}],["$","span",null,{"className":"token content","children":"均值"}],["$","span",null,{"className":"token punctuation","children":"**"}]]}],"和",["$","span",null,{"className":"token bold","children":[["$","span",null,{"className":"token punctuation","children":"**"}],["$","span",null,{"className":"token content","children":"方差"}],["$","span",null,{"className":"token punctuation","children":"**"}]]}],"确定分布，并将某个置信区间之外的数据当做异常点（噪音数据）。这种方法省去了手动设置阈值的烦恼和纠结，概率分布较小的规则取值自动被认为是噪音数据。\n"]}],["$","span",null,{"className":"code-line","children":"\n"}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token important title","children":[["$","span",null,{"className":"token punctuation","children":"#"}]," Atman数据增强"]}],"\n"]}],["$","span",null,{"className":"code-line","children":"\n"}],["$","span",null,{"className":"code-line","children":"举个例子，Amoxicillin（阿莫西林），翻译模型若没见过或只见过特别少的相关训练语料，它就可能不知道这个词如何翻译，这就是语料数量不足的情况。\n"}],["$","span",null,{"className":"code-line","children":"我们可以找一些相似的语料来补充训练集，加强训练，也可以造一批假数据，比如替换其他句子中的药名为阿莫西林给模型训练。\n"}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token bold","children":[["$","span",null,{"className":"token punctuation","children":"**"}],["$","span",null,{"className":"token content","children":"BT"}],["$","span",null,{"className":"token punctuation","children":"**"}]]}],"：\n"]}],["$","span",null,{"className":"code-line","children":"在英中领域：我们使用现有语料训练中英，然后翻译中文单语语料为英文。获得一批平行语料。\n"}],["$","span",null,{"className":"code-line","children":"通过反向模型造一批平行语料，虽然其源语言句子质量不够好，但其目标语言句子是一个正常的句子。这样，模型学习的方向还是朝着一个正常表达的句子的目标来进行的。通过BT方法，语料的丰富程度得到了增强，进而使得模型效果得到大幅提升。\n"}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token bold","children":[["$","span",null,{"className":"token punctuation","children":"**"}],["$","span",null,{"className":"token content","children":"联合训练"}],["$","span",null,{"className":"token punctuation","children":"**"}]]}],"： 半监督方式\n"]}],["$","span",null,{"className":"code-line","children":"对back translation的一种扩展。1. 使用双语训练 英中 中英 模型 2. 使用中英模型将中文单语数据翻译为英文，获得英中伪双语语料，训练 英中 模型 3. 使用 英中 将英文单语语料翻译为 中文，获得中英伪双语语料，训练 中英 模型 4. 如此交替反复\n"}],["$","span",null,{"className":"code-line","children":[["$","span",null,{"className":"token bold","children":[["$","span",null,{"className":"token punctuation","children":"**"}],["$","span",null,{"className":"token content","children":"对偶学习"}],["$","span",null,{"className":"token punctuation","children":"**"}]]}],"： 非监督形式\n"]}],["$","span",null,{"className":"code-line","children":"利用两个语言的单语语料交替训练两个方向的对偶模型。1. 先训练英中和中英两个方向的基线模型。2. 使用英中基础模型将一个英文单语句子以采样的方式翻译成数个中文句子 3. 利用中英基础模型计算将这些中文句子翻译回原始的英文句子的损失（loss），对英中基础模型做提升。\n"}],["$","span",null,{"className":"code-line","children":"使其翻译过程中尽量不丢失信息，提高翻译模型的忠实度。中英方向模型修正过程类似，这样两个模型不断交替更新。\n"}]]}]}]]}]}],["$","div",null,{"className":"pb-6 pt-6 text-center text-gray-700 dark:text-gray-300","id":"comment","children":["$","$L10",null,{"slug":"AI/2021-08-13-Atman机器翻译模型笔记"}]}],["$","footer",null,{"children":["$","div",null,{"className":"flex flex-col text-sm font-medium sm:flex-row sm:justify-between sm:text-base","children":[["$","div",null,{"className":"pt-4 xl:pt-8","children":["$","$La",null,{"href":"/blog/AI/2021-08-13-WMT2020-生物医学-华为","className":"dark:hover:text-primary-400 text-primary-500 hover:text-primary-600","aria-label":"Previous post: WMT2020-生物医学-华为","children":["← ","WMT2020-生物医学-华为"]}]}],["$","div",null,{"className":"pt-4 xl:pt-8","children":["$","$La",null,{"href":"/blog/AI/2021-08-15-WMT2020-新闻-小牛","className":"dark:hover:text-primary-400 text-primary-500 hover:text-primary-600","aria-label":"Next post: WMT2020-新闻-小牛","children":["WMT2020-新闻-小牛"," →"]}]}]]}]}]]}]]}]}]]}]]
d:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Atman机器翻译模型笔记 | Tz Blog"}],["$","meta","3",{"name":"description","content":"这篇文章主要介绍了机器翻译模型的训练过程和数据处理方法。文章详细描述了从大规模语料训练基础模型到领域精调的完整流程,包括使用平行语料和单语回译语料进行训练,以及采用联合训练、EWC约束等技术来优化模型性能。此外,文章还讨论了语料清洗和数据增强的方法,如使用语言模型、句对相似度和统计规则进行数据筛选,以及通过反向翻译和对偶学习等技术来扩充训练数据。"}],["$","meta","4",{"name":"robots","content":"index, follow"}],["$","meta","5",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","6",{"rel":"canonical","href":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-13-Atman%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0"}],["$","link","7",{"rel":"alternate","type":"application/rss+xml","href":"https://tailwind-nextjs-starter-blog.vercel.app/feed.xml"}],["$","meta","8",{"property":"og:title","content":"Atman机器翻译模型笔记"}],["$","meta","9",{"property":"og:description","content":"这篇文章主要介绍了机器翻译模型的训练过程和数据处理方法。文章详细描述了从大规模语料训练基础模型到领域精调的完整流程,包括使用平行语料和单语回译语料进行训练,以及采用联合训练、EWC约束等技术来优化模型性能。此外,文章还讨论了语料清洗和数据增强的方法,如使用语言模型、句对相似度和统计规则进行数据筛选,以及通过反向翻译和对偶学习等技术来扩充训练数据。"}],["$","meta","10",{"property":"og:url","content":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2021-08-13-Atman%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0"}],["$","meta","11",{"property":"og:site_name","content":"Tz Blog"}],["$","meta","12",{"property":"og:locale","content":"en_US"}],["$","meta","13",{"property":"og:image","content":"https://tailwind-nextjs-starter-blog.vercel.app/static/images/twitter-card.png"}],["$","meta","14",{"property":"og:type","content":"article"}],["$","meta","15",{"property":"article:published_time","content":"2021-08-13T00:00:00.000Z"}],["$","meta","16",{"property":"article:modified_time","content":"2021-08-13T00:00:00.000Z"}],["$","meta","17",{"property":"article:author","content":"Tz"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"Atman机器翻译模型笔记"}],["$","meta","20",{"name":"twitter:description","content":"这篇文章主要介绍了机器翻译模型的训练过程和数据处理方法。文章详细描述了从大规模语料训练基础模型到领域精调的完整流程,包括使用平行语料和单语回译语料进行训练,以及采用联合训练、EWC约束等技术来优化模型性能。此外,文章还讨论了语料清洗和数据增强的方法,如使用语言模型、句对相似度和统计规则进行数据筛选,以及通过反向翻译和对偶学习等技术来扩充训练数据。"}],["$","meta","21",{"name":"twitter:image","content":"https://tailwind-nextjs-starter-blog.vercel.app/static/images/twitter-card.png"}],["$","meta","22",{"name":"next-size-adjust"}]]
1:null
