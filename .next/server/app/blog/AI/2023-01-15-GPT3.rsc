3:I[9275,[],""]
5:I[1343,[],""]
6:I[4404,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","97","static/chunks/97-7260ee5660d3a094.js","185","static/chunks/app/layout-956eb3ba3d426405.js"],"GoogleAnalytics"]
7:I[8700,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","97","static/chunks/97-7260ee5660d3a094.js","185","static/chunks/app/layout-956eb3ba3d426405.js"],"ThemeProviders"]
8:I[4080,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","97","static/chunks/97-7260ee5660d3a094.js","185","static/chunks/app/layout-956eb3ba3d426405.js"],""]
9:I[9032,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","97","static/chunks/97-7260ee5660d3a094.js","185","static/chunks/app/layout-956eb3ba3d426405.js"],"KBarSearchProvider"]
a:I[5133,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","97","static/chunks/97-7260ee5660d3a094.js","185","static/chunks/app/layout-956eb3ba3d426405.js"],"default"]
b:I[231,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","797","static/chunks/app/blog/%5B...slug%5D/page-5201c8be1492bbcb.js"],""]
4:["slug","AI/2023-01-15-GPT3","c"]
c:T69f,M12 0C8.74 0 8.333.015 7.053.072 5.775.132 4.905.333 4.14.63c-.789.306-1.459.717-2.126 1.384S.935 3.35.63 4.14C.333 4.905.131 5.775.072 7.053.012 8.333 0 8.74 0 12s.015 3.667.072 4.947c.06 1.277.261 2.148.558 2.913.306.788.717 1.459 1.384 2.126.667.666 1.336 1.079 2.126 1.384.766.296 1.636.499 2.913.558C8.333 23.988 8.74 24 12 24s3.667-.015 4.947-.072c1.277-.06 2.148-.262 2.913-.558.788-.306 1.459-.718 2.126-1.384.666-.667 1.079-1.335 1.384-2.126.296-.765.499-1.636.558-2.913.06-1.28.072-1.687.072-4.947s-.015-3.667-.072-4.947c-.06-1.277-.262-2.149-.558-2.913-.306-.789-.718-1.459-1.384-2.126C21.319 1.347 20.651.935 19.86.63c-.765-.297-1.636-.499-2.913-.558C15.667.012 15.26 0 12 0zm0 2.16c3.203 0 3.585.016 4.85.071 1.17.055 1.805.249 2.227.415.562.217.96.477 1.382.896.419.42.679.819.896 1.381.164.422.36 1.057.413 2.227.057 1.266.07 1.646.07 4.85s-.015 3.585-.074 4.85c-.061 1.17-.256 1.805-.421 2.227-.224.562-.479.96-.899 1.382-.419.419-.824.679-1.38.896-.42.164-1.065.36-2.235.413-1.274.057-1.649.07-4.859.07-3.211 0-3.586-.015-4.859-.074-1.171-.061-1.816-.256-2.236-.421-.569-.224-.96-.479-1.379-.899-.421-.419-.69-.824-.9-1.38-.165-.42-.359-1.065-.42-2.235-.045-1.26-.061-1.649-.061-4.844 0-3.196.016-3.586.061-4.861.061-1.17.255-1.814.42-2.234.21-.57.479-.96.9-1.381.419-.419.81-.689 1.379-.898.42-.166 1.051-.361 2.221-.421 1.275-.045 1.65-.06 4.859-.06l.045.03zm0 3.678c-3.405 0-6.162 2.76-6.162 6.162 0 3.405 2.76 6.162 6.162 6.162 3.405 0 6.162-2.76 6.162-6.162 0-3.405-2.76-6.162-6.162-6.162zM12 16c-2.21 0-4-1.79-4-4s1.79-4 4-4 4 1.79 4 4-1.79 4-4 4zm7.846-10.405c0 .795-.646 1.44-1.44 1.44-.795 0-1.44-.646-1.44-1.44 0-.794.646-1.439 1.44-1.439.793-.001 1.44.645 1.44 1.439zd:T498,M12.186 24h-.007c-3.581-.024-6.334-1.205-8.184-3.509C2.35 18.44 1.5 15.586 1.472 12.01v-.017c.03-3.579.879-6.43 2.525-8.482C5.845 1.205 8.6.024 12.18 0h.014c2.746.02 5.043.725 6.826 2.098 1.677 1.29 2.858 3.13 3.509 5.467l-2.04.569c-1.104-3.96-3.898-5.984-8.304-6.015-2.91.022-5.11.936-6.54 2.717C4.307 6.504 3.616 8.914 3.589 12c.027 3.086.718 5.496 2.057 7.164 1.43 1.783 3.631 2.698 6.54 2.717 2.623-.02 4.358-.631 5.8-2.045 1.647-1.613 1.618-3.593 1.09-4.798-.31-.71-.873-1.3-1.634-1.75-.192 1.352-.622 2.446-1.284 3.272-.886 1.102-2.14 1.704-3.73 1.79-1.202.065-2.361-.218-3.259-.801-1.063-.689-1.685-1.74-1.752-2.964-.065-1.19.408-2.285 1.33-3.082.88-.76 2.119-1.207 3.583-1.291a13.853 13.853 0 0 1 3.02.142c-.126-.742-.375-1.332-.75-1.757-.513-.586-1.308-.883-2.359-.89h-.029c-.844 0-1.992.232-2.721 1.32L7.734 7.847c.98-1.454 2.568-2.256 4.478-2.256h.044c3.194.02 5.097 1.975 5.287 5.388.108.046.216.094.321.142 1.49.7 2.58 1.761 3.154 3.07.797 1.82.871 4.79-1.548 7.158-1.85 1.81-4.094 2.628-7.277 2.65Zm1.003-11.69c-.242 0-.487.007-.739.021-1.836.103-2.98.946-2.916 2.143.067 1.256 1.452 1.839 2.784 1.767 1.224-.065 2.818-.543 3.086-3.71a10.5 10.5 0 0 0-2.215-.221z0:["4GpVTI5t3QYsmO2LiU8Xz",[[["",{"children":["blog",{"children":[["slug","AI/2023-01-15-GPT3","c"],{"children":["__PAGE__?{\"slug\":[\"AI\",\"2023-01-15-GPT3\"]}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["blog",{"children":[["slug","AI/2023-01-15-GPT3","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/ddb77e5ad3e10c15.css","precedence":"next","crossOrigin":"$undefined"}]]}],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"zh-cn","className":"__variable_587f35 scroll-smooth ","suppressHydrationWarning":true,"children":[["$","link",null,{"rel":"apple-touch-icon","sizes":"76x76","href":"/static/favicons/apple-touch-icon.png"}],["$","link",null,{"rel":"icon","type":"image/png","sizes":"32x32","href":"/static/favicons/favicon-32x32.png"}],["$","link",null,{"rel":"icon","type":"image/png","sizes":"16x16","href":"/static/favicons/favicon-16x16.png"}],["$","link",null,{"rel":"icon","type":"image/png","href":"/static/favicons/favicon.ico"}],["$","link",null,{"rel":"manifest","href":"/static/favicons/site.webmanifest"}],["$","link",null,{"rel":"mask-icon","href":"/static/favicons/safari-pinned-tab.svg","color":"#5bbad5"}],["$","meta",null,{"name":"msapplication-TileColor","content":"#000000"}],["$","meta",null,{"name":"theme-color","media":"(prefers-color-scheme: light)","content":"#fff"}],["$","meta",null,{"name":"theme-color","media":"(prefers-color-scheme: dark)","content":"#000"}],["$","link",null,{"rel":"alternate","type":"application/rss+xml","href":"/feed.xml"}],["$","body",null,{"className":"scrollbar-track-slate-400 bg-background pl-[calc(100vw-100%)] antialiased ","children":[["$","$L6",null,{"gaId":"G-JJL8NM5GV2"}],["$","$L7",null,{"children":[["$undefined","$undefined","$undefined",["$","$L8",null,{"async":true,"defer":true,"data-website-id":"$undefined","src":"https://analytics.umami.is/script.js"}],"$undefined","$undefined"],["$","section",null,{"className":"mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0","children":["$","div",null,{"className":"flex h-screen flex-col justify-between font-sans","children":[["$","$L9",null,{"kbarConfig":{"searchDocumentsPath":"search.json"},"children":[["$","$La",null,{}],["$","main",null,{"className":"mb-auto pt-20","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"flex flex-col items-start justify-start md:mt-24 md:flex-row md:items-center md:justify-center md:space-x-6","children":[["$","div",null,{"className":"space-x-2 pb-8 pt-6 md:space-y-5","children":["$","h1",null,{"className":"text-6xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 md:border-r-2 md:px-6 md:text-8xl md:leading-14","children":"404"}]}],["$","div",null,{"className":"max-w-md","children":[["$","p",null,{"className":"mb-4 text-xl font-bold leading-normal md:text-2xl","children":"Sorry we couldn't find this page."}],["$","p",null,{"className":"mb-8","children":"But dont worry, you can find plenty of other things on our homepage."}],["$","$Lb",null,{"href":"/","className":"focus:shadow-outline-blue inline rounded-lg border border-transparent bg-blue-600 px-4 py-2 text-sm font-medium leading-5 text-white shadow transition-colors duration-150 hover:bg-blue-700 focus:outline-none dark:hover:bg-blue-500","children":"Back to homepage"}]]}]]}],"notFoundStyles":[],"styles":null}]}]]}],["$","footer",null,{"children":["$","div",null,{"className":"mt-16 flex flex-col items-center","children":[["$","div",null,{"className":"mb-3 flex space-x-4","children":[["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"mailto:tztw4723@gmail.com","children":[["$","span",null,{"className":"sr-only","children":"mail"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 20 20","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Mail"}],["$","path",null,{"d":"M2.003 5.884L10 9.882l7.997-3.998A2 2 0 0016 4H4a2 2 0 00-1.997 1.884z"}],["$","path",null,{"d":"M18 8.118l-8 4-8-4V14a2 2 0 002 2h12a2 2 0 002-2V8.118z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://github.com/taoztw","children":[["$","span",null,{"className":"sr-only","children":"github"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Github"}],["$","path",null,{"d":"M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://facebook.com","children":[["$","span",null,{"className":"sr-only","children":"facebook"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Facebook"}],["$","path",null,{"d":"M24 12.073c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.99 4.388 10.954 10.125 11.854v-8.385H7.078v-3.47h3.047V9.43c0-3.007 1.792-4.669 4.533-4.669 1.312 0 2.686.235 2.686.235v2.953H15.83c-1.491 0-1.956.925-1.956 1.874v2.25h3.328l-.532 3.47h-2.796v8.385C19.612 23.027 24 18.062 24 12.073z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://youtube.com","children":[["$","span",null,{"className":"sr-only","children":"youtube"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Youtube"}],["$","path",null,{"d":"M23.499 6.203a3.008 3.008 0 00-2.089-2.089c-1.87-.501-9.4-.501-9.4-.501s-7.509-.01-9.399.501a3.008 3.008 0 00-2.088 2.09A31.258 31.26 0 000 12.01a31.258 31.26 0 00.523 5.785 3.008 3.008 0 002.088 2.089c1.869.502 9.4.502 9.4.502s7.508 0 9.399-.502a3.008 3.008 0 002.089-2.09 31.258 31.26 0 00.5-5.784 31.258 31.26 0 00-.5-5.808zm-13.891 9.4V8.407l6.266 3.604z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://www.linkedin.com","children":[["$","span",null,{"className":"sr-only","children":"linkedin"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Linkedin"}],["$","path",null,{"d":"M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 01-2.063-2.065 2.064 2.064 0 112.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"}]]}]]}],null,["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://twitter.com/x","children":[["$","span",null,{"className":"sr-only","children":"x"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"X"}],["$","path",null,{"d":"M18.901 1.153h3.68l-8.04 9.19L24 22.846h-7.406l-5.8-7.584-6.638 7.584H.474l8.6-9.83L0 1.154h7.594l5.243 6.932ZM17.61 20.644h2.039L6.486 3.24H4.298Z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://www.instagram.com","children":[["$","span",null,{"className":"sr-only","children":"instagram"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Instagram"}],["$","path",null,{"d":"$c"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://www.threads.net","children":[["$","span",null,{"className":"sr-only","children":"threads"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Threads"}],["$","path",null,{"d":"$d"}]]}]]}]]}],["$","div",null,{"className":"mb-2 flex space-x-2 text-sm text-gray-500 dark:text-gray-400","children":[["$","div",null,{"children":"Tz"}],["$","div",null,{"children":" • "}],["$","div",null,{"children":"© 2024"}],["$","div",null,{"children":" • "}],["$","a",null,{"target":"_blank","rel":"noopener noreferrer","href":"https://beian.miit.gov.cn/","children":"京ICP备2023010160号"}]]}],["$","div",null,{"className":"mb-8 text-sm text-gray-500 dark:text-gray-400","children":["$","a",null,{"target":"_blank","rel":"noopener noreferrer","href":"https://github.com/timlrx/tailwind-nextjs-starter-blog","children":"Tailwind Nextjs Theme"}]}]]}]}]]}]}]]}]]}]]}],null],null],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/b1aaec952e67a960.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/4fdcd319ea1029e9.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","2",{"rel":"stylesheet","href":"/_next/static/css/74fec4f6a9c4330b.css","precedence":"next","crossOrigin":"$undefined"}]],"$Le"]]]]
f:I[4347,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","797","static/chunks/app/blog/%5B...slug%5D/page-5201c8be1492bbcb.js"],"default"]
10:I[9629,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","797","static/chunks/app/blog/%5B...slug%5D/page-5201c8be1492bbcb.js"],"default"]
2:[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BlogPosting\",\"headline\":\"GPT3\",\"datePublished\":\"2023-01-15T00:00:00.000Z\",\"dateModified\":\"2023-01-15T00:00:00.000Z\",\"description\":\"GPT-3是一个拥有1750亿参数的大型语言模型,通过增大模型规模显著提高了小样本学习能力。在问答、填空、翻译等多项任务上,GPT-3无需微调就能取得不错的性能,但在某些数据集上仍存在困难。该研究还探讨了如何在大规模数据上训练如此庞大的语言模型。\",\"image\":\"/static/images/twitter-card.png\",\"url\":\"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-01-15-GPT3\",\"author\":[{\"@type\":\"Person\",\"name\":\"Tz\"}]}"}}],["$","section",null,{"className":"mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0","children":[["$","$Lf",null,{}],["$","article",null,{"children":["$","div",null,{"children":[["$","header",null,{"children":["$","div",null,{"className":"space-y-1 border-b border-gray-200 pb-10 text-center dark:border-gray-700","children":[["$","dl",null,{"children":["$","div",null,{"children":[["$","dt",null,{"className":"sr-only","children":"Published on"}],["$","dd",null,{"className":"text-base font-medium leading-6 text-gray-500 dark:text-gray-400","children":["$","time",null,{"dateTime":"2023-01-15T00:00:00.000Z","children":"January 15, 2023"}]}]]}]}],["$","div",null,{"children":["$","h1",null,{"className":"text-3xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 sm:text-4xl sm:leading-10 md:text-5xl md:leading-14","children":"GPT3"}]}]]}]}],["$","div",null,{"className":"grid-rows-[auto_1fr] divide-y divide-gray-200 pb-8 dark:divide-gray-700 xl:divide-y-0","children":[["$","div",null,{"className":"divide-y divide-gray-200 dark:divide-gray-700 xl:col-span-3 xl:row-span-2 xl:pb-0","children":["$","div",null,{"className":"prose max-w-none pb-8 pt-10 dark:prose-invert","children":[["$","blockquote",null,{"children":["$","p",null,{"children":"Language Models are Few-Shot Learners"}]}],["$","p",null,{"children":"增大语言模型可以提高模型任务无偏(task-agnostic)和小样本学习(few shot)的能力.GPT3 178b参数的语言模型，参数量是之前语言模型的十倍。不需要梯度更新或fine tuning，在一些任务上(问答，填空，翻译)有不错的性能，"}],["$","p",null,{"children":"GPT3 通过few-shot learning对于一些数据集仍然困难。"}],["$","p",null,{"children":"还有个方法论的问题，如何在大数据量上训练模型。"}],["$","h2",null,{"className":"content-header","id":"简介","children":[["$","a",null,{"href":"#简介","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"简介"]}],["$","p",null,{"children":["$","img",null,{"alt":"","src":"https://tz-1256822507.cos.ap-hongkong.myqcloud.com/typora/image-20230115134942286.png"}]}],["$","p",null,{"children":["$","img",null,{"alt":"","src":"https://tz-1256822507.cos.ap-hongkong.myqcloud.com/typora/image-20230115134954410.png"}]}],["$","p",null,{"children":"zero-shot性能随着模型大小的增加稳步提高，few-shot模型性能增加更快。较大的模型更擅长in-context learning."}],["$","h2",null,{"className":"content-header","id":"方法","children":[["$","a",null,{"href":"#方法","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"方法"]}],["$","p",null,{"children":"数据集，模型大小多样性，训练长度的拓展相对简单。 作者主要探索了在上下文中学习的不同设置："}],["$","ul",null,{"children":[["$","li",null,{"children":"fine-tuning FT"}],["$","li",null,{"children":"few-shot FS，给K个样本的例子(上下文和输出)和最后输出的上下文。few-shot主要的优势是减少了任务样本的数量。few-shot个数量K在10-100之间。"}],["$","li",null,{"children":"one-shot 1S K=1"}],["$","li",null,{"children":"Zero-shot"}]]}],["$","p",null,{"children":"虽然在本人few-shot实现了最高性能。但是zero-shot和1S仍然是未来工作的重要目标。"}],["$","h3",null,{"className":"content-header","id":"模型和架构","children":[["$","a",null,{"href":"#模型和架构","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"模型和架构"]}],["$","p",null,{"children":"训练了8种不同大小的模型，从123m到175b。"}],["$","h3",null,{"className":"content-header","id":"训练数据","children":[["$","a",null,{"href":"#训练数据","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"训练数据"]}],["$","p",null,{"children":"CommonCrawl 高质量的数据"}],["$","p",null,{"children":"模糊重复数据删除 内部以及不同数据集之间。"}],["$","p",null,{"children":"Webtext以及网上数据语料Book1 和Books2， 和英语 Wikipedia。"}],["$","h3",null,{"className":"content-header","id":"训练过程","children":[["$","a",null,{"href":"#训练过程","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"训练过程"]}],["$","p",null,{"children":"较大的模型通常可以使用较大的批量大小，需要较小的学习率。"}],["$","h2",null,{"className":"content-header","id":"结果","children":[["$","a",null,{"href":"#结果","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"结果"]}],["$","p",null,{"children":["$","strong",null,{"children":"Language Models，Cloze， Completion Task"}]}],["$","p",null,{"children":["$","img",null,{"alt":"","src":"https://tz-1256822507.cos.ap-hongkong.myqcloud.com/typora/image-20230115145124344.png"}]}],["$","p",null,{"children":"zero-shot GPT比SOTA高8%, 通过调整输入的format GPT3可以提升的更多（18%），例如fill-in-the-blank【Alice was friends with Bob. Alice went to visit her friend, . → Bob】"}],["$","p",null,{"children":["$","strong",null,{"children":"QA"}]}],["$","p",null,{"children":["$","img",null,{"alt":"","src":"https://tz-1256822507.cos.ap-hongkong.myqcloud.com/typora/image-20230115150045989.png"}]}],["$","p",null,{"children":["$","strong",null,{"children":"翻译"}]}],["$","p",null,{"children":"GPT3的训练数据主要由英文组成（字数比例在93%），也包括7%的非英语内容。"}],["$","p",null,{"children":"目标语言为英文的时候模型的输出能力好。"}],["$","p",null,{"children":["$","img",null,{"alt":"","src":"https://tz-1256822507.cos.ap-hongkong.myqcloud.com/typora/image-20230115151146741.png"}]}],["$","p",null,{"children":["$","strong",null,{"children":"SuperCLUE"}]}],["$","p",null,{"children":["$","img",null,{"alt":"","src":"https://tz-1256822507.cos.ap-hongkong.myqcloud.com/typora/image-20230115151729197.png"}]}],["$","p",null,{"children":"GPT3在八项任务中的四箱优于微调的Bert-learge，并且在两项任务上，GPT接近进过微调的110亿参数模型的SOTA。"}],["$","h2",null,{"className":"content-header","id":"measuring-and-preventing-memorization-of-benchmarks","children":[["$","a",null,{"href":"#measuring-and-preventing-memorization-of-benchmarks","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"Measuring and Preventing Memorization Of Benchmarks"]}],["$","p",null,{"children":"数据集和模型大小比GPT2 数据集和模型大小大约两个数量级。包含common crawl 会增加污染和记忆的可能性。"}],["$","p",null,{"children":"数据量巨大， GPT3 也不会过拟合。"}],["$","p",null,{"children":"通过13-gram的去重，在干净的基准数据集上测试，结果与原始分数相似，表明即使存在污染，也不会对报告产生重大影响。"}],["$","h2",null,{"className":"content-header","id":"局限性","children":[["$","a",null,{"href":"#局限性","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"局限性"]}],["$","p",null,{"children":"在文本合成方面，GPT-3样本有时仍然在文档级别上语义上重复，在足够长的段落中开始失去连贯性，自相矛盾，偶尔包含不符合逻辑的句子或段落。我们的发行版存储库包含无组织的无条件样本。"}],["$","p",null,{"children":"实验不包括双侠架构或其他训练目标，在受益于双向性的任务上，可能表现得更差。例如填空，比较两部分内容，根据长文本生成简短的答案。"}],["$","p",null,{"children":["GPT3的目标是对每一个token都一视同仁，缺乏一个概念，什么是重要的预测，什么是不重要的预测。语言系统可能更好的被认为是采用目标导向的行动，不仅仅是进行预测。大型预训练模型没有基于其他经验领域如视频或现实世界的物理交互，缺乏大量关于世界的上下文。",["$","strong",null,{"children":"有希望从人类那里学习目标函数Fine-tuning language models from human preferences, 2019.。利用强化学习进行微调。"}]]}],["$","p",null,{"children":["$","strong",null,{"children":"GPT3的大小使其部署具有挑战性，特定于任务的蒸馏值得在这个新规模上进行探索。[Distilling the knowledge in a neural network]"}]}],["$","h2",null,{"className":"content-header","id":"instructions","children":[["$","a",null,{"href":"#instructions","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"instructions"]}],["$","blockquote",null,{"children":["$","p",null,{"children":"Training language models to follow instructions with human feedback"}]}],["$","p",null,{"children":"大型语言模型可能会生成不真实的、有毒的或对用户没有帮助的输出。 换句话说，这些模型与其用户不一致。可以通过根据人类反馈进行微调，使语言模型与用户对各种任务的意图保持一致"}],["$","p",null,{"children":"1.3B 参数 InstructGPT 模型的输出优于 175B GPT-3 的输出，尽管参数少 100 倍。 此外，InstructGPT 模型显示了真实性的提高和有毒输出生成的减少，同时对公共 NLP 数据集的性能回归最小。 尽管 InstructGPT 仍然会犯一些简单的错误，但我们的结果表明，根据人类反馈进行微调是使语言模型与人类意图保持一致的一个有前途的方向。"}]]}]}],["$","div",null,{"className":"pb-6 pt-6 text-center text-gray-700 dark:text-gray-300","id":"comment","children":["$","$L10",null,{"slug":"AI/2023-01-15-GPT3"}]}],["$","footer",null,{"children":["$","div",null,{"className":"flex flex-col text-sm font-medium sm:flex-row sm:justify-between sm:text-base","children":[["$","div",null,{"className":"pt-4 xl:pt-8","children":["$","$Lb",null,{"href":"/blog/AI/2023-01-15-自编码-自回归_BERT-GPT-LLM_","className":"dark:hover:text-primary-400 text-primary-500 hover:text-primary-600","aria-label":"Previous post: 自编码-自回归_BERT-GPT-LLM_","children":["← ","自编码-自回归_BERT-GPT-LLM_"]}]}],["$","div",null,{"className":"pt-4 xl:pt-8","children":["$","$Lb",null,{"href":"/blog/AI/2023-01-15-GPT2","className":"dark:hover:text-primary-400 text-primary-500 hover:text-primary-600","aria-label":"Next post: GPT2","children":["GPT2"," →"]}]}]]}]}]]}]]}]}]]}]]
e:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"GPT3 | Tz Blog"}],["$","meta","3",{"name":"description","content":"GPT-3是一个拥有1750亿参数的大型语言模型,通过增大模型规模显著提高了小样本学习能力。在问答、填空、翻译等多项任务上,GPT-3无需微调就能取得不错的性能,但在某些数据集上仍存在困难。该研究还探讨了如何在大规模数据上训练如此庞大的语言模型。"}],["$","meta","4",{"name":"robots","content":"index, follow"}],["$","meta","5",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","6",{"rel":"canonical","href":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-01-15-GPT3"}],["$","link","7",{"rel":"alternate","type":"application/rss+xml","href":"https://tailwind-nextjs-starter-blog.vercel.app/feed.xml"}],["$","meta","8",{"property":"og:title","content":"GPT3"}],["$","meta","9",{"property":"og:description","content":"GPT-3是一个拥有1750亿参数的大型语言模型,通过增大模型规模显著提高了小样本学习能力。在问答、填空、翻译等多项任务上,GPT-3无需微调就能取得不错的性能,但在某些数据集上仍存在困难。该研究还探讨了如何在大规模数据上训练如此庞大的语言模型。"}],["$","meta","10",{"property":"og:url","content":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-01-15-GPT3"}],["$","meta","11",{"property":"og:site_name","content":"Tz Blog"}],["$","meta","12",{"property":"og:locale","content":"en_US"}],["$","meta","13",{"property":"og:image","content":"https://tailwind-nextjs-starter-blog.vercel.app/static/images/twitter-card.png"}],["$","meta","14",{"property":"og:type","content":"article"}],["$","meta","15",{"property":"article:published_time","content":"2023-01-15T00:00:00.000Z"}],["$","meta","16",{"property":"article:modified_time","content":"2023-01-15T00:00:00.000Z"}],["$","meta","17",{"property":"article:author","content":"Tz"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"GPT3"}],["$","meta","20",{"name":"twitter:description","content":"GPT-3是一个拥有1750亿参数的大型语言模型,通过增大模型规模显著提高了小样本学习能力。在问答、填空、翻译等多项任务上,GPT-3无需微调就能取得不错的性能,但在某些数据集上仍存在困难。该研究还探讨了如何在大规模数据上训练如此庞大的语言模型。"}],["$","meta","21",{"name":"twitter:image","content":"https://tailwind-nextjs-starter-blog.vercel.app/static/images/twitter-card.png"}],["$","meta","22",{"name":"next-size-adjust"}]]
1:null
