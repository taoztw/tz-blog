3:I[9275,[],""]
5:I[1343,[],""]
6:I[4404,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","97","static/chunks/97-7260ee5660d3a094.js","185","static/chunks/app/layout-956eb3ba3d426405.js"],"GoogleAnalytics"]
7:I[8700,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","97","static/chunks/97-7260ee5660d3a094.js","185","static/chunks/app/layout-956eb3ba3d426405.js"],"ThemeProviders"]
8:I[4080,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","97","static/chunks/97-7260ee5660d3a094.js","185","static/chunks/app/layout-956eb3ba3d426405.js"],""]
9:I[9032,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","97","static/chunks/97-7260ee5660d3a094.js","185","static/chunks/app/layout-956eb3ba3d426405.js"],"KBarSearchProvider"]
a:I[5133,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","97","static/chunks/97-7260ee5660d3a094.js","185","static/chunks/app/layout-956eb3ba3d426405.js"],"default"]
b:I[231,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","797","static/chunks/app/blog/%5B...slug%5D/page-5201c8be1492bbcb.js"],""]
4:["slug","AI/2023-01-15-GPT2","c"]
c:T69f,M12 0C8.74 0 8.333.015 7.053.072 5.775.132 4.905.333 4.14.63c-.789.306-1.459.717-2.126 1.384S.935 3.35.63 4.14C.333 4.905.131 5.775.072 7.053.012 8.333 0 8.74 0 12s.015 3.667.072 4.947c.06 1.277.261 2.148.558 2.913.306.788.717 1.459 1.384 2.126.667.666 1.336 1.079 2.126 1.384.766.296 1.636.499 2.913.558C8.333 23.988 8.74 24 12 24s3.667-.015 4.947-.072c1.277-.06 2.148-.262 2.913-.558.788-.306 1.459-.718 2.126-1.384.666-.667 1.079-1.335 1.384-2.126.296-.765.499-1.636.558-2.913.06-1.28.072-1.687.072-4.947s-.015-3.667-.072-4.947c-.06-1.277-.262-2.149-.558-2.913-.306-.789-.718-1.459-1.384-2.126C21.319 1.347 20.651.935 19.86.63c-.765-.297-1.636-.499-2.913-.558C15.667.012 15.26 0 12 0zm0 2.16c3.203 0 3.585.016 4.85.071 1.17.055 1.805.249 2.227.415.562.217.96.477 1.382.896.419.42.679.819.896 1.381.164.422.36 1.057.413 2.227.057 1.266.07 1.646.07 4.85s-.015 3.585-.074 4.85c-.061 1.17-.256 1.805-.421 2.227-.224.562-.479.96-.899 1.382-.419.419-.824.679-1.38.896-.42.164-1.065.36-2.235.413-1.274.057-1.649.07-4.859.07-3.211 0-3.586-.015-4.859-.074-1.171-.061-1.816-.256-2.236-.421-.569-.224-.96-.479-1.379-.899-.421-.419-.69-.824-.9-1.38-.165-.42-.359-1.065-.42-2.235-.045-1.26-.061-1.649-.061-4.844 0-3.196.016-3.586.061-4.861.061-1.17.255-1.814.42-2.234.21-.57.479-.96.9-1.381.419-.419.81-.689 1.379-.898.42-.166 1.051-.361 2.221-.421 1.275-.045 1.65-.06 4.859-.06l.045.03zm0 3.678c-3.405 0-6.162 2.76-6.162 6.162 0 3.405 2.76 6.162 6.162 6.162 3.405 0 6.162-2.76 6.162-6.162 0-3.405-2.76-6.162-6.162-6.162zM12 16c-2.21 0-4-1.79-4-4s1.79-4 4-4 4 1.79 4 4-1.79 4-4 4zm7.846-10.405c0 .795-.646 1.44-1.44 1.44-.795 0-1.44-.646-1.44-1.44 0-.794.646-1.439 1.44-1.439.793-.001 1.44.645 1.44 1.439zd:T498,M12.186 24h-.007c-3.581-.024-6.334-1.205-8.184-3.509C2.35 18.44 1.5 15.586 1.472 12.01v-.017c.03-3.579.879-6.43 2.525-8.482C5.845 1.205 8.6.024 12.18 0h.014c2.746.02 5.043.725 6.826 2.098 1.677 1.29 2.858 3.13 3.509 5.467l-2.04.569c-1.104-3.96-3.898-5.984-8.304-6.015-2.91.022-5.11.936-6.54 2.717C4.307 6.504 3.616 8.914 3.589 12c.027 3.086.718 5.496 2.057 7.164 1.43 1.783 3.631 2.698 6.54 2.717 2.623-.02 4.358-.631 5.8-2.045 1.647-1.613 1.618-3.593 1.09-4.798-.31-.71-.873-1.3-1.634-1.75-.192 1.352-.622 2.446-1.284 3.272-.886 1.102-2.14 1.704-3.73 1.79-1.202.065-2.361-.218-3.259-.801-1.063-.689-1.685-1.74-1.752-2.964-.065-1.19.408-2.285 1.33-3.082.88-.76 2.119-1.207 3.583-1.291a13.853 13.853 0 0 1 3.02.142c-.126-.742-.375-1.332-.75-1.757-.513-.586-1.308-.883-2.359-.89h-.029c-.844 0-1.992.232-2.721 1.32L7.734 7.847c.98-1.454 2.568-2.256 4.478-2.256h.044c3.194.02 5.097 1.975 5.287 5.388.108.046.216.094.321.142 1.49.7 2.58 1.761 3.154 3.07.797 1.82.871 4.79-1.548 7.158-1.85 1.81-4.094 2.628-7.277 2.65Zm1.003-11.69c-.242 0-.487.007-.739.021-1.836.103-2.98.946-2.916 2.143.067 1.256 1.452 1.839 2.784 1.767 1.224-.065 2.818-.543 3.086-3.71a10.5 10.5 0 0 0-2.215-.221z0:["4GpVTI5t3QYsmO2LiU8Xz",[[["",{"children":["blog",{"children":[["slug","AI/2023-01-15-GPT2","c"],{"children":["__PAGE__?{\"slug\":[\"AI\",\"2023-01-15-GPT2\"]}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["blog",{"children":[["slug","AI/2023-01-15-GPT2","c"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/ddb77e5ad3e10c15.css","precedence":"next","crossOrigin":"$undefined"}]]}],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"zh-cn","className":"__variable_587f35 scroll-smooth ","suppressHydrationWarning":true,"children":[["$","link",null,{"rel":"apple-touch-icon","sizes":"76x76","href":"/static/favicons/apple-touch-icon.png"}],["$","link",null,{"rel":"icon","type":"image/png","sizes":"32x32","href":"/static/favicons/favicon-32x32.png"}],["$","link",null,{"rel":"icon","type":"image/png","sizes":"16x16","href":"/static/favicons/favicon-16x16.png"}],["$","link",null,{"rel":"icon","type":"image/png","href":"/static/favicons/favicon.ico"}],["$","link",null,{"rel":"manifest","href":"/static/favicons/site.webmanifest"}],["$","link",null,{"rel":"mask-icon","href":"/static/favicons/safari-pinned-tab.svg","color":"#5bbad5"}],["$","meta",null,{"name":"msapplication-TileColor","content":"#000000"}],["$","meta",null,{"name":"theme-color","media":"(prefers-color-scheme: light)","content":"#fff"}],["$","meta",null,{"name":"theme-color","media":"(prefers-color-scheme: dark)","content":"#000"}],["$","link",null,{"rel":"alternate","type":"application/rss+xml","href":"/feed.xml"}],["$","body",null,{"className":"scrollbar-track-slate-400 bg-background pl-[calc(100vw-100%)] antialiased ","children":[["$","$L6",null,{"gaId":"G-JJL8NM5GV2"}],["$","$L7",null,{"children":[["$undefined","$undefined","$undefined",["$","$L8",null,{"async":true,"defer":true,"data-website-id":"$undefined","src":"https://analytics.umami.is/script.js"}],"$undefined","$undefined"],["$","section",null,{"className":"mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0","children":["$","div",null,{"className":"flex h-screen flex-col justify-between font-sans","children":[["$","$L9",null,{"kbarConfig":{"searchDocumentsPath":"search.json"},"children":[["$","$La",null,{}],["$","main",null,{"className":"mb-auto pt-20","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"flex flex-col items-start justify-start md:mt-24 md:flex-row md:items-center md:justify-center md:space-x-6","children":[["$","div",null,{"className":"space-x-2 pb-8 pt-6 md:space-y-5","children":["$","h1",null,{"className":"text-6xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 md:border-r-2 md:px-6 md:text-8xl md:leading-14","children":"404"}]}],["$","div",null,{"className":"max-w-md","children":[["$","p",null,{"className":"mb-4 text-xl font-bold leading-normal md:text-2xl","children":"Sorry we couldn't find this page."}],["$","p",null,{"className":"mb-8","children":"But dont worry, you can find plenty of other things on our homepage."}],["$","$Lb",null,{"href":"/","className":"focus:shadow-outline-blue inline rounded-lg border border-transparent bg-blue-600 px-4 py-2 text-sm font-medium leading-5 text-white shadow transition-colors duration-150 hover:bg-blue-700 focus:outline-none dark:hover:bg-blue-500","children":"Back to homepage"}]]}]]}],"notFoundStyles":[],"styles":null}]}]]}],["$","footer",null,{"children":["$","div",null,{"className":"mt-16 flex flex-col items-center","children":[["$","div",null,{"className":"mb-3 flex space-x-4","children":[["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"mailto:tztw4723@gmail.com","children":[["$","span",null,{"className":"sr-only","children":"mail"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 20 20","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Mail"}],["$","path",null,{"d":"M2.003 5.884L10 9.882l7.997-3.998A2 2 0 0016 4H4a2 2 0 00-1.997 1.884z"}],["$","path",null,{"d":"M18 8.118l-8 4-8-4V14a2 2 0 002 2h12a2 2 0 002-2V8.118z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://github.com/taoztw","children":[["$","span",null,{"className":"sr-only","children":"github"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Github"}],["$","path",null,{"d":"M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://facebook.com","children":[["$","span",null,{"className":"sr-only","children":"facebook"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Facebook"}],["$","path",null,{"d":"M24 12.073c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.99 4.388 10.954 10.125 11.854v-8.385H7.078v-3.47h3.047V9.43c0-3.007 1.792-4.669 4.533-4.669 1.312 0 2.686.235 2.686.235v2.953H15.83c-1.491 0-1.956.925-1.956 1.874v2.25h3.328l-.532 3.47h-2.796v8.385C19.612 23.027 24 18.062 24 12.073z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://youtube.com","children":[["$","span",null,{"className":"sr-only","children":"youtube"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Youtube"}],["$","path",null,{"d":"M23.499 6.203a3.008 3.008 0 00-2.089-2.089c-1.87-.501-9.4-.501-9.4-.501s-7.509-.01-9.399.501a3.008 3.008 0 00-2.088 2.09A31.258 31.26 0 000 12.01a31.258 31.26 0 00.523 5.785 3.008 3.008 0 002.088 2.089c1.869.502 9.4.502 9.4.502s7.508 0 9.399-.502a3.008 3.008 0 002.089-2.09 31.258 31.26 0 00.5-5.784 31.258 31.26 0 00-.5-5.808zm-13.891 9.4V8.407l6.266 3.604z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://www.linkedin.com","children":[["$","span",null,{"className":"sr-only","children":"linkedin"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Linkedin"}],["$","path",null,{"d":"M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 01-2.063-2.065 2.064 2.064 0 112.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"}]]}]]}],null,["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://twitter.com/x","children":[["$","span",null,{"className":"sr-only","children":"x"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"X"}],["$","path",null,{"d":"M18.901 1.153h3.68l-8.04 9.19L24 22.846h-7.406l-5.8-7.584-6.638 7.584H.474l8.6-9.83L0 1.154h7.594l5.243 6.932ZM17.61 20.644h2.039L6.486 3.24H4.298Z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://www.instagram.com","children":[["$","span",null,{"className":"sr-only","children":"instagram"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Instagram"}],["$","path",null,{"d":"$c"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://www.threads.net","children":[["$","span",null,{"className":"sr-only","children":"threads"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"dark:hover:text-primary-400 fill-current text-gray-700 hover:text-primary-500 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Threads"}],["$","path",null,{"d":"$d"}]]}]]}]]}],["$","div",null,{"className":"mb-2 flex space-x-2 text-sm text-gray-500 dark:text-gray-400","children":[["$","div",null,{"children":"Tz"}],["$","div",null,{"children":" • "}],["$","div",null,{"children":"© 2024"}],["$","div",null,{"children":" • "}],["$","a",null,{"target":"_blank","rel":"noopener noreferrer","href":"https://beian.miit.gov.cn/","children":"京ICP备2023010160号"}]]}],["$","div",null,{"className":"mb-8 text-sm text-gray-500 dark:text-gray-400","children":["$","a",null,{"target":"_blank","rel":"noopener noreferrer","href":"https://github.com/timlrx/tailwind-nextjs-starter-blog","children":"Tailwind Nextjs Theme"}]}]]}]}]]}]}]]}]]}]]}],null],null],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/b1aaec952e67a960.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/4fdcd319ea1029e9.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","2",{"rel":"stylesheet","href":"/_next/static/css/74fec4f6a9c4330b.css","precedence":"next","crossOrigin":"$undefined"}]],"$Le"]]]]
f:I[4347,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","797","static/chunks/app/blog/%5B...slug%5D/page-5201c8be1492bbcb.js"],"default"]
10:I[9629,["231","static/chunks/231-a2a5e21f80783222.js","173","static/chunks/173-fb59ec7f2f6147b4.js","797","static/chunks/app/blog/%5B...slug%5D/page-5201c8be1492bbcb.js"],"default"]
2:[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BlogPosting\",\"headline\":\"GPT2\",\"datePublished\":\"2023-01-15T00:00:00.000Z\",\"dateModified\":\"2023-01-15T00:00:00.000Z\",\"description\":\"GPT-2语言模型,一个无监督的多任务学习器。GPT-2在多个任务上实现了零样本学习的最先进结果,展示了语言模型作为通用任务学习器的潜力。文章还讨论了增加模型容量可以以对数线性方式提高性能,以及大规模多样化数据集对模型泛化能力的重要性。\",\"image\":\"/static/images/twitter-card.png\",\"url\":\"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-01-15-GPT2\",\"author\":[{\"@type\":\"Person\",\"name\":\"Tz\"}]}"}}],["$","section",null,{"className":"mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0","children":[["$","$Lf",null,{}],["$","article",null,{"children":["$","div",null,{"children":[["$","header",null,{"children":["$","div",null,{"className":"space-y-1 border-b border-gray-200 pb-10 text-center dark:border-gray-700","children":[["$","dl",null,{"children":["$","div",null,{"children":[["$","dt",null,{"className":"sr-only","children":"Published on"}],["$","dd",null,{"className":"text-base font-medium leading-6 text-gray-500 dark:text-gray-400","children":["$","time",null,{"dateTime":"2023-01-15T00:00:00.000Z","children":"January 15, 2023"}]}]]}]}],["$","div",null,{"children":["$","h1",null,{"className":"text-3xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 sm:text-4xl sm:leading-10 md:text-5xl md:leading-14","children":"GPT2"}]}]]}]}],["$","div",null,{"className":"grid-rows-[auto_1fr] divide-y divide-gray-200 pb-8 dark:divide-gray-700 xl:divide-y-0","children":[["$","div",null,{"className":"divide-y divide-gray-200 dark:divide-gray-700 xl:col-span-3 xl:row-span-2 xl:pb-0","children":["$","div",null,{"className":"prose max-w-none pb-8 pt-10 dark:prose-invert","children":[["$","blockquote",null,{"children":["$","p",null,{"children":"Language Models are Unsupervised Multitask Learners"}]}],["$","p",null,{"children":"语言模型是一个无监督的多任务学习器"}],["$","p",null,{"children":"使用webText数据集训练15亿参数的GPT2，zero-sho在多个任务上取得了SOTA的结果。并且在WebText数据上仍然欠拟合(underfits)"}],["$","p",null,{"children":["语言模型的容量对zero shot任务的迁移是很重要的，并且",["$","strong",null,{"children":"增加容量可以以对数线性方式提高模型性能"}],"。模型参数大小是x轴，性能是y轴。"]}],["$","p",null,{"children":"作者认为：单领域数据集上单任务的训练是当前模型泛华能力不足的原因，多任务学习根据元学习角度，每一个（dateset，objective）是从datasets和objects的分布中采样，仍然需要较多的目标训练数据。"}],["$","p",null,{"children":"预训练和监督微调的方法组合也是一个方法，但是仍然是监督学习，作者展示了语言模型可以在zero-shot下执行下游任务，不需要参数或架构的修改。"}],["$","h2",null,{"id":"approach","className":"content-header","children":[["$","a",null,{"href":"#approach","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"Approach"]}],["$","p",null,{"children":["单任务可以用一个条件分布表示 ",["$","span",null,{"className":"katex","children":[["$","span",null,{"className":"katex-mathml","children":["$","math",null,{"xmlns":"http://www.w3.org/1998/Math/MathML","children":["$","semantics",null,{"children":[["$","mrow",null,{"children":[["$","mi",null,{"children":"p"}],["$","mo",null,{"stretchy":"false","children":"("}],["$","mi",null,{"children":"o"}],["$","mi",null,{"children":"u"}],["$","mi",null,{"children":"t"}],["$","mi",null,{"children":"p"}],["$","mi",null,{"children":"u"}],["$","mi",null,{"children":"t"}],["$","mi",null,{"mathvariant":"normal","children":"∣"}],["$","mi",null,{"children":"i"}],["$","mi",null,{"children":"n"}],["$","mi",null,{"children":"p"}],["$","mi",null,{"children":"u"}],["$","mi",null,{"children":"t"}],["$","mo",null,{"stretchy":"false","children":")"}]]}],["$","annotation",null,{"encoding":"application/x-tex","children":"p(output|input)"}]]}]}]}],["$","span",null,{"className":"katex-html","aria-hidden":"true","children":["$","span",null,{"className":"base","children":[["$","span",null,{"className":"strut","style":{"height":"1em","verticalAlign":"-.25em"}}],["$","span",null,{"className":"mord mathnormal","children":"p"}],["$","span",null,{"className":"mopen","children":"("}],["$","span",null,{"className":"mord mathnormal","children":"o"}],["$","span",null,{"className":"mord mathnormal","children":"u"}],["$","span",null,{"className":"mord mathnormal","children":"tp"}],["$","span",null,{"className":"mord mathnormal","children":"u"}],["$","span",null,{"className":"mord mathnormal","children":"t"}],["$","span",null,{"className":"mord","children":"∣"}],["$","span",null,{"className":"mord mathnormal","children":"in"}],["$","span",null,{"className":"mord mathnormal","children":"p"}],["$","span",null,{"className":"mord mathnormal","children":"u"}],["$","span",null,{"className":"mord mathnormal","children":"t"}],["$","span",null,{"className":"mclose","children":")"}]]}]}]]}]," 多任务",["$","span",null,{"className":"katex","children":[["$","span",null,{"className":"katex-mathml","children":["$","math",null,{"xmlns":"http://www.w3.org/1998/Math/MathML","children":["$","semantics",null,{"children":[["$","mrow",null,{"children":[["$","mi",null,{"children":"p"}],["$","mo",null,{"stretchy":"false","children":"("}],["$","mi",null,{"children":"o"}],["$","mi",null,{"children":"u"}],["$","mi",null,{"children":"t"}],["$","mi",null,{"children":"p"}],["$","mi",null,{"children":"u"}],["$","mi",null,{"children":"t"}],["$","mi",null,{"mathvariant":"normal","children":"∣"}],["$","mi",null,{"children":"i"}],["$","mi",null,{"children":"n"}],["$","mi",null,{"children":"p"}],["$","mi",null,{"children":"u"}],["$","mi",null,{"children":"t"}],["$","mo",null,{"separator":"true","children":","}],["$","mi",null,{"children":"t"}],["$","mi",null,{"children":"a"}],["$","mi",null,{"children":"s"}],["$","mi",null,{"children":"k"}],["$","mo",null,{"stretchy":"false","children":")"}]]}],["$","annotation",null,{"encoding":"application/x-tex","children":"p(output|input, task)"}]]}]}]}],["$","span",null,{"className":"katex-html","aria-hidden":"true","children":["$","span",null,{"className":"base","children":[["$","span",null,{"className":"strut","style":{"height":"1em","verticalAlign":"-.25em"}}],["$","span",null,{"className":"mord mathnormal","children":"p"}],["$","span",null,{"className":"mopen","children":"("}],["$","span",null,{"className":"mord mathnormal","children":"o"}],["$","span",null,{"className":"mord mathnormal","children":"u"}],["$","span",null,{"className":"mord mathnormal","children":"tp"}],["$","span",null,{"className":"mord mathnormal","children":"u"}],["$","span",null,{"className":"mord mathnormal","children":"t"}],["$","span",null,{"className":"mord","children":"∣"}],["$","span",null,{"className":"mord mathnormal","children":"in"}],["$","span",null,{"className":"mord mathnormal","children":"p"}],["$","span",null,{"className":"mord mathnormal","children":"u"}],["$","span",null,{"className":"mord mathnormal","children":"t"}],["$","span",null,{"className":"mpunct","children":","}],["$","span",null,{"className":"mspace","style":{"marginRight":".1667em"}}],["$","span",null,{"className":"mord mathnormal","children":"t"}],["$","span",null,{"className":"mord mathnormal","children":"a"}],["$","span",null,{"className":"mord mathnormal","children":"s"}],["$","span",null,{"className":"mord mathnormal","style":{"marginRight":".03148em"},"children":"k"}],["$","span",null,{"className":"mclose","children":")"}]]}]}]]}],"，对于不同task的处理之前通过设计特殊的encoder 和decoder，通过模型架构来处理多任务。但是语言也提供了灵活的方式来标识不同的task。"]}],["$","p",null,{"children":"作者通过语言模型zero-shot在多任务的性能的表现，来衡量语言模型是否是一个无监督多任务学习器。"}],["$","h3",null,{"className":"content-header","id":"数据","children":[["$","a",null,{"href":"#数据","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"数据"]}],["$","p",null,{"children":"尽可能大和多样化（多领域）"}],["$","p",null,{"children":"Comon Crawl 存在质量问题。“内容大多难以理解”"}],["$","p",null,{"children":"从社交媒体Reddit抓取outbound links，有4500万个链接，清理去重后有800万个文档，总40GB的文本。（删除了Wikipedia的文档。因为是通用数据源可能造成训练和测试数据的重叠。）"}],["$","h3",null,{"className":"content-header","id":"数据输入","children":[["$","a",null,{"href":"#数据输入","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"数据输入"]}],["$","p",null,{"children":"需要有一个词汇表，来包含130000个unicode字符。（Unicode 13.0共有143859个字符），这比BPE通用的32k和64k词表大太多。byte bpe仅仅需要256的vocab大小。16*16"}],["$","p",null,{"children":"采用BPE，作者发现在BPE 词表中有很多变体，如dog为dog. dog! dog? 这因为bpe使用频率的启发式贪心算法导致suboptimal merges。"}],["$","p",null,{"children":"所以作者组织BPE合并跨字符类比的字符。并且为空格添加了一个exception"}],["$","blockquote",null,{"children":["$","p",null,{"children":"(暂不知操作是什么)"}]}],["$","p",null,{"children":"提高压缩效率，添加最少的单词碎片。"}],["$","p",null,{"children":"这样使模型在任何数据集上都可以进行模型评估。"}],["$","h3",null,{"className":"content-header","id":"模型","children":[["$","a",null,{"href":"#模型","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"模型"]}],["$","p",null,{"children":"词表大小 50257"}],["$","p",null,{"children":"batch size 512， context sieze 1024"}],["$","h2",null,{"id":"实验","className":"content-header","children":[["$","a",null,{"href":"#实验","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"实验"]}],["$","p",null,{"children":["$","img",null,{"alt":"","src":"https://tz-1256822507.cos.ap-hongkong.myqcloud.com/typora/image-20230114173536514.png"}]}],["$","p",null,{"children":"训练了四个模型。模型参数大小的差距是log近似 log(parameters)约等于1，每个模型的学习率都是手动调整的以至于在5%webtext保留数据集上获得最好的困惑度。所有模型仍然欠拟合，"}],["$","h2",null,{}],["$","p",null,{"children":["$","img",null,{"alt":"","src":"https://tz-1256822507.cos.ap-hongkong.myqcloud.com/typora/image-20230114234210104.png"}]}],["$","p",null,{"children":[["$","strong",null,{"children":"Children's Book Test(CBT)"}]," 检查LM在不同词类的表现，命名实体，名词，动词介词。将模型完形填空的准确率作为评价指标。"]}],["$","p",null,{"children":[["$","strong",null,{"children":"LAMDADA"}],"：系统对文本中远程依赖建模的能力，预测句子的最后一个单词。"]}],["$","p",null,{"children":"GPT2的错误预测情况下大多是句子的延续而不是句子结尾的最后一个单词。表明LM没有使用单词必须是结尾的约束条件。添加一个停用词过滤会将准确率从"}],["$","p",null,{"children":"52.66%提升到63.24%。"}],["$","p",null,{"children":[["$","strong",null,{"children":"Winograd Schema Challenge"}],":衡量系统解决文本歧义的能力来衡量系统执行常识推理的能力。"]}],["$","img",null,{"src":"https://tz-1256822507.cos.ap-hongkong.myqcloud.com/typora/image-20230114235737803.png","alt":""}],["$","p",null,{"children":[["$","strong",null,{"children":"CoQA Conversation Question Answering"}],":"]}],["$","p",null,{"children":"GPT2 在开发集上55 F1（zero shot）。SOTA 是bert进行监督学习 89F1. 从错误预测的数据中作者发现，GPT2经常使用简单的，基于启发式的检索方法。例如用文档中的名字回答Who问题。"}],["$","p",null,{"children":["$","strong",null,{"children":"CNN and Daily Mail dataset [Summarization]"}]}],["$","p",null,{"children":"为了诱导模型摘要的能力，在文档之后添加文本 TL;DR，使用top-k随机抽样，k=2,减少重复并估计更抽象的摘要。"}],["$","p",null,{"children":["$","img",null,{"alt":"","src":"https://tz-1256822507.cos.ap-hongkong.myqcloud.com/typora/image-20230115000753152.png"}]}],["$","p",null,{"children":"当任务提示移出后，GPT2的指标下降了6.4,这证明可以使用自然语言调用模型针对特定任务的行为。"}],["$","p",null,{"children":["$","strong",null,{"children":"WMT14-En-Fr"}]}],["$","p",null,{"children":"wmt14-en-fr :GPT2 5BLEU，"}],["$","p",null,{"children":"Wmt14-fr-en: GPT2 11.5 BLEU. 得益于英文的语言模型。 最好的无监督机器翻译方法 BLUE是33.5 。差的还比较多。"}],["$","p",null,{"children":["$","strong",null,{"children":"Question-answer"}]}],["$","p",null,{"children":"SQUAD: GPT2 准确回答了4.1%的准确率。最小的模型准确率低于1%。（Who，What，Where）,GPT2在最小信息的1%的数据上有63.1%准确率"}],["$","h2",null,{"id":"泛化与记忆","className":"content-header","children":[["$","a",null,{"href":"#泛化与记忆","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"泛化与记忆"]}],["$","p",null,{"children":"基于8-gram重叠作为重复句子，判断webtext数据和其他测试数据集的重复率"}],["$","p",null,{"children":["$","img",null,{"alt":"","src":"https://tz-1256822507.cos.ap-hongkong.myqcloud.com/typora/image-20230115110551031.png"}]}],["$","p",null,{"children":"作者建议在新的NLP数据集上创建训练或测试拆分期间，基于n-gram重复的验证是有必要的。"}],["$","p",null,{"children":"下图可以看出，模型仍然是欠拟合。"}],["$","img",null,{"src":"https://tz-1256822507.cos.ap-hongkong.myqcloud.com/typora/image-20230115110637126.png","alt":""}],["$","h2",null,{"id":"相关工作","className":"content-header","children":[["$","a",null,{"href":"#相关工作","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"相关工作"]}],["$","p",null,{"children":"Jozefowicz et al. (2016) 在10亿word上训练RNN语言模型。"}],["$","p",null,{"children":"语言模型有趣的功能Karpathy et al. (2015). ，line-width tracking and quote/comment detection"}],["$","p",null,{"children":"(Ramachandran et al., 2016) 证明了seq2seq模型受益于预训练语言模型作为编码器和解码器的初始化。"}],["$","p",null,{"children":"(Wolf et al., 2019) (Dinan et al., 2018) LM pre-training 在对话和困难生成任务上进行微调也有很帮助"}],["$","h2",null,{"id":"讨论","className":"content-header","children":[["$","a",null,{"href":"#讨论","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"讨论"]}],["$","p",null,{"children":"虽然作为研究结果具有启发性，但是实际应用，GPT2的零样本性能仍远未可用。"}],["$","p",null,{"children":"尚不清楚GPT2微调的上限。"}],["$","p",null,{"children":"并且不清楚GPT2的额外训练数据和容量是否能够克服BERT所展示单向表示的低效率(Devlin et al., 2018)."}]]}]}],["$","div",null,{"className":"pb-6 pt-6 text-center text-gray-700 dark:text-gray-300","id":"comment","children":["$","$L10",null,{"slug":"AI/2023-01-15-GPT2"}]}],["$","footer",null,{"children":["$","div",null,{"className":"flex flex-col text-sm font-medium sm:flex-row sm:justify-between sm:text-base","children":[["$","div",null,{"className":"pt-4 xl:pt-8","children":["$","$Lb",null,{"href":"/blog/AI/2023-01-15-GPT3","className":"dark:hover:text-primary-400 text-primary-500 hover:text-primary-600","aria-label":"Previous post: GPT3","children":["← ","GPT3"]}]}],["$","div",null,{"className":"pt-4 xl:pt-8","children":["$","$Lb",null,{"href":"/blog/AI/2023-02-12-笔记-nanoGPT","className":"dark:hover:text-primary-400 text-primary-500 hover:text-primary-600","aria-label":"Next post: 笔记-nanoGPT","children":["笔记-nanoGPT"," →"]}]}]]}]}]]}]]}]}]]}]]
e:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"GPT2 | Tz Blog"}],["$","meta","3",{"name":"description","content":"GPT-2语言模型,一个无监督的多任务学习器。GPT-2在多个任务上实现了零样本学习的最先进结果,展示了语言模型作为通用任务学习器的潜力。文章还讨论了增加模型容量可以以对数线性方式提高性能,以及大规模多样化数据集对模型泛化能力的重要性。"}],["$","meta","4",{"name":"robots","content":"index, follow"}],["$","meta","5",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","6",{"rel":"canonical","href":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-01-15-GPT2"}],["$","link","7",{"rel":"alternate","type":"application/rss+xml","href":"https://tailwind-nextjs-starter-blog.vercel.app/feed.xml"}],["$","meta","8",{"property":"og:title","content":"GPT2"}],["$","meta","9",{"property":"og:description","content":"GPT-2语言模型,一个无监督的多任务学习器。GPT-2在多个任务上实现了零样本学习的最先进结果,展示了语言模型作为通用任务学习器的潜力。文章还讨论了增加模型容量可以以对数线性方式提高性能,以及大规模多样化数据集对模型泛化能力的重要性。"}],["$","meta","10",{"property":"og:url","content":"https://tailwind-nextjs-starter-blog.vercel.app/blog/AI/2023-01-15-GPT2"}],["$","meta","11",{"property":"og:site_name","content":"Tz Blog"}],["$","meta","12",{"property":"og:locale","content":"en_US"}],["$","meta","13",{"property":"og:image","content":"https://tailwind-nextjs-starter-blog.vercel.app/static/images/twitter-card.png"}],["$","meta","14",{"property":"og:type","content":"article"}],["$","meta","15",{"property":"article:published_time","content":"2023-01-15T00:00:00.000Z"}],["$","meta","16",{"property":"article:modified_time","content":"2023-01-15T00:00:00.000Z"}],["$","meta","17",{"property":"article:author","content":"Tz"}],["$","meta","18",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","19",{"name":"twitter:title","content":"GPT2"}],["$","meta","20",{"name":"twitter:description","content":"GPT-2语言模型,一个无监督的多任务学习器。GPT-2在多个任务上实现了零样本学习的最先进结果,展示了语言模型作为通用任务学习器的潜力。文章还讨论了增加模型容量可以以对数线性方式提高性能,以及大规模多样化数据集对模型泛化能力的重要性。"}],["$","meta","21",{"name":"twitter:image","content":"https://tailwind-nextjs-starter-blog.vercel.app/static/images/twitter-card.png"}],["$","meta","22",{"name":"next-size-adjust"}]]
1:null
